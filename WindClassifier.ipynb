{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "text",
    "id": "AH7bAAGcobV3"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-ccc1ecde25f7>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-ccc1ecde25f7>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    이번 과제에서는 케라스(Keras)를 활용하여, 와인의 품질을 분류하는 인공신경망 분류기를 만들어 볼 것입니다.\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 와인 감별사 : 와인의 Quality를 분류하는 Classifier 만들기\n",
    "\n",
    "## 1. 과제 설명\n",
    "이번 과제에서는 케라스(Keras)를 활용하여, 와인의 품질을 분류하는 인공신경망 분류기를 만들어 볼 것입니다.\n",
    "케라스는 Tensorflow, Theano 등의 딥 러닝 라이브러리 위에서 동작하는 오픈 소스 라이브러리로, 보다 쉬운 API를 제공함으로써 모델 설계 및 학습, 테스트가 간단하다는 장점이 있습니다. \n",
    "\n",
    "### 1.1 케라스 설치를 위한 필수 라이브러리\n",
    "케라스를 설치하기 전에 먼저 필수적으로 설치해야 할 것들이 있습니다.\n",
    "* Anaconda : Python 3.x 버전, Numpy, Pandas, SciPy, sklearn 등 필수 라이브러리들이 포함된 통합 배포 팩\n",
    "<br> 아나콘다 설치 : https://www.anaconda.com/distribution/#download-section\n",
    "* Tensorflow : Google에서 개발한 오픈 소스 딥 러닝 라이브러리. <b>설치된 Python 버전과 호환되는 것으로 설치할것!</b>\n",
    "<br> 텐서플로우 설치 : https://www.tensorflow.org/install/pip\n",
    "<br> * CPU 버전을 설치할 것을 권장. \n",
    "\n",
    "### 1.2 케라스 설치\n",
    "위 라이브러리들을 설치한 후, 케라스를 설치합니다.\n",
    "* https://keras.io/#installation\n",
    "\n",
    "### 1.3 케라스 설치 확인\n",
    "케라스가 올바르게 설치되었는지 확인하기 위해, 케라스를 Import한 뒤 버전을 출력해봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdWzUjvZobV4",
    "outputId": "e8e9a35e-98d5-48e1-f9c1-978077d96b36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lWlwSKksobV_"
   },
   "source": [
    "위와 같이 케라스의 버전이 출력되면 정상입니다. (출력되는 버전은 위 예시와 다를 수도 있음)<br> 나중에 신경망을 만들기 위한 클래스들도 함께 Import 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ruFtS02AobWA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from keras import layers, models\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZggQC1JiobWC"
   },
   "source": [
    "---\n",
    "## 2. Data Set 설명\n",
    " 본 과제에서 사용할 데이터 셋은 UCI에서 제공되는 Wine Quality Data Set입니다. (https://archive.ics.uci.edu/ml/datasets/Wine+Quality) 데이터는 레드 와인 1599개, 화이트 와인 4898개의 화학적 특성을 포함하고 있습니다. 데이터는 두 개의 CSV(Comma-seperated values)형태로 제공되며, 구성은 다음과 같습니다.\n",
    "* 화이트 와인 / 레드 와인 CSV 파일\n",
    "* 11개의 실수(Real) 입력 변수 (X)\n",
    "    * fixed acidity\n",
    "    * volatile acidity\n",
    "    * citric acid\n",
    "    * residual sugar\n",
    "    * chlorides\n",
    "    * free sulfur dioxide\n",
    "    * total sulfur dioxide\n",
    "    * density\n",
    "    * pH\n",
    "    * sulphates\n",
    "    * alcohol\n",
    "* 1개의 클래스 레이블 (Y)\n",
    "   * quality (0~10, 0: Very poor, 10: Very excellent)\n",
    "* Missing Value 없음\n",
    "* 클래스들이 불균등하게 분포함.\n",
    "\n",
    "더 자세한 사항은 블랙보드에 함께 올라가있는 설명 파일을 참고하도록 합시다.\n",
    "\n",
    "### 2.1 데이터 로드\n",
    "데이터 분석에서 가장 많이 사용되는 라이브러리 중 하나인 Pandas와 Numpy를 Import하겠습니다. Pandas는 데이터 분석에 유용한 데이터 타입인 DataFrame을 제공하며, Numpy는 효율적이고 빠른 매트릭스 연산을 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5kTZyX1obWD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.__version__\n",
    "pd.options.display.max_rows=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0thM0X0obWG",
    "outputId": "424a3336-02e9-4d28-b9db-725719c2e71b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCI_seungchan\\Jupyter\\wine_classifier\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHEmT15sobWJ"
   },
   "source": [
    "Pandas를 이용해서 CSV 파일을 읽어들이도록 합시다. white_wine 변수에는 화이트 와인 데이터를, red_wine 변수에는 레드 와인 데이터를 읽어들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t0s-aG2SobWJ"
   },
   "outputs": [],
   "source": [
    "#########################코드########################\n",
    "\n",
    "\n",
    "white_wine = pd.read_csv('./wine_data/winequality-white.csv')\n",
    "red_wine = pd.read_csv('./wine_data/winequality-red.csv')\n",
    "\n",
    "\n",
    "\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3zUEFZtobWM"
   },
   "source": [
    "### 2.2 데이터 전처리\n",
    "데이터를 읽어들인 뒤, 읽어들인 데이터프레임을 display 함수를 통해 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IR2Bk48fobWM",
    "outputId": "378265b5-1cf8-4927-d318-c196f9e658bd"
   },
   "outputs": [],
   "source": [
    "display(white_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aoIonV7KobWP",
    "outputId": "4e225517-5e4c-4291-8371-da3ba36acc3f"
   },
   "outputs": [],
   "source": [
    "# print(red_wine.loc[0])\n",
    "# display(red_wine)\n",
    "red_wine.shape\n",
    "# from keras import datasets\n",
    "# (x,y),(x_, y_)  = datasets.mnist.load_data()\n",
    "# print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YA0L1jCDobWS"
   },
   "source": [
    "이제 데이터프레임을 입력 변수와 정답 셋(클래스 레이블)으로 나누는 함수를 작성하겠습니다.<br>\n",
    "<b>generate_data</b>함수는 데이터프레임 객체와 테스트 셋 비율을 입력으로 받아, 네 개의 numpy array를 반환합니다. 트레이닝 셋과 테스트 셋의 비율은 training_set_ratio에 의해 결정됩니다.\n",
    "* Function : generate_data\n",
    " * 입력\n",
    "     * pd.DataFrame : df\n",
    "     * double : training_set_ratio  \n",
    " * 출력\n",
    "     * np.array : X_train\n",
    "     * np.array : Y_train\n",
    "     * np.array : X_test\n",
    "     * np.array : Y_test\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sHHRgjpWobWT"
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "def normalize(total_data: np.array) -> None:\n",
    "    for i in range(np.shape(total_data)[1]-1):\n",
    "        col_zero_base = total_data[:,i] - total_data[:,i].min()\n",
    "        total_data[:,i] = ( col_zero_base ) / ( col_zero_base.max() )\n",
    "\n",
    "def generate_data(df: pd.DataFrame, t_r: float):\n",
    "    total_data = df.to_numpy()\n",
    "    normalize(total_data)\n",
    "\n",
    "    np.random.shuffle(total_data)\n",
    "    n_train_set = int(np.shape(total_data)[0] * t_r)\n",
    "\n",
    "    x_train = total_data[:n_train_set, :-1]\n",
    "    y_train = total_data[:n_train_set, -1:]\n",
    "\n",
    "    x_test = total_data[n_train_set:, :-1]\n",
    "    y_test = total_data[n_train_set:, -1:]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "#####################################################\n",
    "\n",
    "global one_hot_codes\n",
    "one_hot_codes = []\n",
    "def make_label():\n",
    "    global one_hot_codes\n",
    "    tmp = [0] * 10\n",
    "    for i in range(10):\n",
    "        tmp[i] = 1\n",
    "        one_hot_codes.append(tmp.copy())\n",
    "        tmp[i] = 0\n",
    "\n",
    "def one_hot_enc(y_label: np.array) -> np.array:\n",
    "    onehot_y = []\n",
    "    for i in range(np.shape(y_label)[0]):\n",
    "        idx = int(y_label[i][0])\n",
    "        if(idx < 0 or idx > 9):\n",
    "            print(idx)\n",
    "        onehot_y.append(one_hot_codes[idx])\n",
    "    \n",
    "    onehot_y = np.array(onehot_y)\n",
    "    return onehot_y\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train','Test'], loc=0)\n",
    "\n",
    "def plot_acc(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model acc')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train','Test'], loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-kAXFUkobWV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25961538, 0.43137255, 0.10240964, ..., 0.49090909, 0.11627907,\n",
       "        0.32258065],\n",
       "       [0.27884615, 0.15686275, 0.21686747, ..., 0.56363636, 0.34883721,\n",
       "        0.46774194],\n",
       "       [0.45192308, 0.08823529, 0.44578313, ..., 0.50909091, 0.20930233,\n",
       "        0.70967742],\n",
       "       ...,\n",
       "       [0.41346154, 0.41176471, 0.28313253, ..., 0.44545455, 0.23255814,\n",
       "        0.46774194],\n",
       "       [0.47115385, 0.2254902 , 0.43975904, ..., 0.21818182, 0.76744186,\n",
       "        0.11290323],\n",
       "       [0.35576923, 0.29411765, 0.3373494 , ..., 0.37272727, 0.5       ,\n",
       "        0.30645161]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_label()\n",
    "x_train, y_train, x_test, y_test = generate_data(white_wine, 0.8)\n",
    "y_train = one_hot_enc(y_train)\n",
    "y_test = one_hot_enc(y_test)\n",
    "\n",
    "display(x_train)\n",
    "display(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctr0KTQ7obWX"
   },
   "source": [
    "작성한 함수를 호출하여 화이트 와인 데이터에 대해 트레이닝 셋과 테스트 셋의 입력과 정답이 적절하게 생성되었는지 확인합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWOKgPSaobWY"
   },
   "source": [
    "# 3. 케라스를 이용한 모델 생성, 학습, 테스트\n",
    "입력 데이터와 정답 셋이 만들어졌으니 케라스를 사용하여 각 데이터에 대한 분류기를 생성하고, 트레이닝 셋으로 학습시킨 뒤 테스트 정확도를 관찰합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FO4OxZuhobWZ"
   },
   "source": [
    "# 과제\n",
    "### 1. 화이트 와인 분류 모델과 레드 와인 분류 모델 설계 및 학습\n",
    "* 하나의 히든 레이어에 32개의 노드를 가진 인공신경망 모델 생성 및 모델 학습\n",
    "* 트레이닝 Epoch에 따라 Loss의 변화를 그래프로 시각화\n",
    "* 테스트 셋에 대한 정확도 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gE8UhHrNobWZ"
   },
   "outputs": [],
   "source": [
    "##########################################################\n",
    "class ANN(models.Model):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        hidden = layers.Dense(n_h)\n",
    "        output = layers.Dense(n_out)\n",
    "        relu = layers.Activation('relu')\n",
    "        softmax = layers.Activation('softmax')\n",
    "\n",
    "        x = layers.Input(shape=(n_in,))\n",
    "        h = relu(hidden(x))\n",
    "        y = softmax(output(h))\n",
    "\n",
    "        super().__init__(x, y)\n",
    "        self.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "n_in = 11\n",
    "n_h = 32\n",
    "n_out = 10\n",
    "model = ANN(n_in, n_h, n_out)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=500,\n",
    "                    batch_size=200, validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "performance_test = model.evaluate(x_test, y_test, batch_size=200)\n",
    "\n",
    "print(f'\\nTest Loss: {performance_test}')\n",
    "\n",
    "plot_loss(history)\n",
    "plt.show()\n",
    "plot_acc(history)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5aI6JweqobWc"
   },
   "source": [
    "### 2. 각 모델의 성능을 향상시킬 수 있는 방법 적용\n",
    "* 하이퍼파라미터를 변경하여 테스트 셋에서의 정확도를 향상시킬 것\n",
    "    * 예) 레이어 수, 노드 수, Learning rate 등\n",
    "* 하이퍼파라미터를 변화시킨 각각의 모델에 대해, 트레이닝 Epoch 당 Loss의 변화를 기록하고 이를 시각화\n",
    "* 그 외 성능을 향상시킬 수 있는 모든 방법을 사용하여 가장 성능이 좋은 모델을 선택\n",
    "    * 예) Dropout, Normalization 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5JOT7FBobWc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HCI_seungchan\\.conda\\envs\\jup_keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3134 samples, validate on 784 samples\n",
      "Epoch 1/15\n",
      "3134/3134 [==============================] - 0s 158us/step - loss: 1.6729 - accuracy: 0.3638 - val_loss: 1.2964 - val_accuracy: 0.4617\n",
      "Epoch 2/15\n",
      "3134/3134 [==============================] - 0s 28us/step - loss: 1.4156 - accuracy: 0.3928 - val_loss: 1.2999 - val_accuracy: 0.4617\n",
      "Epoch 3/15\n",
      "3134/3134 [==============================] - 0s 28us/step - loss: 1.3700 - accuracy: 0.4017 - val_loss: 1.2947 - val_accuracy: 0.4617\n",
      "Epoch 4/15\n",
      "3134/3134 [==============================] - 0s 28us/step - loss: 1.3553 - accuracy: 0.4100 - val_loss: 1.2975 - val_accuracy: 0.4617\n",
      "Epoch 5/15\n",
      "3134/3134 [==============================] - 0s 28us/step - loss: 1.3367 - accuracy: 0.4148 - val_loss: 1.2927 - val_accuracy: 0.4617\n",
      "Epoch 6/15\n",
      "3134/3134 [==============================] - 0s 28us/step - loss: 1.3388 - accuracy: 0.4215 - val_loss: 1.2915 - val_accuracy: 0.4617\n",
      "Epoch 7/15\n",
      "3134/3134 [==============================] - 0s 28us/step - loss: 1.3284 - accuracy: 0.4158 - val_loss: 1.3006 - val_accuracy: 0.4617\n",
      "Epoch 8/15\n",
      "3134/3134 [==============================] - 0s 27us/step - loss: 1.3156 - accuracy: 0.4381 - val_loss: 1.2940 - val_accuracy: 0.4617\n",
      "Epoch 9/15\n",
      "3134/3134 [==============================] - 0s 27us/step - loss: 1.3176 - accuracy: 0.4250 - val_loss: 1.2997 - val_accuracy: 0.4617\n",
      "Epoch 10/15\n",
      "3134/3134 [==============================] - 0s 27us/step - loss: 1.3161 - accuracy: 0.4362 - val_loss: 1.2891 - val_accuracy: 0.4617\n",
      "Epoch 11/15\n",
      "3134/3134 [==============================] - 0s 27us/step - loss: 1.3085 - accuracy: 0.4266 - val_loss: 1.2891 - val_accuracy: 0.4617\n",
      "Epoch 12/15\n",
      "3134/3134 [==============================] - 0s 27us/step - loss: 1.3109 - accuracy: 0.4391 - val_loss: 1.2907 - val_accuracy: 0.4617\n",
      "Epoch 13/15\n",
      "3134/3134 [==============================] - 0s 27us/step - loss: 1.3073 - accuracy: 0.4438 - val_loss: 1.2890 - val_accuracy: 0.4617\n",
      "Epoch 14/15\n",
      "3134/3134 [==============================] - 0s 27us/step - loss: 1.3090 - accuracy: 0.4410 - val_loss: 1.2891 - val_accuracy: 0.4617\n",
      "Epoch 15/15\n",
      "3134/3134 [==============================] - 0s 27us/step - loss: 1.3057 - accuracy: 0.4416 - val_loss: 1.2967 - val_accuracy: 0.4617\n",
      "980/980 [==============================] - 0s 9us/step\n",
      "\n",
      "Test Loss: [1.3133507310127726, 0.44285714626312256]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################################################\n",
    "class DNN(models.Model):\n",
    "    def __init__(self, n_in, n_h, n_h2, n_h3, n_h4, n_h5, n_h6, n_h7, n_h8, n_h9, n_out):\n",
    "        hidden = layers.Dense(n_h)\n",
    "        hidden2 = layers.Dense(n_h2)\n",
    "        hidden3 = layers.Dense(n_h3)\n",
    "        hidden4 = layers.Dense(n_h4)\n",
    "        hidden5 = layers.Dense(n_h5)\n",
    "        hidden6 = layers.Dense(n_h6)\n",
    "        hidden7 = layers.Dense(n_h7)\n",
    "        hidden8 = layers.Dense(n_h8)\n",
    "        hidden9 = layers.Dense(n_h9)\n",
    "        hidden10 = layers.Dense(n_h9)\n",
    "        sigmoid = layers.Activation('sigmoid')\n",
    "        output = layers.Dense(n_out)\n",
    "        relu = layers.Activation('softplus')  \n",
    "        softmax = layers.Activation('softmax')\n",
    "        dropout_4 = layers.Dropout(0.48)\n",
    "        dropout_2 = layers.Dropout(0.2)\n",
    "\n",
    "        x = layers.Input(shape=(n_in,))\n",
    "        h = relu(hidden(x))\n",
    "        h = relu(hidden2(h))\n",
    "        h = dropout_4(h)\n",
    "        h = relu(hidden3(h))\n",
    "        h = dropout_2(h)\n",
    "        h = relu(hidden4(h))\n",
    "        h = relu(hidden5(h))\n",
    "        h = relu(hidden6(h))\n",
    "        h = dropout_2(h)\n",
    "        h = relu(hidden7(h))\n",
    "        h = dropout_4(h)\n",
    "        h = relu(hidden8(h))\n",
    "        h = dropout_4(h)\n",
    "        h = relu(hidden9(h))\n",
    "        h = dropout_2(h)\n",
    "        h = hidden10(h)\n",
    "        y = softmax(output(h))\n",
    "        \n",
    "        adam_slow = optimizers.Adam(lr=0.0008, beta_1=0.80)\n",
    "\n",
    "        super().__init__(x, y)\n",
    "        self.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=adam_slow,\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "n_in = 11\n",
    "n_h = 128\n",
    "n_h2 = 96\n",
    "n_h3 = 64\n",
    "n_h4 = 32\n",
    "n_h5 = 16\n",
    "n_h6 = n_h4\n",
    "n_h7 = n_h3\n",
    "n_h8 = n_h2\n",
    "n_h9 = n_h\n",
    "n_out = 10\n",
    "BATCH_SIZE = 200\n",
    "model = DNN(n_in, n_h, n_h2, n_h3, n_h4, n_h5, n_h6, n_h7, n_h8, n_h9, n_out)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=15,\n",
    "                    batch_size=BATCH_SIZE, validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "performance_test = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f'\\nTest Loss: {performance_test}')\n",
    "\n",
    "plot_loss(history)\n",
    "plt.show()\n",
    "plot_acc(history)\n",
    "plt.show()\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJ_KUtH2obWf"
   },
   "source": [
    "### 3. 화이트 와인과 레드 와인을 하나의 모델만 사용하여 분류\n",
    "* 화이트 와인과 레드 와인 데이터를 합쳐 wine 데이터 셋 생성\n",
    "* 입력이 화이트 와인인지 레드 와인인지에 관계없이 와인 품질을 분류하는 모델 생성\n",
    "* 모델의 성능을 향상시킬 수 있는 방법을 찾아 적용할 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWzy7FV8obWg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4157 samples, validate on 1040 samples\n",
      "Epoch 1/1500\n",
      "4157/4157 [==============================] - 1s 129us/step - loss: 1.6775 - accuracy: 0.3548 - val_loss: 1.2318 - val_accuracy: 0.4010\n",
      "Epoch 2/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.3766 - accuracy: 0.3924 - val_loss: 1.2284 - val_accuracy: 0.4010\n",
      "Epoch 3/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.3384 - accuracy: 0.4236 - val_loss: 1.2026 - val_accuracy: 0.4231\n",
      "Epoch 4/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3356 - accuracy: 0.4152 - val_loss: 1.2330 - val_accuracy: 0.4010\n",
      "Epoch 5/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.3218 - accuracy: 0.4260 - val_loss: 1.2587 - val_accuracy: 0.4010\n",
      "Epoch 6/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3150 - accuracy: 0.4296 - val_loss: 1.2083 - val_accuracy: 0.4010\n",
      "Epoch 7/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3118 - accuracy: 0.4287 - val_loss: 1.2383 - val_accuracy: 0.4010\n",
      "Epoch 8/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3101 - accuracy: 0.4409 - val_loss: 1.2069 - val_accuracy: 0.4010\n",
      "Epoch 9/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3058 - accuracy: 0.4292 - val_loss: 1.2362 - val_accuracy: 0.4010\n",
      "Epoch 10/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3034 - accuracy: 0.4443 - val_loss: 1.2196 - val_accuracy: 0.4231\n",
      "Epoch 11/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3020 - accuracy: 0.4287 - val_loss: 1.2598 - val_accuracy: 0.4010\n",
      "Epoch 12/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3010 - accuracy: 0.4453 - val_loss: 1.2134 - val_accuracy: 0.4010\n",
      "Epoch 13/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2998 - accuracy: 0.4438 - val_loss: 1.2385 - val_accuracy: 0.4010\n",
      "Epoch 14/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3025 - accuracy: 0.4402 - val_loss: 1.2204 - val_accuracy: 0.4010\n",
      "Epoch 15/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3009 - accuracy: 0.4407 - val_loss: 1.2212 - val_accuracy: 0.4010\n",
      "Epoch 16/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3011 - accuracy: 0.4304 - val_loss: 1.2132 - val_accuracy: 0.4010\n",
      "Epoch 17/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2962 - accuracy: 0.4441 - val_loss: 1.2668 - val_accuracy: 0.4010\n",
      "Epoch 18/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2966 - accuracy: 0.4455 - val_loss: 1.2461 - val_accuracy: 0.4010\n",
      "Epoch 19/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.3048 - accuracy: 0.4224 - val_loss: 1.3184 - val_accuracy: 0.4010\n",
      "Epoch 20/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2988 - accuracy: 0.4474 - val_loss: 1.2459 - val_accuracy: 0.4010\n",
      "Epoch 21/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2984 - accuracy: 0.4378 - val_loss: 1.2382 - val_accuracy: 0.4010\n",
      "Epoch 22/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2987 - accuracy: 0.4409 - val_loss: 1.2421 - val_accuracy: 0.4010\n",
      "Epoch 23/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2966 - accuracy: 0.4455 - val_loss: 1.2278 - val_accuracy: 0.4010\n",
      "Epoch 24/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2931 - accuracy: 0.4470 - val_loss: 1.2301 - val_accuracy: 0.4010\n",
      "Epoch 25/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2949 - accuracy: 0.4438 - val_loss: 1.2585 - val_accuracy: 0.4010\n",
      "Epoch 26/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2970 - accuracy: 0.4433 - val_loss: 1.2351 - val_accuracy: 0.4010\n",
      "Epoch 27/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2903 - accuracy: 0.4453 - val_loss: 1.2213 - val_accuracy: 0.4010\n",
      "Epoch 28/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2982 - accuracy: 0.4352 - val_loss: 1.2279 - val_accuracy: 0.4010\n",
      "Epoch 29/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.2965 - accuracy: 0.4446 - val_loss: 1.2212 - val_accuracy: 0.4010\n",
      "Epoch 30/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2929 - accuracy: 0.4455 - val_loss: 1.2261 - val_accuracy: 0.4010\n",
      "Epoch 31/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2915 - accuracy: 0.4448 - val_loss: 1.2184 - val_accuracy: 0.4010\n",
      "Epoch 32/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2941 - accuracy: 0.4433 - val_loss: 1.2533 - val_accuracy: 0.4010\n",
      "Epoch 33/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2940 - accuracy: 0.4453 - val_loss: 1.2180 - val_accuracy: 0.4010\n",
      "Epoch 34/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2978 - accuracy: 0.4344 - val_loss: 1.2265 - val_accuracy: 0.4010\n",
      "Epoch 35/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2995 - accuracy: 0.4318 - val_loss: 1.2349 - val_accuracy: 0.4010\n",
      "Epoch 36/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2931 - accuracy: 0.4465 - val_loss: 1.2289 - val_accuracy: 0.4010\n",
      "Epoch 37/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2941 - accuracy: 0.4462 - val_loss: 1.2207 - val_accuracy: 0.4010\n",
      "Epoch 38/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2890 - accuracy: 0.4441 - val_loss: 1.2505 - val_accuracy: 0.4010\n",
      "Epoch 39/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2980 - accuracy: 0.4414 - val_loss: 1.2347 - val_accuracy: 0.4010\n",
      "Epoch 40/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2933 - accuracy: 0.4412 - val_loss: 1.2311 - val_accuracy: 0.4010\n",
      "Epoch 41/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2905 - accuracy: 0.4462 - val_loss: 1.2302 - val_accuracy: 0.4010\n",
      "Epoch 42/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2921 - accuracy: 0.4465 - val_loss: 1.2304 - val_accuracy: 0.4010\n",
      "Epoch 43/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2937 - accuracy: 0.4414 - val_loss: 1.2286 - val_accuracy: 0.4010\n",
      "Epoch 44/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2918 - accuracy: 0.4470 - val_loss: 1.2218 - val_accuracy: 0.4010\n",
      "Epoch 45/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2905 - accuracy: 0.4470 - val_loss: 1.2307 - val_accuracy: 0.4010\n",
      "Epoch 46/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2904 - accuracy: 0.4470 - val_loss: 1.2178 - val_accuracy: 0.4010\n",
      "Epoch 47/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2919 - accuracy: 0.4465 - val_loss: 1.2343 - val_accuracy: 0.4010\n",
      "Epoch 48/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2942 - accuracy: 0.4470 - val_loss: 1.2342 - val_accuracy: 0.4010\n",
      "Epoch 49/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2911 - accuracy: 0.4467 - val_loss: 1.2510 - val_accuracy: 0.4010\n",
      "Epoch 50/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2927 - accuracy: 0.4460 - val_loss: 1.2362 - val_accuracy: 0.4010\n",
      "Epoch 51/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2909 - accuracy: 0.4460 - val_loss: 1.2209 - val_accuracy: 0.4010\n",
      "Epoch 52/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2862 - accuracy: 0.4498 - val_loss: 1.1936 - val_accuracy: 0.4029\n",
      "Epoch 53/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2667 - accuracy: 0.4587 - val_loss: 1.1409 - val_accuracy: 0.5038\n",
      "Epoch 54/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2435 - accuracy: 0.4513 - val_loss: 1.1249 - val_accuracy: 0.5067\n",
      "Epoch 55/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2168 - accuracy: 0.4708 - val_loss: 1.1456 - val_accuracy: 0.5135\n",
      "Epoch 56/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2119 - accuracy: 0.4650 - val_loss: 1.1345 - val_accuracy: 0.5548\n",
      "Epoch 57/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.2016 - accuracy: 0.4652 - val_loss: 1.1188 - val_accuracy: 0.5452\n",
      "Epoch 58/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1983 - accuracy: 0.4645 - val_loss: 1.1341 - val_accuracy: 0.4894\n",
      "Epoch 59/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1892 - accuracy: 0.4722 - val_loss: 1.1129 - val_accuracy: 0.4894\n",
      "Epoch 60/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1860 - accuracy: 0.4761 - val_loss: 1.1075 - val_accuracy: 0.5500\n",
      "Epoch 61/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1828 - accuracy: 0.4753 - val_loss: 1.1078 - val_accuracy: 0.5462\n",
      "Epoch 62/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1750 - accuracy: 0.4674 - val_loss: 1.0995 - val_accuracy: 0.5433\n",
      "Epoch 63/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1744 - accuracy: 0.4910 - val_loss: 1.1259 - val_accuracy: 0.5548\n",
      "Epoch 64/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.1705 - accuracy: 0.4823 - val_loss: 1.1153 - val_accuracy: 0.5567\n",
      "Epoch 65/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1723 - accuracy: 0.4775 - val_loss: 1.1254 - val_accuracy: 0.5010\n",
      "Epoch 66/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1697 - accuracy: 0.4797 - val_loss: 1.0867 - val_accuracy: 0.5260\n",
      "Epoch 67/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1711 - accuracy: 0.4729 - val_loss: 1.0988 - val_accuracy: 0.5048\n",
      "Epoch 68/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1651 - accuracy: 0.4924 - val_loss: 1.0910 - val_accuracy: 0.5606\n",
      "Epoch 69/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1684 - accuracy: 0.4838 - val_loss: 1.0934 - val_accuracy: 0.5394\n",
      "Epoch 70/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.1615 - accuracy: 0.4900 - val_loss: 1.0966 - val_accuracy: 0.5221\n",
      "Epoch 71/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1619 - accuracy: 0.4833 - val_loss: 1.0895 - val_accuracy: 0.5250\n",
      "Epoch 72/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1649 - accuracy: 0.4840 - val_loss: 1.0764 - val_accuracy: 0.5538\n",
      "Epoch 73/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.1641 - accuracy: 0.4903 - val_loss: 1.0899 - val_accuracy: 0.5240\n",
      "Epoch 74/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1599 - accuracy: 0.4992 - val_loss: 1.0782 - val_accuracy: 0.5490\n",
      "Epoch 75/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1571 - accuracy: 0.4980 - val_loss: 1.0885 - val_accuracy: 0.5096\n",
      "Epoch 76/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1540 - accuracy: 0.4891 - val_loss: 1.0763 - val_accuracy: 0.5298\n",
      "Epoch 77/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1641 - accuracy: 0.4919 - val_loss: 1.0800 - val_accuracy: 0.5317\n",
      "Epoch 78/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1526 - accuracy: 0.4943 - val_loss: 1.0838 - val_accuracy: 0.5635\n",
      "Epoch 79/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1523 - accuracy: 0.5020 - val_loss: 1.0775 - val_accuracy: 0.5500\n",
      "Epoch 80/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1557 - accuracy: 0.4924 - val_loss: 1.0700 - val_accuracy: 0.5548\n",
      "Epoch 81/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1507 - accuracy: 0.5011 - val_loss: 1.0651 - val_accuracy: 0.5596\n",
      "Epoch 82/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1455 - accuracy: 0.4931 - val_loss: 1.0518 - val_accuracy: 0.5596\n",
      "Epoch 83/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1483 - accuracy: 0.5042 - val_loss: 1.0597 - val_accuracy: 0.5692\n",
      "Epoch 84/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.1476 - accuracy: 0.5032 - val_loss: 1.0616 - val_accuracy: 0.5548\n",
      "Epoch 85/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1514 - accuracy: 0.4996 - val_loss: 1.0635 - val_accuracy: 0.5606\n",
      "Epoch 86/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.1526 - accuracy: 0.4953 - val_loss: 1.0747 - val_accuracy: 0.5548\n",
      "Epoch 87/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1545 - accuracy: 0.4984 - val_loss: 1.0580 - val_accuracy: 0.5442\n",
      "Epoch 88/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1502 - accuracy: 0.4996 - val_loss: 1.0605 - val_accuracy: 0.5538\n",
      "Epoch 89/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1562 - accuracy: 0.4958 - val_loss: 1.0677 - val_accuracy: 0.5529\n",
      "Epoch 90/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1421 - accuracy: 0.5054 - val_loss: 1.0546 - val_accuracy: 0.5587\n",
      "Epoch 91/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1407 - accuracy: 0.5076 - val_loss: 1.0507 - val_accuracy: 0.5490\n",
      "Epoch 92/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1430 - accuracy: 0.5032 - val_loss: 1.0615 - val_accuracy: 0.5510\n",
      "Epoch 93/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1478 - accuracy: 0.5064 - val_loss: 1.0683 - val_accuracy: 0.5490\n",
      "Epoch 94/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1440 - accuracy: 0.5030 - val_loss: 1.0610 - val_accuracy: 0.5577\n",
      "Epoch 95/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1459 - accuracy: 0.5025 - val_loss: 1.0699 - val_accuracy: 0.5558\n",
      "Epoch 96/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1470 - accuracy: 0.5030 - val_loss: 1.0692 - val_accuracy: 0.5327\n",
      "Epoch 97/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1444 - accuracy: 0.5061 - val_loss: 1.0665 - val_accuracy: 0.5471\n",
      "Epoch 98/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1447 - accuracy: 0.5112 - val_loss: 1.0595 - val_accuracy: 0.5471\n",
      "Epoch 99/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1447 - accuracy: 0.5013 - val_loss: 1.0632 - val_accuracy: 0.5587\n",
      "Epoch 100/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1444 - accuracy: 0.5093 - val_loss: 1.0545 - val_accuracy: 0.5500\n",
      "Epoch 101/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1460 - accuracy: 0.5030 - val_loss: 1.0733 - val_accuracy: 0.5481\n",
      "Epoch 102/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1451 - accuracy: 0.4994 - val_loss: 1.0704 - val_accuracy: 0.5558\n",
      "Epoch 103/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1456 - accuracy: 0.5066 - val_loss: 1.0742 - val_accuracy: 0.5337\n",
      "Epoch 104/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1348 - accuracy: 0.4970 - val_loss: 1.0662 - val_accuracy: 0.5529\n",
      "Epoch 105/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1478 - accuracy: 0.5061 - val_loss: 1.0540 - val_accuracy: 0.5558\n",
      "Epoch 106/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1380 - accuracy: 0.5153 - val_loss: 1.0575 - val_accuracy: 0.5519\n",
      "Epoch 107/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1444 - accuracy: 0.5008 - val_loss: 1.0645 - val_accuracy: 0.5317\n",
      "Epoch 108/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1361 - accuracy: 0.5030 - val_loss: 1.0542 - val_accuracy: 0.5423\n",
      "Epoch 109/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1381 - accuracy: 0.5150 - val_loss: 1.0707 - val_accuracy: 0.5423\n",
      "Epoch 110/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1395 - accuracy: 0.5148 - val_loss: 1.0537 - val_accuracy: 0.5471\n",
      "Epoch 111/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1443 - accuracy: 0.5016 - val_loss: 1.0513 - val_accuracy: 0.5567\n",
      "Epoch 112/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1365 - accuracy: 0.5102 - val_loss: 1.0558 - val_accuracy: 0.5606\n",
      "Epoch 113/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1377 - accuracy: 0.5066 - val_loss: 1.0515 - val_accuracy: 0.5510\n",
      "Epoch 114/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1416 - accuracy: 0.4999 - val_loss: 1.0514 - val_accuracy: 0.5490\n",
      "Epoch 115/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1360 - accuracy: 0.5006 - val_loss: 1.0545 - val_accuracy: 0.5500\n",
      "Epoch 116/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1416 - accuracy: 0.5119 - val_loss: 1.0682 - val_accuracy: 0.5317\n",
      "Epoch 117/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1392 - accuracy: 0.5037 - val_loss: 1.0553 - val_accuracy: 0.5471\n",
      "Epoch 118/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1363 - accuracy: 0.5105 - val_loss: 1.0623 - val_accuracy: 0.5490\n",
      "Epoch 119/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1402 - accuracy: 0.5105 - val_loss: 1.0607 - val_accuracy: 0.5490\n",
      "Epoch 120/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1366 - accuracy: 0.5032 - val_loss: 1.0486 - val_accuracy: 0.5471\n",
      "Epoch 121/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1364 - accuracy: 0.5131 - val_loss: 1.0501 - val_accuracy: 0.5500\n",
      "Epoch 122/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1349 - accuracy: 0.5076 - val_loss: 1.0546 - val_accuracy: 0.5490\n",
      "Epoch 123/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1314 - accuracy: 0.5124 - val_loss: 1.0591 - val_accuracy: 0.5510\n",
      "Epoch 124/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1340 - accuracy: 0.5160 - val_loss: 1.0499 - val_accuracy: 0.5519\n",
      "Epoch 125/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1362 - accuracy: 0.5054 - val_loss: 1.0415 - val_accuracy: 0.5519\n",
      "Epoch 126/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1369 - accuracy: 0.5016 - val_loss: 1.0514 - val_accuracy: 0.5481\n",
      "Epoch 127/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1381 - accuracy: 0.5150 - val_loss: 1.0509 - val_accuracy: 0.5510\n",
      "Epoch 128/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1328 - accuracy: 0.5150 - val_loss: 1.0516 - val_accuracy: 0.5510\n",
      "Epoch 129/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1349 - accuracy: 0.5172 - val_loss: 1.0442 - val_accuracy: 0.5510\n",
      "Epoch 130/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1387 - accuracy: 0.5114 - val_loss: 1.0441 - val_accuracy: 0.5510\n",
      "Epoch 131/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.1352 - accuracy: 0.5174 - val_loss: 1.0397 - val_accuracy: 0.5462\n",
      "Epoch 132/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1351 - accuracy: 0.5134 - val_loss: 1.0450 - val_accuracy: 0.5538\n",
      "Epoch 133/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1303 - accuracy: 0.5186 - val_loss: 1.0441 - val_accuracy: 0.5529\n",
      "Epoch 134/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1371 - accuracy: 0.5112 - val_loss: 1.0395 - val_accuracy: 0.5538\n",
      "Epoch 135/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1356 - accuracy: 0.5064 - val_loss: 1.0500 - val_accuracy: 0.5538\n",
      "Epoch 136/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1351 - accuracy: 0.5085 - val_loss: 1.0402 - val_accuracy: 0.5490\n",
      "Epoch 137/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1336 - accuracy: 0.5069 - val_loss: 1.0512 - val_accuracy: 0.5548\n",
      "Epoch 138/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1379 - accuracy: 0.5073 - val_loss: 1.0485 - val_accuracy: 0.5481\n",
      "Epoch 139/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1368 - accuracy: 0.5138 - val_loss: 1.0419 - val_accuracy: 0.5481\n",
      "Epoch 140/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1345 - accuracy: 0.5117 - val_loss: 1.0619 - val_accuracy: 0.5423\n",
      "Epoch 141/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1358 - accuracy: 0.5136 - val_loss: 1.0480 - val_accuracy: 0.5481\n",
      "Epoch 142/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.1298 - accuracy: 0.5215 - val_loss: 1.0467 - val_accuracy: 0.5558\n",
      "Epoch 143/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1291 - accuracy: 0.5208 - val_loss: 1.0402 - val_accuracy: 0.5529\n",
      "Epoch 144/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1321 - accuracy: 0.5088 - val_loss: 1.0420 - val_accuracy: 0.5481\n",
      "Epoch 145/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1286 - accuracy: 0.5124 - val_loss: 1.0435 - val_accuracy: 0.5548\n",
      "Epoch 146/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1338 - accuracy: 0.5138 - val_loss: 1.0443 - val_accuracy: 0.5462\n",
      "Epoch 147/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1350 - accuracy: 0.5025 - val_loss: 1.0377 - val_accuracy: 0.5462\n",
      "Epoch 148/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1323 - accuracy: 0.5105 - val_loss: 1.0416 - val_accuracy: 0.5500\n",
      "Epoch 149/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1276 - accuracy: 0.5165 - val_loss: 1.0385 - val_accuracy: 0.5577\n",
      "Epoch 150/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1305 - accuracy: 0.5117 - val_loss: 1.0418 - val_accuracy: 0.5433\n",
      "Epoch 151/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1333 - accuracy: 0.5134 - val_loss: 1.0413 - val_accuracy: 0.5442\n",
      "Epoch 152/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1315 - accuracy: 0.5196 - val_loss: 1.0395 - val_accuracy: 0.5500\n",
      "Epoch 153/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1356 - accuracy: 0.5093 - val_loss: 1.0428 - val_accuracy: 0.5519\n",
      "Epoch 154/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1348 - accuracy: 0.5134 - val_loss: 1.0510 - val_accuracy: 0.5625\n",
      "Epoch 155/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1247 - accuracy: 0.5141 - val_loss: 1.0337 - val_accuracy: 0.5548\n",
      "Epoch 156/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1345 - accuracy: 0.5114 - val_loss: 1.0387 - val_accuracy: 0.5500\n",
      "Epoch 157/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1276 - accuracy: 0.5112 - val_loss: 1.0359 - val_accuracy: 0.5462\n",
      "Epoch 158/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1319 - accuracy: 0.5129 - val_loss: 1.0330 - val_accuracy: 0.5490\n",
      "Epoch 159/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1221 - accuracy: 0.5244 - val_loss: 1.0402 - val_accuracy: 0.5529\n",
      "Epoch 160/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1309 - accuracy: 0.5109 - val_loss: 1.0367 - val_accuracy: 0.5538\n",
      "Epoch 161/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1323 - accuracy: 0.5218 - val_loss: 1.0331 - val_accuracy: 0.5433\n",
      "Epoch 162/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1287 - accuracy: 0.5117 - val_loss: 1.0366 - val_accuracy: 0.5548\n",
      "Epoch 163/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1298 - accuracy: 0.5162 - val_loss: 1.0416 - val_accuracy: 0.5442\n",
      "Epoch 164/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1302 - accuracy: 0.5194 - val_loss: 1.0400 - val_accuracy: 0.5548\n",
      "Epoch 165/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1270 - accuracy: 0.5117 - val_loss: 1.0360 - val_accuracy: 0.5490\n",
      "Epoch 166/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1288 - accuracy: 0.5121 - val_loss: 1.0321 - val_accuracy: 0.5519\n",
      "Epoch 167/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1302 - accuracy: 0.5167 - val_loss: 1.0425 - val_accuracy: 0.5510\n",
      "Epoch 168/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1311 - accuracy: 0.5109 - val_loss: 1.0361 - val_accuracy: 0.5433\n",
      "Epoch 169/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1311 - accuracy: 0.5124 - val_loss: 1.0377 - val_accuracy: 0.5481\n",
      "Epoch 170/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1253 - accuracy: 0.5196 - val_loss: 1.0338 - val_accuracy: 0.5423\n",
      "Epoch 171/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1288 - accuracy: 0.5134 - val_loss: 1.0323 - val_accuracy: 0.5423\n",
      "Epoch 172/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1274 - accuracy: 0.5085 - val_loss: 1.0257 - val_accuracy: 0.5462\n",
      "Epoch 173/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1263 - accuracy: 0.5172 - val_loss: 1.0255 - val_accuracy: 0.5404\n",
      "Epoch 174/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1326 - accuracy: 0.5191 - val_loss: 1.0318 - val_accuracy: 0.5529\n",
      "Epoch 175/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1220 - accuracy: 0.5170 - val_loss: 1.0301 - val_accuracy: 0.5423\n",
      "Epoch 176/1500\n",
      "4157/4157 [==============================] - 0s 34us/step - loss: 1.1266 - accuracy: 0.5201 - val_loss: 1.0403 - val_accuracy: 0.5462\n",
      "Epoch 177/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1279 - accuracy: 0.5160 - val_loss: 1.0459 - val_accuracy: 0.5413\n",
      "Epoch 178/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1333 - accuracy: 0.5112 - val_loss: 1.0272 - val_accuracy: 0.5567\n",
      "Epoch 179/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1268 - accuracy: 0.5223 - val_loss: 1.0330 - val_accuracy: 0.5490\n",
      "Epoch 180/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1234 - accuracy: 0.5191 - val_loss: 1.0284 - val_accuracy: 0.5538\n",
      "Epoch 181/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1219 - accuracy: 0.5150 - val_loss: 1.0343 - val_accuracy: 0.5471\n",
      "Epoch 182/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1247 - accuracy: 0.5179 - val_loss: 1.0416 - val_accuracy: 0.5510\n",
      "Epoch 183/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1251 - accuracy: 0.5124 - val_loss: 1.0264 - val_accuracy: 0.5510\n",
      "Epoch 184/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1249 - accuracy: 0.5213 - val_loss: 1.0327 - val_accuracy: 0.5538\n",
      "Epoch 185/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1256 - accuracy: 0.5186 - val_loss: 1.0334 - val_accuracy: 0.5548\n",
      "Epoch 186/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1290 - accuracy: 0.5215 - val_loss: 1.0266 - val_accuracy: 0.5433\n",
      "Epoch 187/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1283 - accuracy: 0.5158 - val_loss: 1.0272 - val_accuracy: 0.5548\n",
      "Epoch 188/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1199 - accuracy: 0.5148 - val_loss: 1.0412 - val_accuracy: 0.5490\n",
      "Epoch 189/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1199 - accuracy: 0.5191 - val_loss: 1.0249 - val_accuracy: 0.5519\n",
      "Epoch 190/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1276 - accuracy: 0.5160 - val_loss: 1.0319 - val_accuracy: 0.5538\n",
      "Epoch 191/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1259 - accuracy: 0.5210 - val_loss: 1.0335 - val_accuracy: 0.5452\n",
      "Epoch 192/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1224 - accuracy: 0.5223 - val_loss: 1.0309 - val_accuracy: 0.5462\n",
      "Epoch 193/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1203 - accuracy: 0.5138 - val_loss: 1.0189 - val_accuracy: 0.5519\n",
      "Epoch 194/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1202 - accuracy: 0.5225 - val_loss: 1.0233 - val_accuracy: 0.5490\n",
      "Epoch 195/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1247 - accuracy: 0.5210 - val_loss: 1.0279 - val_accuracy: 0.5490\n",
      "Epoch 196/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1216 - accuracy: 0.5117 - val_loss: 1.0240 - val_accuracy: 0.5462\n",
      "Epoch 197/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1214 - accuracy: 0.5189 - val_loss: 1.0245 - val_accuracy: 0.5510\n",
      "Epoch 198/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1215 - accuracy: 0.5160 - val_loss: 1.0270 - val_accuracy: 0.5529\n",
      "Epoch 199/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1261 - accuracy: 0.5146 - val_loss: 1.0228 - val_accuracy: 0.5519\n",
      "Epoch 200/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1205 - accuracy: 0.5184 - val_loss: 1.0274 - val_accuracy: 0.5433\n",
      "Epoch 201/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1119 - accuracy: 0.5210 - val_loss: 1.0314 - val_accuracy: 0.5471\n",
      "Epoch 202/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1174 - accuracy: 0.5155 - val_loss: 1.0252 - val_accuracy: 0.5567\n",
      "Epoch 203/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1273 - accuracy: 0.5189 - val_loss: 1.0312 - val_accuracy: 0.5558\n",
      "Epoch 204/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1226 - accuracy: 0.5186 - val_loss: 1.0252 - val_accuracy: 0.5471\n",
      "Epoch 205/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1188 - accuracy: 0.5184 - val_loss: 1.0369 - val_accuracy: 0.5587\n",
      "Epoch 206/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1239 - accuracy: 0.5213 - val_loss: 1.0200 - val_accuracy: 0.5490\n",
      "Epoch 207/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1161 - accuracy: 0.5223 - val_loss: 1.0269 - val_accuracy: 0.5500\n",
      "Epoch 208/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1208 - accuracy: 0.5206 - val_loss: 1.0212 - val_accuracy: 0.5510\n",
      "Epoch 209/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1222 - accuracy: 0.5174 - val_loss: 1.0271 - val_accuracy: 0.5452\n",
      "Epoch 210/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1187 - accuracy: 0.5136 - val_loss: 1.0268 - val_accuracy: 0.5529\n",
      "Epoch 211/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1160 - accuracy: 0.5235 - val_loss: 1.0210 - val_accuracy: 0.5471\n",
      "Epoch 212/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1166 - accuracy: 0.5242 - val_loss: 1.0316 - val_accuracy: 0.5462\n",
      "Epoch 213/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1244 - accuracy: 0.5218 - val_loss: 1.0256 - val_accuracy: 0.5500\n",
      "Epoch 214/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1201 - accuracy: 0.5196 - val_loss: 1.0263 - val_accuracy: 0.5481\n",
      "Epoch 215/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1164 - accuracy: 0.5186 - val_loss: 1.0268 - val_accuracy: 0.5452\n",
      "Epoch 216/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1182 - accuracy: 0.5235 - val_loss: 1.0299 - val_accuracy: 0.5433\n",
      "Epoch 217/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1178 - accuracy: 0.5196 - val_loss: 1.0262 - val_accuracy: 0.5481\n",
      "Epoch 218/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1206 - accuracy: 0.5244 - val_loss: 1.0243 - val_accuracy: 0.5452\n",
      "Epoch 219/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1125 - accuracy: 0.5198 - val_loss: 1.0253 - val_accuracy: 0.5481\n",
      "Epoch 220/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1158 - accuracy: 0.5247 - val_loss: 1.0243 - val_accuracy: 0.5462\n",
      "Epoch 221/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1149 - accuracy: 0.5186 - val_loss: 1.0346 - val_accuracy: 0.5433\n",
      "Epoch 222/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1151 - accuracy: 0.5225 - val_loss: 1.0283 - val_accuracy: 0.5500\n",
      "Epoch 223/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1138 - accuracy: 0.5242 - val_loss: 1.0272 - val_accuracy: 0.5471\n",
      "Epoch 224/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1155 - accuracy: 0.5223 - val_loss: 1.0273 - val_accuracy: 0.5462\n",
      "Epoch 225/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1135 - accuracy: 0.5232 - val_loss: 1.0310 - val_accuracy: 0.5452\n",
      "Epoch 226/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1179 - accuracy: 0.5213 - val_loss: 1.0314 - val_accuracy: 0.5404\n",
      "Epoch 227/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1164 - accuracy: 0.5167 - val_loss: 1.0289 - val_accuracy: 0.5385\n",
      "Epoch 228/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1139 - accuracy: 0.5275 - val_loss: 1.0269 - val_accuracy: 0.5433\n",
      "Epoch 229/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1130 - accuracy: 0.5158 - val_loss: 1.0258 - val_accuracy: 0.5500\n",
      "Epoch 230/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1116 - accuracy: 0.5254 - val_loss: 1.0366 - val_accuracy: 0.5490\n",
      "Epoch 231/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1097 - accuracy: 0.5215 - val_loss: 1.0312 - val_accuracy: 0.5404\n",
      "Epoch 232/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1171 - accuracy: 0.5162 - val_loss: 1.0291 - val_accuracy: 0.5346\n",
      "Epoch 233/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1157 - accuracy: 0.5218 - val_loss: 1.0305 - val_accuracy: 0.5519\n",
      "Epoch 234/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1094 - accuracy: 0.5215 - val_loss: 1.0322 - val_accuracy: 0.5423\n",
      "Epoch 235/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1128 - accuracy: 0.5201 - val_loss: 1.0340 - val_accuracy: 0.5423\n",
      "Epoch 236/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1124 - accuracy: 0.5251 - val_loss: 1.0298 - val_accuracy: 0.5385\n",
      "Epoch 237/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1119 - accuracy: 0.5201 - val_loss: 1.0347 - val_accuracy: 0.5308\n",
      "Epoch 238/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1100 - accuracy: 0.5186 - val_loss: 1.0294 - val_accuracy: 0.5413\n",
      "Epoch 239/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1176 - accuracy: 0.5239 - val_loss: 1.0321 - val_accuracy: 0.5346\n",
      "Epoch 240/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1105 - accuracy: 0.5227 - val_loss: 1.0297 - val_accuracy: 0.5471\n",
      "Epoch 241/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1127 - accuracy: 0.5355 - val_loss: 1.0376 - val_accuracy: 0.5365\n",
      "Epoch 242/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1083 - accuracy: 0.5266 - val_loss: 1.0354 - val_accuracy: 0.5385\n",
      "Epoch 243/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1117 - accuracy: 0.5254 - val_loss: 1.0289 - val_accuracy: 0.5442\n",
      "Epoch 244/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1085 - accuracy: 0.5278 - val_loss: 1.0354 - val_accuracy: 0.5442\n",
      "Epoch 245/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1096 - accuracy: 0.5237 - val_loss: 1.0295 - val_accuracy: 0.5423\n",
      "Epoch 246/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1113 - accuracy: 0.5201 - val_loss: 1.0340 - val_accuracy: 0.5442\n",
      "Epoch 247/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1124 - accuracy: 0.5186 - val_loss: 1.0280 - val_accuracy: 0.5442\n",
      "Epoch 248/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1091 - accuracy: 0.5242 - val_loss: 1.0312 - val_accuracy: 0.5462\n",
      "Epoch 249/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1101 - accuracy: 0.5225 - val_loss: 1.0334 - val_accuracy: 0.5423\n",
      "Epoch 250/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1140 - accuracy: 0.5143 - val_loss: 1.0294 - val_accuracy: 0.5404\n",
      "Epoch 251/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1065 - accuracy: 0.5237 - val_loss: 1.0385 - val_accuracy: 0.5423\n",
      "Epoch 252/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1075 - accuracy: 0.5275 - val_loss: 1.0323 - val_accuracy: 0.5413\n",
      "Epoch 253/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1092 - accuracy: 0.5256 - val_loss: 1.0370 - val_accuracy: 0.5394\n",
      "Epoch 254/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1131 - accuracy: 0.5251 - val_loss: 1.0390 - val_accuracy: 0.5404\n",
      "Epoch 255/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1106 - accuracy: 0.5232 - val_loss: 1.0456 - val_accuracy: 0.5327\n",
      "Epoch 256/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1108 - accuracy: 0.5225 - val_loss: 1.0403 - val_accuracy: 0.5433\n",
      "Epoch 257/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1048 - accuracy: 0.5247 - val_loss: 1.0408 - val_accuracy: 0.5308\n",
      "Epoch 258/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1072 - accuracy: 0.5271 - val_loss: 1.0346 - val_accuracy: 0.5394\n",
      "Epoch 259/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1040 - accuracy: 0.5292 - val_loss: 1.0421 - val_accuracy: 0.5298\n",
      "Epoch 260/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1111 - accuracy: 0.5239 - val_loss: 1.0365 - val_accuracy: 0.5423\n",
      "Epoch 261/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1023 - accuracy: 0.5203 - val_loss: 1.0346 - val_accuracy: 0.5404\n",
      "Epoch 262/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1073 - accuracy: 0.5266 - val_loss: 1.0407 - val_accuracy: 0.5413\n",
      "Epoch 263/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1134 - accuracy: 0.5268 - val_loss: 1.0343 - val_accuracy: 0.5442\n",
      "Epoch 264/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1112 - accuracy: 0.5167 - val_loss: 1.0327 - val_accuracy: 0.5433\n",
      "Epoch 265/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1038 - accuracy: 0.5266 - val_loss: 1.0339 - val_accuracy: 0.5423\n",
      "Epoch 266/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1058 - accuracy: 0.5299 - val_loss: 1.0389 - val_accuracy: 0.5404\n",
      "Epoch 267/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1065 - accuracy: 0.5215 - val_loss: 1.0341 - val_accuracy: 0.5404\n",
      "Epoch 268/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1065 - accuracy: 0.5297 - val_loss: 1.0368 - val_accuracy: 0.5375\n",
      "Epoch 269/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1081 - accuracy: 0.5227 - val_loss: 1.0372 - val_accuracy: 0.5433\n",
      "Epoch 270/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1071 - accuracy: 0.5218 - val_loss: 1.0321 - val_accuracy: 0.5413\n",
      "Epoch 271/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1075 - accuracy: 0.5210 - val_loss: 1.0354 - val_accuracy: 0.5413\n",
      "Epoch 272/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1119 - accuracy: 0.5206 - val_loss: 1.0349 - val_accuracy: 0.5442\n",
      "Epoch 273/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1089 - accuracy: 0.5203 - val_loss: 1.0375 - val_accuracy: 0.5413\n",
      "Epoch 274/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1024 - accuracy: 0.5268 - val_loss: 1.0416 - val_accuracy: 0.5394\n",
      "Epoch 275/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1042 - accuracy: 0.5213 - val_loss: 1.0382 - val_accuracy: 0.5423\n",
      "Epoch 276/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1105 - accuracy: 0.5256 - val_loss: 1.0370 - val_accuracy: 0.5423\n",
      "Epoch 277/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1070 - accuracy: 0.5242 - val_loss: 1.0327 - val_accuracy: 0.5413\n",
      "Epoch 278/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1060 - accuracy: 0.5290 - val_loss: 1.0348 - val_accuracy: 0.5413\n",
      "Epoch 279/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1041 - accuracy: 0.5326 - val_loss: 1.0370 - val_accuracy: 0.5413\n",
      "Epoch 280/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1070 - accuracy: 0.5182 - val_loss: 1.0393 - val_accuracy: 0.5404\n",
      "Epoch 281/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1088 - accuracy: 0.5249 - val_loss: 1.0371 - val_accuracy: 0.5433\n",
      "Epoch 282/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1081 - accuracy: 0.5256 - val_loss: 1.0403 - val_accuracy: 0.5442\n",
      "Epoch 283/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1108 - accuracy: 0.5254 - val_loss: 1.0404 - val_accuracy: 0.5413\n",
      "Epoch 284/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1078 - accuracy: 0.5263 - val_loss: 1.0461 - val_accuracy: 0.5308\n",
      "Epoch 285/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.1097 - accuracy: 0.5292 - val_loss: 1.0407 - val_accuracy: 0.5423\n",
      "Epoch 286/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1054 - accuracy: 0.5285 - val_loss: 1.0392 - val_accuracy: 0.5462\n",
      "Epoch 287/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1065 - accuracy: 0.5287 - val_loss: 1.0413 - val_accuracy: 0.5433\n",
      "Epoch 288/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1058 - accuracy: 0.5307 - val_loss: 1.0456 - val_accuracy: 0.5385\n",
      "Epoch 289/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0972 - accuracy: 0.5338 - val_loss: 1.0406 - val_accuracy: 0.5423\n",
      "Epoch 290/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1098 - accuracy: 0.5268 - val_loss: 1.0361 - val_accuracy: 0.5433\n",
      "Epoch 291/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1058 - accuracy: 0.5210 - val_loss: 1.0403 - val_accuracy: 0.5423\n",
      "Epoch 292/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1064 - accuracy: 0.5275 - val_loss: 1.0418 - val_accuracy: 0.5413\n",
      "Epoch 293/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1034 - accuracy: 0.5263 - val_loss: 1.0321 - val_accuracy: 0.5452\n",
      "Epoch 294/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1053 - accuracy: 0.5309 - val_loss: 1.0469 - val_accuracy: 0.5462\n",
      "Epoch 295/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1006 - accuracy: 0.5295 - val_loss: 1.0411 - val_accuracy: 0.5356\n",
      "Epoch 296/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1017 - accuracy: 0.5302 - val_loss: 1.0387 - val_accuracy: 0.5413\n",
      "Epoch 297/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1039 - accuracy: 0.5237 - val_loss: 1.0403 - val_accuracy: 0.5413\n",
      "Epoch 298/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1036 - accuracy: 0.5280 - val_loss: 1.0410 - val_accuracy: 0.5413\n",
      "Epoch 299/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1049 - accuracy: 0.5319 - val_loss: 1.0421 - val_accuracy: 0.5413\n",
      "Epoch 300/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1058 - accuracy: 0.5316 - val_loss: 1.0428 - val_accuracy: 0.5423\n",
      "Epoch 301/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1045 - accuracy: 0.5213 - val_loss: 1.0448 - val_accuracy: 0.5442\n",
      "Epoch 302/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0997 - accuracy: 0.5287 - val_loss: 1.0434 - val_accuracy: 0.5365\n",
      "Epoch 303/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1035 - accuracy: 0.5235 - val_loss: 1.0421 - val_accuracy: 0.5442\n",
      "Epoch 304/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1088 - accuracy: 0.5268 - val_loss: 1.0366 - val_accuracy: 0.5375\n",
      "Epoch 305/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1022 - accuracy: 0.5309 - val_loss: 1.0356 - val_accuracy: 0.5413\n",
      "Epoch 306/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0997 - accuracy: 0.5302 - val_loss: 1.0395 - val_accuracy: 0.5413\n",
      "Epoch 307/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1055 - accuracy: 0.5292 - val_loss: 1.0417 - val_accuracy: 0.5452\n",
      "Epoch 308/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1025 - accuracy: 0.5292 - val_loss: 1.0406 - val_accuracy: 0.5404\n",
      "Epoch 309/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1005 - accuracy: 0.5355 - val_loss: 1.0452 - val_accuracy: 0.5433\n",
      "Epoch 310/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1035 - accuracy: 0.5275 - val_loss: 1.0442 - val_accuracy: 0.5385\n",
      "Epoch 311/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0973 - accuracy: 0.5307 - val_loss: 1.0429 - val_accuracy: 0.5375\n",
      "Epoch 312/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1009 - accuracy: 0.5302 - val_loss: 1.0430 - val_accuracy: 0.5346\n",
      "Epoch 313/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1063 - accuracy: 0.5309 - val_loss: 1.0407 - val_accuracy: 0.5385\n",
      "Epoch 314/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0993 - accuracy: 0.5372 - val_loss: 1.0440 - val_accuracy: 0.5394\n",
      "Epoch 315/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1075 - accuracy: 0.5261 - val_loss: 1.0406 - val_accuracy: 0.5433\n",
      "Epoch 316/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1047 - accuracy: 0.5191 - val_loss: 1.0389 - val_accuracy: 0.5365\n",
      "Epoch 317/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1018 - accuracy: 0.5263 - val_loss: 1.0393 - val_accuracy: 0.5394\n",
      "Epoch 318/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0984 - accuracy: 0.5307 - val_loss: 1.0434 - val_accuracy: 0.5337\n",
      "Epoch 319/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0987 - accuracy: 0.5312 - val_loss: 1.0403 - val_accuracy: 0.5394\n",
      "Epoch 320/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1030 - accuracy: 0.5285 - val_loss: 1.0450 - val_accuracy: 0.5365\n",
      "Epoch 321/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1049 - accuracy: 0.5328 - val_loss: 1.0421 - val_accuracy: 0.5404\n",
      "Epoch 322/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0991 - accuracy: 0.5259 - val_loss: 1.0370 - val_accuracy: 0.5356\n",
      "Epoch 323/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1034 - accuracy: 0.5273 - val_loss: 1.0412 - val_accuracy: 0.5404\n",
      "Epoch 324/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0992 - accuracy: 0.5268 - val_loss: 1.0411 - val_accuracy: 0.5404\n",
      "Epoch 325/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1039 - accuracy: 0.5328 - val_loss: 1.0417 - val_accuracy: 0.5404\n",
      "Epoch 326/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0944 - accuracy: 0.5324 - val_loss: 1.0430 - val_accuracy: 0.5413\n",
      "Epoch 327/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1028 - accuracy: 0.5275 - val_loss: 1.0478 - val_accuracy: 0.5356\n",
      "Epoch 328/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1015 - accuracy: 0.5343 - val_loss: 1.0433 - val_accuracy: 0.5375\n",
      "Epoch 329/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1018 - accuracy: 0.5271 - val_loss: 1.0430 - val_accuracy: 0.5404\n",
      "Epoch 330/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0992 - accuracy: 0.5292 - val_loss: 1.0422 - val_accuracy: 0.5394\n",
      "Epoch 331/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1056 - accuracy: 0.5273 - val_loss: 1.0415 - val_accuracy: 0.5394\n",
      "Epoch 332/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1051 - accuracy: 0.5259 - val_loss: 1.0415 - val_accuracy: 0.5346\n",
      "Epoch 333/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1009 - accuracy: 0.5302 - val_loss: 1.0372 - val_accuracy: 0.5413\n",
      "Epoch 334/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0999 - accuracy: 0.5295 - val_loss: 1.0395 - val_accuracy: 0.5385\n",
      "Epoch 335/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1010 - accuracy: 0.5328 - val_loss: 1.0402 - val_accuracy: 0.5385\n",
      "Epoch 336/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0991 - accuracy: 0.5360 - val_loss: 1.0365 - val_accuracy: 0.5471\n",
      "Epoch 337/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0973 - accuracy: 0.5324 - val_loss: 1.0380 - val_accuracy: 0.5423\n",
      "Epoch 338/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1011 - accuracy: 0.5208 - val_loss: 1.0335 - val_accuracy: 0.5452\n",
      "Epoch 339/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0993 - accuracy: 0.5391 - val_loss: 1.0364 - val_accuracy: 0.5413\n",
      "Epoch 340/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0991 - accuracy: 0.5314 - val_loss: 1.0352 - val_accuracy: 0.5404\n",
      "Epoch 341/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1011 - accuracy: 0.5338 - val_loss: 1.0342 - val_accuracy: 0.5404\n",
      "Epoch 342/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0977 - accuracy: 0.5350 - val_loss: 1.0411 - val_accuracy: 0.5442\n",
      "Epoch 343/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1060 - accuracy: 0.5285 - val_loss: 1.0404 - val_accuracy: 0.5337\n",
      "Epoch 344/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0985 - accuracy: 0.5299 - val_loss: 1.0403 - val_accuracy: 0.5394\n",
      "Epoch 345/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1028 - accuracy: 0.5227 - val_loss: 1.0419 - val_accuracy: 0.5404\n",
      "Epoch 346/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0995 - accuracy: 0.5283 - val_loss: 1.0354 - val_accuracy: 0.5404\n",
      "Epoch 347/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0943 - accuracy: 0.5328 - val_loss: 1.0378 - val_accuracy: 0.5356\n",
      "Epoch 348/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0965 - accuracy: 0.5292 - val_loss: 1.0399 - val_accuracy: 0.5452\n",
      "Epoch 349/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0974 - accuracy: 0.5295 - val_loss: 1.0387 - val_accuracy: 0.5327\n",
      "Epoch 350/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0963 - accuracy: 0.5345 - val_loss: 1.0396 - val_accuracy: 0.5404\n",
      "Epoch 351/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1021 - accuracy: 0.5309 - val_loss: 1.0465 - val_accuracy: 0.5385\n",
      "Epoch 352/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0954 - accuracy: 0.5449 - val_loss: 1.0386 - val_accuracy: 0.5404\n",
      "Epoch 353/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0976 - accuracy: 0.5324 - val_loss: 1.0436 - val_accuracy: 0.5337\n",
      "Epoch 354/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0942 - accuracy: 0.5302 - val_loss: 1.0415 - val_accuracy: 0.5404\n",
      "Epoch 355/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0999 - accuracy: 0.5328 - val_loss: 1.0398 - val_accuracy: 0.5337\n",
      "Epoch 356/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1014 - accuracy: 0.5278 - val_loss: 1.0452 - val_accuracy: 0.5356\n",
      "Epoch 357/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0944 - accuracy: 0.5295 - val_loss: 1.0440 - val_accuracy: 0.5375\n",
      "Epoch 358/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0987 - accuracy: 0.5247 - val_loss: 1.0456 - val_accuracy: 0.5413\n",
      "Epoch 359/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0961 - accuracy: 0.5273 - val_loss: 1.0389 - val_accuracy: 0.5433\n",
      "Epoch 360/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0959 - accuracy: 0.5275 - val_loss: 1.0350 - val_accuracy: 0.5423\n",
      "Epoch 361/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0991 - accuracy: 0.5343 - val_loss: 1.0368 - val_accuracy: 0.5404\n",
      "Epoch 362/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1006 - accuracy: 0.5261 - val_loss: 1.0420 - val_accuracy: 0.5394\n",
      "Epoch 363/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0981 - accuracy: 0.5309 - val_loss: 1.0400 - val_accuracy: 0.5365\n",
      "Epoch 364/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0940 - accuracy: 0.5309 - val_loss: 1.0391 - val_accuracy: 0.5394\n",
      "Epoch 365/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0978 - accuracy: 0.5254 - val_loss: 1.0345 - val_accuracy: 0.5385\n",
      "Epoch 366/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0955 - accuracy: 0.5345 - val_loss: 1.0379 - val_accuracy: 0.5346\n",
      "Epoch 367/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0970 - accuracy: 0.5316 - val_loss: 1.0390 - val_accuracy: 0.5423\n",
      "Epoch 368/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0960 - accuracy: 0.5343 - val_loss: 1.0382 - val_accuracy: 0.5337\n",
      "Epoch 369/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0950 - accuracy: 0.5287 - val_loss: 1.0371 - val_accuracy: 0.5404\n",
      "Epoch 370/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0996 - accuracy: 0.5309 - val_loss: 1.0390 - val_accuracy: 0.5385\n",
      "Epoch 371/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1001 - accuracy: 0.5312 - val_loss: 1.0371 - val_accuracy: 0.5394\n",
      "Epoch 372/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0925 - accuracy: 0.5309 - val_loss: 1.0342 - val_accuracy: 0.5365\n",
      "Epoch 373/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0920 - accuracy: 0.5316 - val_loss: 1.0383 - val_accuracy: 0.5337\n",
      "Epoch 374/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1000 - accuracy: 0.5304 - val_loss: 1.0368 - val_accuracy: 0.5365\n",
      "Epoch 375/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0953 - accuracy: 0.5367 - val_loss: 1.0440 - val_accuracy: 0.5375\n",
      "Epoch 376/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0960 - accuracy: 0.5333 - val_loss: 1.0432 - val_accuracy: 0.5442\n",
      "Epoch 377/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0967 - accuracy: 0.5307 - val_loss: 1.0360 - val_accuracy: 0.5385\n",
      "Epoch 378/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1001 - accuracy: 0.5259 - val_loss: 1.0445 - val_accuracy: 0.5317\n",
      "Epoch 379/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0959 - accuracy: 0.5336 - val_loss: 1.0355 - val_accuracy: 0.5365\n",
      "Epoch 380/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0947 - accuracy: 0.5367 - val_loss: 1.0360 - val_accuracy: 0.5375\n",
      "Epoch 381/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0955 - accuracy: 0.5304 - val_loss: 1.0355 - val_accuracy: 0.5327\n",
      "Epoch 382/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0954 - accuracy: 0.5396 - val_loss: 1.0358 - val_accuracy: 0.5394\n",
      "Epoch 383/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0966 - accuracy: 0.5362 - val_loss: 1.0344 - val_accuracy: 0.5394\n",
      "Epoch 384/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1000 - accuracy: 0.5343 - val_loss: 1.0300 - val_accuracy: 0.5404\n",
      "Epoch 385/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0976 - accuracy: 0.5384 - val_loss: 1.0422 - val_accuracy: 0.5404\n",
      "Epoch 386/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0968 - accuracy: 0.5309 - val_loss: 1.0343 - val_accuracy: 0.5404\n",
      "Epoch 387/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0935 - accuracy: 0.5295 - val_loss: 1.0342 - val_accuracy: 0.5433\n",
      "Epoch 388/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0906 - accuracy: 0.5401 - val_loss: 1.0354 - val_accuracy: 0.5394\n",
      "Epoch 389/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0945 - accuracy: 0.5304 - val_loss: 1.0342 - val_accuracy: 0.5394\n",
      "Epoch 390/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1001 - accuracy: 0.5384 - val_loss: 1.0349 - val_accuracy: 0.5423\n",
      "Epoch 391/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0965 - accuracy: 0.5408 - val_loss: 1.0384 - val_accuracy: 0.5356\n",
      "Epoch 392/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0965 - accuracy: 0.5367 - val_loss: 1.0381 - val_accuracy: 0.5346\n",
      "Epoch 393/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0978 - accuracy: 0.5251 - val_loss: 1.0377 - val_accuracy: 0.5462\n",
      "Epoch 394/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0978 - accuracy: 0.5328 - val_loss: 1.0340 - val_accuracy: 0.5404\n",
      "Epoch 395/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0912 - accuracy: 0.5316 - val_loss: 1.0352 - val_accuracy: 0.5375\n",
      "Epoch 396/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0943 - accuracy: 0.5297 - val_loss: 1.0312 - val_accuracy: 0.5471\n",
      "Epoch 397/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0922 - accuracy: 0.5338 - val_loss: 1.0375 - val_accuracy: 0.5385\n",
      "Epoch 398/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0943 - accuracy: 0.5312 - val_loss: 1.0372 - val_accuracy: 0.5442\n",
      "Epoch 399/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0918 - accuracy: 0.5350 - val_loss: 1.0404 - val_accuracy: 0.5423\n",
      "Epoch 400/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0895 - accuracy: 0.5389 - val_loss: 1.0361 - val_accuracy: 0.5346\n",
      "Epoch 401/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0943 - accuracy: 0.5302 - val_loss: 1.0356 - val_accuracy: 0.5413\n",
      "Epoch 402/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0911 - accuracy: 0.5292 - val_loss: 1.0359 - val_accuracy: 0.5423\n",
      "Epoch 403/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0911 - accuracy: 0.5374 - val_loss: 1.0369 - val_accuracy: 0.5452\n",
      "Epoch 404/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0927 - accuracy: 0.5432 - val_loss: 1.0432 - val_accuracy: 0.5394\n",
      "Epoch 405/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0913 - accuracy: 0.5352 - val_loss: 1.0410 - val_accuracy: 0.5394\n",
      "Epoch 406/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0915 - accuracy: 0.5340 - val_loss: 1.0376 - val_accuracy: 0.5519\n",
      "Epoch 407/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0968 - accuracy: 0.5328 - val_loss: 1.0323 - val_accuracy: 0.5471\n",
      "Epoch 408/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0956 - accuracy: 0.5244 - val_loss: 1.0356 - val_accuracy: 0.5327\n",
      "Epoch 409/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1021 - accuracy: 0.5314 - val_loss: 1.0388 - val_accuracy: 0.5452\n",
      "Epoch 410/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0961 - accuracy: 0.5372 - val_loss: 1.0410 - val_accuracy: 0.5375\n",
      "Epoch 411/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1016 - accuracy: 0.5285 - val_loss: 1.0373 - val_accuracy: 0.5433\n",
      "Epoch 412/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0916 - accuracy: 0.5321 - val_loss: 1.0360 - val_accuracy: 0.5413\n",
      "Epoch 413/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0940 - accuracy: 0.5352 - val_loss: 1.0331 - val_accuracy: 0.5423\n",
      "Epoch 414/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0915 - accuracy: 0.5364 - val_loss: 1.0319 - val_accuracy: 0.5365\n",
      "Epoch 415/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0890 - accuracy: 0.5328 - val_loss: 1.0325 - val_accuracy: 0.5442\n",
      "Epoch 416/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0896 - accuracy: 0.5360 - val_loss: 1.0411 - val_accuracy: 0.5433\n",
      "Epoch 417/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0904 - accuracy: 0.5319 - val_loss: 1.0374 - val_accuracy: 0.5413\n",
      "Epoch 418/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0909 - accuracy: 0.5321 - val_loss: 1.0385 - val_accuracy: 0.5346\n",
      "Epoch 419/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0933 - accuracy: 0.5314 - val_loss: 1.0347 - val_accuracy: 0.5346\n",
      "Epoch 420/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0907 - accuracy: 0.5254 - val_loss: 1.0326 - val_accuracy: 0.5471\n",
      "Epoch 421/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0912 - accuracy: 0.5292 - val_loss: 1.0353 - val_accuracy: 0.5394\n",
      "Epoch 422/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0938 - accuracy: 0.5352 - val_loss: 1.0336 - val_accuracy: 0.5423\n",
      "Epoch 423/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0917 - accuracy: 0.5355 - val_loss: 1.0343 - val_accuracy: 0.5462\n",
      "Epoch 424/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0917 - accuracy: 0.5283 - val_loss: 1.0346 - val_accuracy: 0.5394\n",
      "Epoch 425/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0908 - accuracy: 0.5287 - val_loss: 1.0346 - val_accuracy: 0.5433\n",
      "Epoch 426/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0902 - accuracy: 0.5321 - val_loss: 1.0357 - val_accuracy: 0.5452\n",
      "Epoch 427/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0907 - accuracy: 0.5336 - val_loss: 1.0396 - val_accuracy: 0.5490\n",
      "Epoch 428/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0939 - accuracy: 0.5328 - val_loss: 1.0416 - val_accuracy: 0.5452\n",
      "Epoch 429/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0928 - accuracy: 0.5290 - val_loss: 1.0367 - val_accuracy: 0.5452\n",
      "Epoch 430/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0881 - accuracy: 0.5324 - val_loss: 1.0360 - val_accuracy: 0.5452\n",
      "Epoch 431/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0877 - accuracy: 0.5304 - val_loss: 1.0373 - val_accuracy: 0.5462\n",
      "Epoch 432/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0860 - accuracy: 0.5381 - val_loss: 1.0401 - val_accuracy: 0.5442\n",
      "Epoch 433/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0907 - accuracy: 0.5302 - val_loss: 1.0330 - val_accuracy: 0.5510\n",
      "Epoch 434/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0897 - accuracy: 0.5393 - val_loss: 1.0373 - val_accuracy: 0.5433\n",
      "Epoch 435/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1008 - accuracy: 0.5268 - val_loss: 1.0341 - val_accuracy: 0.5462\n",
      "Epoch 436/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0893 - accuracy: 0.5343 - val_loss: 1.0390 - val_accuracy: 0.5500\n",
      "Epoch 437/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0899 - accuracy: 0.5372 - val_loss: 1.0370 - val_accuracy: 0.5490\n",
      "Epoch 438/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0930 - accuracy: 0.5340 - val_loss: 1.0325 - val_accuracy: 0.5452\n",
      "Epoch 439/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0891 - accuracy: 0.5324 - val_loss: 1.0357 - val_accuracy: 0.5500\n",
      "Epoch 440/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0889 - accuracy: 0.5336 - val_loss: 1.0355 - val_accuracy: 0.5404\n",
      "Epoch 441/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0920 - accuracy: 0.5372 - val_loss: 1.0382 - val_accuracy: 0.5500\n",
      "Epoch 442/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0914 - accuracy: 0.5292 - val_loss: 1.0360 - val_accuracy: 0.5413\n",
      "Epoch 443/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0893 - accuracy: 0.5362 - val_loss: 1.0357 - val_accuracy: 0.5433\n",
      "Epoch 444/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0899 - accuracy: 0.5312 - val_loss: 1.0382 - val_accuracy: 0.5385\n",
      "Epoch 445/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0873 - accuracy: 0.5408 - val_loss: 1.0337 - val_accuracy: 0.5452\n",
      "Epoch 446/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0906 - accuracy: 0.5355 - val_loss: 1.0318 - val_accuracy: 0.5442\n",
      "Epoch 447/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0896 - accuracy: 0.5319 - val_loss: 1.0309 - val_accuracy: 0.5452\n",
      "Epoch 448/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0851 - accuracy: 0.5372 - val_loss: 1.0358 - val_accuracy: 0.5452\n",
      "Epoch 449/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0884 - accuracy: 0.5367 - val_loss: 1.0364 - val_accuracy: 0.5356\n",
      "Epoch 450/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0920 - accuracy: 0.5328 - val_loss: 1.0339 - val_accuracy: 0.5471\n",
      "Epoch 451/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0837 - accuracy: 0.5319 - val_loss: 1.0346 - val_accuracy: 0.5423\n",
      "Epoch 452/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0884 - accuracy: 0.5319 - val_loss: 1.0312 - val_accuracy: 0.5481\n",
      "Epoch 453/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0885 - accuracy: 0.5350 - val_loss: 1.0312 - val_accuracy: 0.5404\n",
      "Epoch 454/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0907 - accuracy: 0.5328 - val_loss: 1.0312 - val_accuracy: 0.5433\n",
      "Epoch 455/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0876 - accuracy: 0.5331 - val_loss: 1.0341 - val_accuracy: 0.5433\n",
      "Epoch 456/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0907 - accuracy: 0.5328 - val_loss: 1.0331 - val_accuracy: 0.5385\n",
      "Epoch 457/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0910 - accuracy: 0.5345 - val_loss: 1.0323 - val_accuracy: 0.5452\n",
      "Epoch 458/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0872 - accuracy: 0.5389 - val_loss: 1.0363 - val_accuracy: 0.5433\n",
      "Epoch 459/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0871 - accuracy: 0.5355 - val_loss: 1.0365 - val_accuracy: 0.5433\n",
      "Epoch 460/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0852 - accuracy: 0.5376 - val_loss: 1.0374 - val_accuracy: 0.5413\n",
      "Epoch 461/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0883 - accuracy: 0.5307 - val_loss: 1.0358 - val_accuracy: 0.5452\n",
      "Epoch 462/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0880 - accuracy: 0.5350 - val_loss: 1.0289 - val_accuracy: 0.5413\n",
      "Epoch 463/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0872 - accuracy: 0.5278 - val_loss: 1.0371 - val_accuracy: 0.5471\n",
      "Epoch 464/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0875 - accuracy: 0.5316 - val_loss: 1.0412 - val_accuracy: 0.5510\n",
      "Epoch 465/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0881 - accuracy: 0.5340 - val_loss: 1.0357 - val_accuracy: 0.5423\n",
      "Epoch 466/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0908 - accuracy: 0.5287 - val_loss: 1.0319 - val_accuracy: 0.5385\n",
      "Epoch 467/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0857 - accuracy: 0.5336 - val_loss: 1.0354 - val_accuracy: 0.5433\n",
      "Epoch 468/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0846 - accuracy: 0.5376 - val_loss: 1.0316 - val_accuracy: 0.5471\n",
      "Epoch 469/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0823 - accuracy: 0.5352 - val_loss: 1.0338 - val_accuracy: 0.5462\n",
      "Epoch 470/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0934 - accuracy: 0.5324 - val_loss: 1.0350 - val_accuracy: 0.5529\n",
      "Epoch 471/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0850 - accuracy: 0.5333 - val_loss: 1.0288 - val_accuracy: 0.5385\n",
      "Epoch 472/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0885 - accuracy: 0.5292 - val_loss: 1.0293 - val_accuracy: 0.5442\n",
      "Epoch 473/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0892 - accuracy: 0.5343 - val_loss: 1.0334 - val_accuracy: 0.5471\n",
      "Epoch 474/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0870 - accuracy: 0.5360 - val_loss: 1.0299 - val_accuracy: 0.5442\n",
      "Epoch 475/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0862 - accuracy: 0.5348 - val_loss: 1.0373 - val_accuracy: 0.5442\n",
      "Epoch 476/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0851 - accuracy: 0.5386 - val_loss: 1.0370 - val_accuracy: 0.5413\n",
      "Epoch 477/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0889 - accuracy: 0.5367 - val_loss: 1.0296 - val_accuracy: 0.5404\n",
      "Epoch 478/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0850 - accuracy: 0.5415 - val_loss: 1.0387 - val_accuracy: 0.5490\n",
      "Epoch 479/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0891 - accuracy: 0.5336 - val_loss: 1.0305 - val_accuracy: 0.5442\n",
      "Epoch 480/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0898 - accuracy: 0.5302 - val_loss: 1.0328 - val_accuracy: 0.5452\n",
      "Epoch 481/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0889 - accuracy: 0.5350 - val_loss: 1.0348 - val_accuracy: 0.5413\n",
      "Epoch 482/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0907 - accuracy: 0.5345 - val_loss: 1.0343 - val_accuracy: 0.5490\n",
      "Epoch 483/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0927 - accuracy: 0.5312 - val_loss: 1.0315 - val_accuracy: 0.5413\n",
      "Epoch 484/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0875 - accuracy: 0.5352 - val_loss: 1.0325 - val_accuracy: 0.5394\n",
      "Epoch 485/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0833 - accuracy: 0.5410 - val_loss: 1.0346 - val_accuracy: 0.5413\n",
      "Epoch 486/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0801 - accuracy: 0.5348 - val_loss: 1.0300 - val_accuracy: 0.5375\n",
      "Epoch 487/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0858 - accuracy: 0.5343 - val_loss: 1.0304 - val_accuracy: 0.5452\n",
      "Epoch 488/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0814 - accuracy: 0.5362 - val_loss: 1.0340 - val_accuracy: 0.5452\n",
      "Epoch 489/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0866 - accuracy: 0.5295 - val_loss: 1.0351 - val_accuracy: 0.5471\n",
      "Epoch 490/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0802 - accuracy: 0.5386 - val_loss: 1.0311 - val_accuracy: 0.5452\n",
      "Epoch 491/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0882 - accuracy: 0.5316 - val_loss: 1.0295 - val_accuracy: 0.5423\n",
      "Epoch 492/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0883 - accuracy: 0.5299 - val_loss: 1.0327 - val_accuracy: 0.5433\n",
      "Epoch 493/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0876 - accuracy: 0.5321 - val_loss: 1.0309 - val_accuracy: 0.5423\n",
      "Epoch 494/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0857 - accuracy: 0.5417 - val_loss: 1.0316 - val_accuracy: 0.5433\n",
      "Epoch 495/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0824 - accuracy: 0.5357 - val_loss: 1.0357 - val_accuracy: 0.5490\n",
      "Epoch 496/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0869 - accuracy: 0.5319 - val_loss: 1.0306 - val_accuracy: 0.5394\n",
      "Epoch 497/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0823 - accuracy: 0.5376 - val_loss: 1.0351 - val_accuracy: 0.5433\n",
      "Epoch 498/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0904 - accuracy: 0.5348 - val_loss: 1.0337 - val_accuracy: 0.5481\n",
      "Epoch 499/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0873 - accuracy: 0.5287 - val_loss: 1.0325 - val_accuracy: 0.5413\n",
      "Epoch 500/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0837 - accuracy: 0.5403 - val_loss: 1.0313 - val_accuracy: 0.5375\n",
      "Epoch 501/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0836 - accuracy: 0.5350 - val_loss: 1.0393 - val_accuracy: 0.5423\n",
      "Epoch 502/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0863 - accuracy: 0.5314 - val_loss: 1.0340 - val_accuracy: 0.5433\n",
      "Epoch 503/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0837 - accuracy: 0.5401 - val_loss: 1.0321 - val_accuracy: 0.5394\n",
      "Epoch 504/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0834 - accuracy: 0.5381 - val_loss: 1.0342 - val_accuracy: 0.5423\n",
      "Epoch 505/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0885 - accuracy: 0.5367 - val_loss: 1.0325 - val_accuracy: 0.5462\n",
      "Epoch 506/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0847 - accuracy: 0.5304 - val_loss: 1.0349 - val_accuracy: 0.5385\n",
      "Epoch 507/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0881 - accuracy: 0.5376 - val_loss: 1.0312 - val_accuracy: 0.5413\n",
      "Epoch 508/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0846 - accuracy: 0.5379 - val_loss: 1.0478 - val_accuracy: 0.5442\n",
      "Epoch 509/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0889 - accuracy: 0.5307 - val_loss: 1.0370 - val_accuracy: 0.5404\n",
      "Epoch 510/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0898 - accuracy: 0.5312 - val_loss: 1.0422 - val_accuracy: 0.5510\n",
      "Epoch 511/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0841 - accuracy: 0.5439 - val_loss: 1.0382 - val_accuracy: 0.5442\n",
      "Epoch 512/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0835 - accuracy: 0.5376 - val_loss: 1.0348 - val_accuracy: 0.5404\n",
      "Epoch 513/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0862 - accuracy: 0.5357 - val_loss: 1.0370 - val_accuracy: 0.5413\n",
      "Epoch 514/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0853 - accuracy: 0.5367 - val_loss: 1.0343 - val_accuracy: 0.5471\n",
      "Epoch 515/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0883 - accuracy: 0.5357 - val_loss: 1.0349 - val_accuracy: 0.5433\n",
      "Epoch 516/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0886 - accuracy: 0.5316 - val_loss: 1.0334 - val_accuracy: 0.5462\n",
      "Epoch 517/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0900 - accuracy: 0.5393 - val_loss: 1.0380 - val_accuracy: 0.5500\n",
      "Epoch 518/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0858 - accuracy: 0.5348 - val_loss: 1.0331 - val_accuracy: 0.5452\n",
      "Epoch 519/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0850 - accuracy: 0.5364 - val_loss: 1.0341 - val_accuracy: 0.5519\n",
      "Epoch 520/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0860 - accuracy: 0.5343 - val_loss: 1.0345 - val_accuracy: 0.5385\n",
      "Epoch 521/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0923 - accuracy: 0.5314 - val_loss: 1.0293 - val_accuracy: 0.5462\n",
      "Epoch 522/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0815 - accuracy: 0.5348 - val_loss: 1.0295 - val_accuracy: 0.5413\n",
      "Epoch 523/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0885 - accuracy: 0.5362 - val_loss: 1.0350 - val_accuracy: 0.5500\n",
      "Epoch 524/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0838 - accuracy: 0.5367 - val_loss: 1.0448 - val_accuracy: 0.5538\n",
      "Epoch 525/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0836 - accuracy: 0.5364 - val_loss: 1.0349 - val_accuracy: 0.5385\n",
      "Epoch 526/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0847 - accuracy: 0.5331 - val_loss: 1.0318 - val_accuracy: 0.5404\n",
      "Epoch 527/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0858 - accuracy: 0.5307 - val_loss: 1.0331 - val_accuracy: 0.5500\n",
      "Epoch 528/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0844 - accuracy: 0.5389 - val_loss: 1.0362 - val_accuracy: 0.5385\n",
      "Epoch 529/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0859 - accuracy: 0.5408 - val_loss: 1.0324 - val_accuracy: 0.5404\n",
      "Epoch 530/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0821 - accuracy: 0.5372 - val_loss: 1.0336 - val_accuracy: 0.5413\n",
      "Epoch 531/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0847 - accuracy: 0.5319 - val_loss: 1.0395 - val_accuracy: 0.5346\n",
      "Epoch 532/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0829 - accuracy: 0.5398 - val_loss: 1.0412 - val_accuracy: 0.5365\n",
      "Epoch 533/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0794 - accuracy: 0.5441 - val_loss: 1.0411 - val_accuracy: 0.5385\n",
      "Epoch 534/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0849 - accuracy: 0.5398 - val_loss: 1.0504 - val_accuracy: 0.5356\n",
      "Epoch 535/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0843 - accuracy: 0.5357 - val_loss: 1.0318 - val_accuracy: 0.5433\n",
      "Epoch 536/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0820 - accuracy: 0.5384 - val_loss: 1.0344 - val_accuracy: 0.5442\n",
      "Epoch 537/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0816 - accuracy: 0.5328 - val_loss: 1.0385 - val_accuracy: 0.5404\n",
      "Epoch 538/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0852 - accuracy: 0.5441 - val_loss: 1.0368 - val_accuracy: 0.5442\n",
      "Epoch 539/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0865 - accuracy: 0.5312 - val_loss: 1.0350 - val_accuracy: 0.5394\n",
      "Epoch 540/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0810 - accuracy: 0.5379 - val_loss: 1.0345 - val_accuracy: 0.5413\n",
      "Epoch 541/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0785 - accuracy: 0.5343 - val_loss: 1.0406 - val_accuracy: 0.5462\n",
      "Epoch 542/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0854 - accuracy: 0.5413 - val_loss: 1.0351 - val_accuracy: 0.5442\n",
      "Epoch 543/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0820 - accuracy: 0.5393 - val_loss: 1.0361 - val_accuracy: 0.5442\n",
      "Epoch 544/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0878 - accuracy: 0.5350 - val_loss: 1.0338 - val_accuracy: 0.5433\n",
      "Epoch 545/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0874 - accuracy: 0.5376 - val_loss: 1.0340 - val_accuracy: 0.5452\n",
      "Epoch 546/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0838 - accuracy: 0.5348 - val_loss: 1.0357 - val_accuracy: 0.5423\n",
      "Epoch 547/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0855 - accuracy: 0.5384 - val_loss: 1.0358 - val_accuracy: 0.5413\n",
      "Epoch 548/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0839 - accuracy: 0.5381 - val_loss: 1.0337 - val_accuracy: 0.5442\n",
      "Epoch 549/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0818 - accuracy: 0.5381 - val_loss: 1.0373 - val_accuracy: 0.5413\n",
      "Epoch 550/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0836 - accuracy: 0.5360 - val_loss: 1.0407 - val_accuracy: 0.5433\n",
      "Epoch 551/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0832 - accuracy: 0.5307 - val_loss: 1.0298 - val_accuracy: 0.5442\n",
      "Epoch 552/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0811 - accuracy: 0.5376 - val_loss: 1.0382 - val_accuracy: 0.5365\n",
      "Epoch 553/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0818 - accuracy: 0.5384 - val_loss: 1.0398 - val_accuracy: 0.5365\n",
      "Epoch 554/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0847 - accuracy: 0.5287 - val_loss: 1.0350 - val_accuracy: 0.5423\n",
      "Epoch 555/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0827 - accuracy: 0.5355 - val_loss: 1.0368 - val_accuracy: 0.5394\n",
      "Epoch 556/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0818 - accuracy: 0.5422 - val_loss: 1.0349 - val_accuracy: 0.5413\n",
      "Epoch 557/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0819 - accuracy: 0.5386 - val_loss: 1.0413 - val_accuracy: 0.5471\n",
      "Epoch 558/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0830 - accuracy: 0.5352 - val_loss: 1.0358 - val_accuracy: 0.5413\n",
      "Epoch 559/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0828 - accuracy: 0.5338 - val_loss: 1.0443 - val_accuracy: 0.5462\n",
      "Epoch 560/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0811 - accuracy: 0.5350 - val_loss: 1.0366 - val_accuracy: 0.5423\n",
      "Epoch 561/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0807 - accuracy: 0.5427 - val_loss: 1.0418 - val_accuracy: 0.5423\n",
      "Epoch 562/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0805 - accuracy: 0.5415 - val_loss: 1.0323 - val_accuracy: 0.5442\n",
      "Epoch 563/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0856 - accuracy: 0.5336 - val_loss: 1.0330 - val_accuracy: 0.5452\n",
      "Epoch 564/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0809 - accuracy: 0.5355 - val_loss: 1.0322 - val_accuracy: 0.5385\n",
      "Epoch 565/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0753 - accuracy: 0.5391 - val_loss: 1.0385 - val_accuracy: 0.5442\n",
      "Epoch 566/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0795 - accuracy: 0.5360 - val_loss: 1.0352 - val_accuracy: 0.5423\n",
      "Epoch 567/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0759 - accuracy: 0.5355 - val_loss: 1.0469 - val_accuracy: 0.5394\n",
      "Epoch 568/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0852 - accuracy: 0.5312 - val_loss: 1.0367 - val_accuracy: 0.5394\n",
      "Epoch 569/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0839 - accuracy: 0.5343 - val_loss: 1.0308 - val_accuracy: 0.5433\n",
      "Epoch 570/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0833 - accuracy: 0.5275 - val_loss: 1.0335 - val_accuracy: 0.5365\n",
      "Epoch 571/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0844 - accuracy: 0.5328 - val_loss: 1.0327 - val_accuracy: 0.5452\n",
      "Epoch 572/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0808 - accuracy: 0.5352 - val_loss: 1.0393 - val_accuracy: 0.5365\n",
      "Epoch 573/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0825 - accuracy: 0.5340 - val_loss: 1.0387 - val_accuracy: 0.5452\n",
      "Epoch 574/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0827 - accuracy: 0.5338 - val_loss: 1.0311 - val_accuracy: 0.5452\n",
      "Epoch 575/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0837 - accuracy: 0.5372 - val_loss: 1.0366 - val_accuracy: 0.5365\n",
      "Epoch 576/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0801 - accuracy: 0.5357 - val_loss: 1.0349 - val_accuracy: 0.5433\n",
      "Epoch 577/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0796 - accuracy: 0.5439 - val_loss: 1.0339 - val_accuracy: 0.5433\n",
      "Epoch 578/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0769 - accuracy: 0.5405 - val_loss: 1.0368 - val_accuracy: 0.5490\n",
      "Epoch 579/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0822 - accuracy: 0.5360 - val_loss: 1.0411 - val_accuracy: 0.5404\n",
      "Epoch 580/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0841 - accuracy: 0.5372 - val_loss: 1.0347 - val_accuracy: 0.5404\n",
      "Epoch 581/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0794 - accuracy: 0.5413 - val_loss: 1.0364 - val_accuracy: 0.5442\n",
      "Epoch 582/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0820 - accuracy: 0.5338 - val_loss: 1.0342 - val_accuracy: 0.5394\n",
      "Epoch 583/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0823 - accuracy: 0.5415 - val_loss: 1.0298 - val_accuracy: 0.5442\n",
      "Epoch 584/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0803 - accuracy: 0.5405 - val_loss: 1.0351 - val_accuracy: 0.5394\n",
      "Epoch 585/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0830 - accuracy: 0.5393 - val_loss: 1.0345 - val_accuracy: 0.5423\n",
      "Epoch 586/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0800 - accuracy: 0.5364 - val_loss: 1.0370 - val_accuracy: 0.5413\n",
      "Epoch 587/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0831 - accuracy: 0.5348 - val_loss: 1.0404 - val_accuracy: 0.5346\n",
      "Epoch 588/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0860 - accuracy: 0.5360 - val_loss: 1.0353 - val_accuracy: 0.5442\n",
      "Epoch 589/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0832 - accuracy: 0.5292 - val_loss: 1.0349 - val_accuracy: 0.5452\n",
      "Epoch 590/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0820 - accuracy: 0.5439 - val_loss: 1.0312 - val_accuracy: 0.5471\n",
      "Epoch 591/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0805 - accuracy: 0.5384 - val_loss: 1.0390 - val_accuracy: 0.5481\n",
      "Epoch 592/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0779 - accuracy: 0.5398 - val_loss: 1.0327 - val_accuracy: 0.5433\n",
      "Epoch 593/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0760 - accuracy: 0.5415 - val_loss: 1.0415 - val_accuracy: 0.5365\n",
      "Epoch 594/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0788 - accuracy: 0.5374 - val_loss: 1.0368 - val_accuracy: 0.5404\n",
      "Epoch 595/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0811 - accuracy: 0.5389 - val_loss: 1.0375 - val_accuracy: 0.5413\n",
      "Epoch 596/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0806 - accuracy: 0.5355 - val_loss: 1.0345 - val_accuracy: 0.5413\n",
      "Epoch 597/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0762 - accuracy: 0.5441 - val_loss: 1.0394 - val_accuracy: 0.5404\n",
      "Epoch 598/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0775 - accuracy: 0.5432 - val_loss: 1.0422 - val_accuracy: 0.5375\n",
      "Epoch 599/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0798 - accuracy: 0.5326 - val_loss: 1.0386 - val_accuracy: 0.5346\n",
      "Epoch 600/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0810 - accuracy: 0.5343 - val_loss: 1.0360 - val_accuracy: 0.5346\n",
      "Epoch 601/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0807 - accuracy: 0.5403 - val_loss: 1.0380 - val_accuracy: 0.5394\n",
      "Epoch 602/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0824 - accuracy: 0.5355 - val_loss: 1.0365 - val_accuracy: 0.5404\n",
      "Epoch 603/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0814 - accuracy: 0.5381 - val_loss: 1.0342 - val_accuracy: 0.5365\n",
      "Epoch 604/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0794 - accuracy: 0.5376 - val_loss: 1.0439 - val_accuracy: 0.5413\n",
      "Epoch 605/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0807 - accuracy: 0.5374 - val_loss: 1.0361 - val_accuracy: 0.5452\n",
      "Epoch 606/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0782 - accuracy: 0.5379 - val_loss: 1.0350 - val_accuracy: 0.5442\n",
      "Epoch 607/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0823 - accuracy: 0.5352 - val_loss: 1.0352 - val_accuracy: 0.5490\n",
      "Epoch 608/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0806 - accuracy: 0.5389 - val_loss: 1.0354 - val_accuracy: 0.5413\n",
      "Epoch 609/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0787 - accuracy: 0.5417 - val_loss: 1.0393 - val_accuracy: 0.5385\n",
      "Epoch 610/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0809 - accuracy: 0.5379 - val_loss: 1.0352 - val_accuracy: 0.5423\n",
      "Epoch 611/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0798 - accuracy: 0.5401 - val_loss: 1.0396 - val_accuracy: 0.5462\n",
      "Epoch 612/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0787 - accuracy: 0.5379 - val_loss: 1.0389 - val_accuracy: 0.5423\n",
      "Epoch 613/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0769 - accuracy: 0.5410 - val_loss: 1.0347 - val_accuracy: 0.5394\n",
      "Epoch 614/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0803 - accuracy: 0.5403 - val_loss: 1.0404 - val_accuracy: 0.5375\n",
      "Epoch 615/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0792 - accuracy: 0.5345 - val_loss: 1.0332 - val_accuracy: 0.5452\n",
      "Epoch 616/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0786 - accuracy: 0.5408 - val_loss: 1.0337 - val_accuracy: 0.5442\n",
      "Epoch 617/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0747 - accuracy: 0.5376 - val_loss: 1.0340 - val_accuracy: 0.5413\n",
      "Epoch 618/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0825 - accuracy: 0.5410 - val_loss: 1.0319 - val_accuracy: 0.5404\n",
      "Epoch 619/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0818 - accuracy: 0.5386 - val_loss: 1.0306 - val_accuracy: 0.5471\n",
      "Epoch 620/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0753 - accuracy: 0.5437 - val_loss: 1.0388 - val_accuracy: 0.5413\n",
      "Epoch 621/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0776 - accuracy: 0.5348 - val_loss: 1.0440 - val_accuracy: 0.5394\n",
      "Epoch 622/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0853 - accuracy: 0.5379 - val_loss: 1.0346 - val_accuracy: 0.5404\n",
      "Epoch 623/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0876 - accuracy: 0.5338 - val_loss: 1.0363 - val_accuracy: 0.5452\n",
      "Epoch 624/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0804 - accuracy: 0.5422 - val_loss: 1.0360 - val_accuracy: 0.5413\n",
      "Epoch 625/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0792 - accuracy: 0.5328 - val_loss: 1.0391 - val_accuracy: 0.5356\n",
      "Epoch 626/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0814 - accuracy: 0.5444 - val_loss: 1.0376 - val_accuracy: 0.5471\n",
      "Epoch 627/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0780 - accuracy: 0.5393 - val_loss: 1.0399 - val_accuracy: 0.5433\n",
      "Epoch 628/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0791 - accuracy: 0.5401 - val_loss: 1.0364 - val_accuracy: 0.5423\n",
      "Epoch 629/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0792 - accuracy: 0.5408 - val_loss: 1.0389 - val_accuracy: 0.5375\n",
      "Epoch 630/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0833 - accuracy: 0.5398 - val_loss: 1.0324 - val_accuracy: 0.5375\n",
      "Epoch 631/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0811 - accuracy: 0.5343 - val_loss: 1.0320 - val_accuracy: 0.5385\n",
      "Epoch 632/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0775 - accuracy: 0.5398 - val_loss: 1.0327 - val_accuracy: 0.5337\n",
      "Epoch 633/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0798 - accuracy: 0.5309 - val_loss: 1.0344 - val_accuracy: 0.5375\n",
      "Epoch 634/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0819 - accuracy: 0.5408 - val_loss: 1.0354 - val_accuracy: 0.5385\n",
      "Epoch 635/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0794 - accuracy: 0.5362 - val_loss: 1.0369 - val_accuracy: 0.5394\n",
      "Epoch 636/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0758 - accuracy: 0.5360 - val_loss: 1.0312 - val_accuracy: 0.5385\n",
      "Epoch 637/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0809 - accuracy: 0.5434 - val_loss: 1.0329 - val_accuracy: 0.5471\n",
      "Epoch 638/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0806 - accuracy: 0.5439 - val_loss: 1.0294 - val_accuracy: 0.5471\n",
      "Epoch 639/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0787 - accuracy: 0.5439 - val_loss: 1.0359 - val_accuracy: 0.5433\n",
      "Epoch 640/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0753 - accuracy: 0.5458 - val_loss: 1.0382 - val_accuracy: 0.5337\n",
      "Epoch 641/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0863 - accuracy: 0.5271 - val_loss: 1.0363 - val_accuracy: 0.5423\n",
      "Epoch 642/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0756 - accuracy: 0.5386 - val_loss: 1.0362 - val_accuracy: 0.5394\n",
      "Epoch 643/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0807 - accuracy: 0.5381 - val_loss: 1.0383 - val_accuracy: 0.5481\n",
      "Epoch 644/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0846 - accuracy: 0.5350 - val_loss: 1.0350 - val_accuracy: 0.5375\n",
      "Epoch 645/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0770 - accuracy: 0.5427 - val_loss: 1.0384 - val_accuracy: 0.5375\n",
      "Epoch 646/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0777 - accuracy: 0.5465 - val_loss: 1.0387 - val_accuracy: 0.5423\n",
      "Epoch 647/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0769 - accuracy: 0.5379 - val_loss: 1.0308 - val_accuracy: 0.5500\n",
      "Epoch 648/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0789 - accuracy: 0.5417 - val_loss: 1.0349 - val_accuracy: 0.5385\n",
      "Epoch 649/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0832 - accuracy: 0.5374 - val_loss: 1.0354 - val_accuracy: 0.5404\n",
      "Epoch 650/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0762 - accuracy: 0.5456 - val_loss: 1.0346 - val_accuracy: 0.5423\n",
      "Epoch 651/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0796 - accuracy: 0.5355 - val_loss: 1.0337 - val_accuracy: 0.5490\n",
      "Epoch 652/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0750 - accuracy: 0.5410 - val_loss: 1.0350 - val_accuracy: 0.5442\n",
      "Epoch 653/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0759 - accuracy: 0.5352 - val_loss: 1.0319 - val_accuracy: 0.5452\n",
      "Epoch 654/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0805 - accuracy: 0.5372 - val_loss: 1.0404 - val_accuracy: 0.5375\n",
      "Epoch 655/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0755 - accuracy: 0.5441 - val_loss: 1.0319 - val_accuracy: 0.5433\n",
      "Epoch 656/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0744 - accuracy: 0.5458 - val_loss: 1.0368 - val_accuracy: 0.5346\n",
      "Epoch 657/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0833 - accuracy: 0.5434 - val_loss: 1.0303 - val_accuracy: 0.5452\n",
      "Epoch 658/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0727 - accuracy: 0.5463 - val_loss: 1.0420 - val_accuracy: 0.5394\n",
      "Epoch 659/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0764 - accuracy: 0.5386 - val_loss: 1.0338 - val_accuracy: 0.5385\n",
      "Epoch 660/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0777 - accuracy: 0.5417 - val_loss: 1.0322 - val_accuracy: 0.5365\n",
      "Epoch 661/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0786 - accuracy: 0.5372 - val_loss: 1.0324 - val_accuracy: 0.5423\n",
      "Epoch 662/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0732 - accuracy: 0.5360 - val_loss: 1.0389 - val_accuracy: 0.5462\n",
      "Epoch 663/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0782 - accuracy: 0.5434 - val_loss: 1.0365 - val_accuracy: 0.5346\n",
      "Epoch 664/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0774 - accuracy: 0.5369 - val_loss: 1.0314 - val_accuracy: 0.5471\n",
      "Epoch 665/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0771 - accuracy: 0.5415 - val_loss: 1.0355 - val_accuracy: 0.5433\n",
      "Epoch 666/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0719 - accuracy: 0.5422 - val_loss: 1.0400 - val_accuracy: 0.5346\n",
      "Epoch 667/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0815 - accuracy: 0.5360 - val_loss: 1.0354 - val_accuracy: 0.5365\n",
      "Epoch 668/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0833 - accuracy: 0.5340 - val_loss: 1.0360 - val_accuracy: 0.5394\n",
      "Epoch 669/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0810 - accuracy: 0.5336 - val_loss: 1.0363 - val_accuracy: 0.5365\n",
      "Epoch 670/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0771 - accuracy: 0.5369 - val_loss: 1.0360 - val_accuracy: 0.5462\n",
      "Epoch 671/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0763 - accuracy: 0.5427 - val_loss: 1.0294 - val_accuracy: 0.5462\n",
      "Epoch 672/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0788 - accuracy: 0.5324 - val_loss: 1.0312 - val_accuracy: 0.5481\n",
      "Epoch 673/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0737 - accuracy: 0.5422 - val_loss: 1.0373 - val_accuracy: 0.5442\n",
      "Epoch 674/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0785 - accuracy: 0.5379 - val_loss: 1.0387 - val_accuracy: 0.5423\n",
      "Epoch 675/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0727 - accuracy: 0.5490 - val_loss: 1.0367 - val_accuracy: 0.5365\n",
      "Epoch 676/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0754 - accuracy: 0.5410 - val_loss: 1.0433 - val_accuracy: 0.5452\n",
      "Epoch 677/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0775 - accuracy: 0.5434 - val_loss: 1.0420 - val_accuracy: 0.5356\n",
      "Epoch 678/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0749 - accuracy: 0.5425 - val_loss: 1.0400 - val_accuracy: 0.5346\n",
      "Epoch 679/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0765 - accuracy: 0.5396 - val_loss: 1.0344 - val_accuracy: 0.5423\n",
      "Epoch 680/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0771 - accuracy: 0.5350 - val_loss: 1.0369 - val_accuracy: 0.5423\n",
      "Epoch 681/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0780 - accuracy: 0.5352 - val_loss: 1.0363 - val_accuracy: 0.5442\n",
      "Epoch 682/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0779 - accuracy: 0.5386 - val_loss: 1.0407 - val_accuracy: 0.5298\n",
      "Epoch 683/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0730 - accuracy: 0.5434 - val_loss: 1.0378 - val_accuracy: 0.5385\n",
      "Epoch 684/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0752 - accuracy: 0.5465 - val_loss: 1.0383 - val_accuracy: 0.5346\n",
      "Epoch 685/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0771 - accuracy: 0.5391 - val_loss: 1.0413 - val_accuracy: 0.5346\n",
      "Epoch 686/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0776 - accuracy: 0.5362 - val_loss: 1.0397 - val_accuracy: 0.5433\n",
      "Epoch 687/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0762 - accuracy: 0.5403 - val_loss: 1.0330 - val_accuracy: 0.5413\n",
      "Epoch 688/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0728 - accuracy: 0.5410 - val_loss: 1.0321 - val_accuracy: 0.5462\n",
      "Epoch 689/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0732 - accuracy: 0.5393 - val_loss: 1.0431 - val_accuracy: 0.5308\n",
      "Epoch 690/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0778 - accuracy: 0.5389 - val_loss: 1.0381 - val_accuracy: 0.5442\n",
      "Epoch 691/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0749 - accuracy: 0.5420 - val_loss: 1.0338 - val_accuracy: 0.5481\n",
      "Epoch 692/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0777 - accuracy: 0.5415 - val_loss: 1.0359 - val_accuracy: 0.5413\n",
      "Epoch 693/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0731 - accuracy: 0.5381 - val_loss: 1.0412 - val_accuracy: 0.5413\n",
      "Epoch 694/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0758 - accuracy: 0.5398 - val_loss: 1.0432 - val_accuracy: 0.5442\n",
      "Epoch 695/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0777 - accuracy: 0.5441 - val_loss: 1.0411 - val_accuracy: 0.5346\n",
      "Epoch 696/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0702 - accuracy: 0.5362 - val_loss: 1.0433 - val_accuracy: 0.5375\n",
      "Epoch 697/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0775 - accuracy: 0.5401 - val_loss: 1.0391 - val_accuracy: 0.5394\n",
      "Epoch 698/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0762 - accuracy: 0.5401 - val_loss: 1.0382 - val_accuracy: 0.5433\n",
      "Epoch 699/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0798 - accuracy: 0.5396 - val_loss: 1.0400 - val_accuracy: 0.5375\n",
      "Epoch 700/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0774 - accuracy: 0.5425 - val_loss: 1.0330 - val_accuracy: 0.5375\n",
      "Epoch 701/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0789 - accuracy: 0.5429 - val_loss: 1.0365 - val_accuracy: 0.5452\n",
      "Epoch 702/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0757 - accuracy: 0.5389 - val_loss: 1.0373 - val_accuracy: 0.5481\n",
      "Epoch 703/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0720 - accuracy: 0.5417 - val_loss: 1.0377 - val_accuracy: 0.5404\n",
      "Epoch 704/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0713 - accuracy: 0.5374 - val_loss: 1.0352 - val_accuracy: 0.5385\n",
      "Epoch 705/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0733 - accuracy: 0.5420 - val_loss: 1.0374 - val_accuracy: 0.5413\n",
      "Epoch 706/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0738 - accuracy: 0.5398 - val_loss: 1.0330 - val_accuracy: 0.5385\n",
      "Epoch 707/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0767 - accuracy: 0.5410 - val_loss: 1.0361 - val_accuracy: 0.5337\n",
      "Epoch 708/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0747 - accuracy: 0.5417 - val_loss: 1.0399 - val_accuracy: 0.5452\n",
      "Epoch 709/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0752 - accuracy: 0.5422 - val_loss: 1.0372 - val_accuracy: 0.5413\n",
      "Epoch 710/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0762 - accuracy: 0.5391 - val_loss: 1.0376 - val_accuracy: 0.5423\n",
      "Epoch 711/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0776 - accuracy: 0.5379 - val_loss: 1.0402 - val_accuracy: 0.5423\n",
      "Epoch 712/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0710 - accuracy: 0.5444 - val_loss: 1.0399 - val_accuracy: 0.5375\n",
      "Epoch 713/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0749 - accuracy: 0.5398 - val_loss: 1.0368 - val_accuracy: 0.5462\n",
      "Epoch 714/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0724 - accuracy: 0.5480 - val_loss: 1.0430 - val_accuracy: 0.5346\n",
      "Epoch 715/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0669 - accuracy: 0.5461 - val_loss: 1.0380 - val_accuracy: 0.5404\n",
      "Epoch 716/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0717 - accuracy: 0.5487 - val_loss: 1.0363 - val_accuracy: 0.5433\n",
      "Epoch 717/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0742 - accuracy: 0.5374 - val_loss: 1.0411 - val_accuracy: 0.5404\n",
      "Epoch 718/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0779 - accuracy: 0.5420 - val_loss: 1.0425 - val_accuracy: 0.5404\n",
      "Epoch 719/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0742 - accuracy: 0.5408 - val_loss: 1.0377 - val_accuracy: 0.5404\n",
      "Epoch 720/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0739 - accuracy: 0.5422 - val_loss: 1.0373 - val_accuracy: 0.5365\n",
      "Epoch 721/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0744 - accuracy: 0.5398 - val_loss: 1.0389 - val_accuracy: 0.5385\n",
      "Epoch 722/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0687 - accuracy: 0.5444 - val_loss: 1.0365 - val_accuracy: 0.5394\n",
      "Epoch 723/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0721 - accuracy: 0.5485 - val_loss: 1.0358 - val_accuracy: 0.5385\n",
      "Epoch 724/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0743 - accuracy: 0.5432 - val_loss: 1.0401 - val_accuracy: 0.5308\n",
      "Epoch 725/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0717 - accuracy: 0.5336 - val_loss: 1.0366 - val_accuracy: 0.5404\n",
      "Epoch 726/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0737 - accuracy: 0.5427 - val_loss: 1.0426 - val_accuracy: 0.5413\n",
      "Epoch 727/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0723 - accuracy: 0.5422 - val_loss: 1.0415 - val_accuracy: 0.5337\n",
      "Epoch 728/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0720 - accuracy: 0.5461 - val_loss: 1.0408 - val_accuracy: 0.5346\n",
      "Epoch 729/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0725 - accuracy: 0.5437 - val_loss: 1.0402 - val_accuracy: 0.5413\n",
      "Epoch 730/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0733 - accuracy: 0.5357 - val_loss: 1.0373 - val_accuracy: 0.5375\n",
      "Epoch 731/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0714 - accuracy: 0.5441 - val_loss: 1.0443 - val_accuracy: 0.5356\n",
      "Epoch 732/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0688 - accuracy: 0.5391 - val_loss: 1.0477 - val_accuracy: 0.5346\n",
      "Epoch 733/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0732 - accuracy: 0.5422 - val_loss: 1.0395 - val_accuracy: 0.5356\n",
      "Epoch 734/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0766 - accuracy: 0.5381 - val_loss: 1.0412 - val_accuracy: 0.5452\n",
      "Epoch 735/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0768 - accuracy: 0.5352 - val_loss: 1.0358 - val_accuracy: 0.5500\n",
      "Epoch 736/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0785 - accuracy: 0.5374 - val_loss: 1.0394 - val_accuracy: 0.5433\n",
      "Epoch 737/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0728 - accuracy: 0.5465 - val_loss: 1.0391 - val_accuracy: 0.5394\n",
      "Epoch 738/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0691 - accuracy: 0.5432 - val_loss: 1.0440 - val_accuracy: 0.5423\n",
      "Epoch 739/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0749 - accuracy: 0.5432 - val_loss: 1.0508 - val_accuracy: 0.5375\n",
      "Epoch 740/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0680 - accuracy: 0.5475 - val_loss: 1.0348 - val_accuracy: 0.5529\n",
      "Epoch 741/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0660 - accuracy: 0.5451 - val_loss: 1.0424 - val_accuracy: 0.5394\n",
      "Epoch 742/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0703 - accuracy: 0.5470 - val_loss: 1.0329 - val_accuracy: 0.5433\n",
      "Epoch 743/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0725 - accuracy: 0.5417 - val_loss: 1.0341 - val_accuracy: 0.5471\n",
      "Epoch 744/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0728 - accuracy: 0.5439 - val_loss: 1.0400 - val_accuracy: 0.5538\n",
      "Epoch 745/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0761 - accuracy: 0.5437 - val_loss: 1.0384 - val_accuracy: 0.5423\n",
      "Epoch 746/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0713 - accuracy: 0.5441 - val_loss: 1.0375 - val_accuracy: 0.5481\n",
      "Epoch 747/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0701 - accuracy: 0.5427 - val_loss: 1.0380 - val_accuracy: 0.5404\n",
      "Epoch 748/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0739 - accuracy: 0.5403 - val_loss: 1.0373 - val_accuracy: 0.5452\n",
      "Epoch 749/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0789 - accuracy: 0.5391 - val_loss: 1.0397 - val_accuracy: 0.5413\n",
      "Epoch 750/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0720 - accuracy: 0.5401 - val_loss: 1.0378 - val_accuracy: 0.5375\n",
      "Epoch 751/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0722 - accuracy: 0.5437 - val_loss: 1.0313 - val_accuracy: 0.5375\n",
      "Epoch 752/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0699 - accuracy: 0.5470 - val_loss: 1.0336 - val_accuracy: 0.5394\n",
      "Epoch 753/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0666 - accuracy: 0.5420 - val_loss: 1.0396 - val_accuracy: 0.5346\n",
      "Epoch 754/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0757 - accuracy: 0.5391 - val_loss: 1.0385 - val_accuracy: 0.5385\n",
      "Epoch 755/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0726 - accuracy: 0.5417 - val_loss: 1.0338 - val_accuracy: 0.5413\n",
      "Epoch 756/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0645 - accuracy: 0.5398 - val_loss: 1.0300 - val_accuracy: 0.5433\n",
      "Epoch 757/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0700 - accuracy: 0.5461 - val_loss: 1.0348 - val_accuracy: 0.5404\n",
      "Epoch 758/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0716 - accuracy: 0.5439 - val_loss: 1.0382 - val_accuracy: 0.5462\n",
      "Epoch 759/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0752 - accuracy: 0.5499 - val_loss: 1.0298 - val_accuracy: 0.5510\n",
      "Epoch 760/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0689 - accuracy: 0.5422 - val_loss: 1.0331 - val_accuracy: 0.5471\n",
      "Epoch 761/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0728 - accuracy: 0.5391 - val_loss: 1.0343 - val_accuracy: 0.5490\n",
      "Epoch 762/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0710 - accuracy: 0.5413 - val_loss: 1.0347 - val_accuracy: 0.5385\n",
      "Epoch 763/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0701 - accuracy: 0.5398 - val_loss: 1.0366 - val_accuracy: 0.5433\n",
      "Epoch 764/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0712 - accuracy: 0.5393 - val_loss: 1.0297 - val_accuracy: 0.5404\n",
      "Epoch 765/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0731 - accuracy: 0.5441 - val_loss: 1.0376 - val_accuracy: 0.5394\n",
      "Epoch 766/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0693 - accuracy: 0.5410 - val_loss: 1.0361 - val_accuracy: 0.5462\n",
      "Epoch 767/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0701 - accuracy: 0.5410 - val_loss: 1.0358 - val_accuracy: 0.5442\n",
      "Epoch 768/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0677 - accuracy: 0.5425 - val_loss: 1.0336 - val_accuracy: 0.5442\n",
      "Epoch 769/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0728 - accuracy: 0.5425 - val_loss: 1.0297 - val_accuracy: 0.5538\n",
      "Epoch 770/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0656 - accuracy: 0.5425 - val_loss: 1.0322 - val_accuracy: 0.5433\n",
      "Epoch 771/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0688 - accuracy: 0.5456 - val_loss: 1.0298 - val_accuracy: 0.5394\n",
      "Epoch 772/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0757 - accuracy: 0.5350 - val_loss: 1.0351 - val_accuracy: 0.5346\n",
      "Epoch 773/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0708 - accuracy: 0.5381 - val_loss: 1.0289 - val_accuracy: 0.5462\n",
      "Epoch 774/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0696 - accuracy: 0.5408 - val_loss: 1.0280 - val_accuracy: 0.5510\n",
      "Epoch 775/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0719 - accuracy: 0.5449 - val_loss: 1.0299 - val_accuracy: 0.5500\n",
      "Epoch 776/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0711 - accuracy: 0.5415 - val_loss: 1.0328 - val_accuracy: 0.5471\n",
      "Epoch 777/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0757 - accuracy: 0.5386 - val_loss: 1.0294 - val_accuracy: 0.5452\n",
      "Epoch 778/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0704 - accuracy: 0.5434 - val_loss: 1.0367 - val_accuracy: 0.5394\n",
      "Epoch 779/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0695 - accuracy: 0.5338 - val_loss: 1.0344 - val_accuracy: 0.5404\n",
      "Epoch 780/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0736 - accuracy: 0.5391 - val_loss: 1.0316 - val_accuracy: 0.5452\n",
      "Epoch 781/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0705 - accuracy: 0.5379 - val_loss: 1.0312 - val_accuracy: 0.5442\n",
      "Epoch 782/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0743 - accuracy: 0.5439 - val_loss: 1.0279 - val_accuracy: 0.5452\n",
      "Epoch 783/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0688 - accuracy: 0.5352 - val_loss: 1.0296 - val_accuracy: 0.5433\n",
      "Epoch 784/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0740 - accuracy: 0.5398 - val_loss: 1.0295 - val_accuracy: 0.5442\n",
      "Epoch 785/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0749 - accuracy: 0.5391 - val_loss: 1.0235 - val_accuracy: 0.5500\n",
      "Epoch 786/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0704 - accuracy: 0.5415 - val_loss: 1.0281 - val_accuracy: 0.5577\n",
      "Epoch 787/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0710 - accuracy: 0.5408 - val_loss: 1.0320 - val_accuracy: 0.5500\n",
      "Epoch 788/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0705 - accuracy: 0.5393 - val_loss: 1.0274 - val_accuracy: 0.5490\n",
      "Epoch 789/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0682 - accuracy: 0.5376 - val_loss: 1.0285 - val_accuracy: 0.5490\n",
      "Epoch 790/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0695 - accuracy: 0.5470 - val_loss: 1.0322 - val_accuracy: 0.5442\n",
      "Epoch 791/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0693 - accuracy: 0.5480 - val_loss: 1.0269 - val_accuracy: 0.5519\n",
      "Epoch 792/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0705 - accuracy: 0.5413 - val_loss: 1.0302 - val_accuracy: 0.5413\n",
      "Epoch 793/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0676 - accuracy: 0.5453 - val_loss: 1.0310 - val_accuracy: 0.5462\n",
      "Epoch 794/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0664 - accuracy: 0.5550 - val_loss: 1.0303 - val_accuracy: 0.5500\n",
      "Epoch 795/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0712 - accuracy: 0.5410 - val_loss: 1.0303 - val_accuracy: 0.5510\n",
      "Epoch 796/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0689 - accuracy: 0.5456 - val_loss: 1.0297 - val_accuracy: 0.5471\n",
      "Epoch 797/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0691 - accuracy: 0.5478 - val_loss: 1.0250 - val_accuracy: 0.5442\n",
      "Epoch 798/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0771 - accuracy: 0.5425 - val_loss: 1.0230 - val_accuracy: 0.5500\n",
      "Epoch 799/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0675 - accuracy: 0.5432 - val_loss: 1.0278 - val_accuracy: 0.5404\n",
      "Epoch 800/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0678 - accuracy: 0.5451 - val_loss: 1.0260 - val_accuracy: 0.5471\n",
      "Epoch 801/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0656 - accuracy: 0.5482 - val_loss: 1.0283 - val_accuracy: 0.5500\n",
      "Epoch 802/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0664 - accuracy: 0.5437 - val_loss: 1.0350 - val_accuracy: 0.5519\n",
      "Epoch 803/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0667 - accuracy: 0.5463 - val_loss: 1.0346 - val_accuracy: 0.5510\n",
      "Epoch 804/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0600 - accuracy: 0.5461 - val_loss: 1.0265 - val_accuracy: 0.5596\n",
      "Epoch 805/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0686 - accuracy: 0.5497 - val_loss: 1.0247 - val_accuracy: 0.5500\n",
      "Epoch 806/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0666 - accuracy: 0.5398 - val_loss: 1.0289 - val_accuracy: 0.5481\n",
      "Epoch 807/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0673 - accuracy: 0.5461 - val_loss: 1.0265 - val_accuracy: 0.5510\n",
      "Epoch 808/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0625 - accuracy: 0.5465 - val_loss: 1.0332 - val_accuracy: 0.5442\n",
      "Epoch 809/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0749 - accuracy: 0.5391 - val_loss: 1.0245 - val_accuracy: 0.5510\n",
      "Epoch 810/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0660 - accuracy: 0.5417 - val_loss: 1.0273 - val_accuracy: 0.5558\n",
      "Epoch 811/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0710 - accuracy: 0.5444 - val_loss: 1.0284 - val_accuracy: 0.5538\n",
      "Epoch 812/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0673 - accuracy: 0.5485 - val_loss: 1.0192 - val_accuracy: 0.5433\n",
      "Epoch 813/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0643 - accuracy: 0.5437 - val_loss: 1.0227 - val_accuracy: 0.5442\n",
      "Epoch 814/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0700 - accuracy: 0.5465 - val_loss: 1.0227 - val_accuracy: 0.5404\n",
      "Epoch 815/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0648 - accuracy: 0.5473 - val_loss: 1.0223 - val_accuracy: 0.5538\n",
      "Epoch 816/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0702 - accuracy: 0.5420 - val_loss: 1.0220 - val_accuracy: 0.5490\n",
      "Epoch 817/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0654 - accuracy: 0.5458 - val_loss: 1.0197 - val_accuracy: 0.5519\n",
      "Epoch 818/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0633 - accuracy: 0.5494 - val_loss: 1.0206 - val_accuracy: 0.5500\n",
      "Epoch 819/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0625 - accuracy: 0.5499 - val_loss: 1.0237 - val_accuracy: 0.5558\n",
      "Epoch 820/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0663 - accuracy: 0.5441 - val_loss: 1.0161 - val_accuracy: 0.5519\n",
      "Epoch 821/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0645 - accuracy: 0.5441 - val_loss: 1.0176 - val_accuracy: 0.5548\n",
      "Epoch 822/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0642 - accuracy: 0.5398 - val_loss: 1.0179 - val_accuracy: 0.5615\n",
      "Epoch 823/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0678 - accuracy: 0.5463 - val_loss: 1.0171 - val_accuracy: 0.5644\n",
      "Epoch 824/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0675 - accuracy: 0.5401 - val_loss: 1.0216 - val_accuracy: 0.5587\n",
      "Epoch 825/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0660 - accuracy: 0.5439 - val_loss: 1.0159 - val_accuracy: 0.5596\n",
      "Epoch 826/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0654 - accuracy: 0.5485 - val_loss: 1.0165 - val_accuracy: 0.5500\n",
      "Epoch 827/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0626 - accuracy: 0.5475 - val_loss: 1.0260 - val_accuracy: 0.5442\n",
      "Epoch 828/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0653 - accuracy: 0.5432 - val_loss: 1.0269 - val_accuracy: 0.5538\n",
      "Epoch 829/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0659 - accuracy: 0.5410 - val_loss: 1.0178 - val_accuracy: 0.5596\n",
      "Epoch 830/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0686 - accuracy: 0.5415 - val_loss: 1.0186 - val_accuracy: 0.5587\n",
      "Epoch 831/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0669 - accuracy: 0.5369 - val_loss: 1.0183 - val_accuracy: 0.5567\n",
      "Epoch 832/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0641 - accuracy: 0.5461 - val_loss: 1.0240 - val_accuracy: 0.5519\n",
      "Epoch 833/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0701 - accuracy: 0.5403 - val_loss: 1.0154 - val_accuracy: 0.5529\n",
      "Epoch 834/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0656 - accuracy: 0.5439 - val_loss: 1.0168 - val_accuracy: 0.5606\n",
      "Epoch 835/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0647 - accuracy: 0.5439 - val_loss: 1.0212 - val_accuracy: 0.5510\n",
      "Epoch 836/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0593 - accuracy: 0.5446 - val_loss: 1.0205 - val_accuracy: 0.5596\n",
      "Epoch 837/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0652 - accuracy: 0.5413 - val_loss: 1.0213 - val_accuracy: 0.5510\n",
      "Epoch 838/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0661 - accuracy: 0.5451 - val_loss: 1.0149 - val_accuracy: 0.5471\n",
      "Epoch 839/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0690 - accuracy: 0.5403 - val_loss: 1.0208 - val_accuracy: 0.5587\n",
      "Epoch 840/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0676 - accuracy: 0.5405 - val_loss: 1.0271 - val_accuracy: 0.5404\n",
      "Epoch 841/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0596 - accuracy: 0.5509 - val_loss: 1.0225 - val_accuracy: 0.5567\n",
      "Epoch 842/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0627 - accuracy: 0.5485 - val_loss: 1.0147 - val_accuracy: 0.5606\n",
      "Epoch 843/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0644 - accuracy: 0.5446 - val_loss: 1.0196 - val_accuracy: 0.5538\n",
      "Epoch 844/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0656 - accuracy: 0.5456 - val_loss: 1.0265 - val_accuracy: 0.5490\n",
      "Epoch 845/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0647 - accuracy: 0.5456 - val_loss: 1.0186 - val_accuracy: 0.5558\n",
      "Epoch 846/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0667 - accuracy: 0.5408 - val_loss: 1.0152 - val_accuracy: 0.5606\n",
      "Epoch 847/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0651 - accuracy: 0.5509 - val_loss: 1.0138 - val_accuracy: 0.5548\n",
      "Epoch 848/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0643 - accuracy: 0.5410 - val_loss: 1.0175 - val_accuracy: 0.5538\n",
      "Epoch 849/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0671 - accuracy: 0.5446 - val_loss: 1.0174 - val_accuracy: 0.5538\n",
      "Epoch 850/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0644 - accuracy: 0.5492 - val_loss: 1.0181 - val_accuracy: 0.5577\n",
      "Epoch 851/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0636 - accuracy: 0.5439 - val_loss: 1.0188 - val_accuracy: 0.5548\n",
      "Epoch 852/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0642 - accuracy: 0.5494 - val_loss: 1.0141 - val_accuracy: 0.5635\n",
      "Epoch 853/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0651 - accuracy: 0.5429 - val_loss: 1.0093 - val_accuracy: 0.5606\n",
      "Epoch 854/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0617 - accuracy: 0.5441 - val_loss: 1.0107 - val_accuracy: 0.5663\n",
      "Epoch 855/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0670 - accuracy: 0.5444 - val_loss: 1.0197 - val_accuracy: 0.5558\n",
      "Epoch 856/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0629 - accuracy: 0.5468 - val_loss: 1.0148 - val_accuracy: 0.5538\n",
      "Epoch 857/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0708 - accuracy: 0.5417 - val_loss: 1.0199 - val_accuracy: 0.5558\n",
      "Epoch 858/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0646 - accuracy: 0.5530 - val_loss: 1.0153 - val_accuracy: 0.5558\n",
      "Epoch 859/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0580 - accuracy: 0.5494 - val_loss: 1.0204 - val_accuracy: 0.5683\n",
      "Epoch 860/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0629 - accuracy: 0.5451 - val_loss: 1.0185 - val_accuracy: 0.5625\n",
      "Epoch 861/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0620 - accuracy: 0.5458 - val_loss: 1.0184 - val_accuracy: 0.5615\n",
      "Epoch 862/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0615 - accuracy: 0.5439 - val_loss: 1.0253 - val_accuracy: 0.5587\n",
      "Epoch 863/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0668 - accuracy: 0.5451 - val_loss: 1.0243 - val_accuracy: 0.5558\n",
      "Epoch 864/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0668 - accuracy: 0.5396 - val_loss: 1.0165 - val_accuracy: 0.5510\n",
      "Epoch 865/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0665 - accuracy: 0.5413 - val_loss: 1.0205 - val_accuracy: 0.5615\n",
      "Epoch 866/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0647 - accuracy: 0.5429 - val_loss: 1.0104 - val_accuracy: 0.5635\n",
      "Epoch 867/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0558 - accuracy: 0.5453 - val_loss: 1.0235 - val_accuracy: 0.5567\n",
      "Epoch 868/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0583 - accuracy: 0.5449 - val_loss: 1.0190 - val_accuracy: 0.5625\n",
      "Epoch 869/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0681 - accuracy: 0.5384 - val_loss: 1.0164 - val_accuracy: 0.5596\n",
      "Epoch 870/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0614 - accuracy: 0.5389 - val_loss: 1.0189 - val_accuracy: 0.5721\n",
      "Epoch 871/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0630 - accuracy: 0.5523 - val_loss: 1.0195 - val_accuracy: 0.5663\n",
      "Epoch 872/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0648 - accuracy: 0.5408 - val_loss: 1.0219 - val_accuracy: 0.5606\n",
      "Epoch 873/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0559 - accuracy: 0.5538 - val_loss: 1.0198 - val_accuracy: 0.5567\n",
      "Epoch 874/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0577 - accuracy: 0.5494 - val_loss: 1.0297 - val_accuracy: 0.5606\n",
      "Epoch 875/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0577 - accuracy: 0.5533 - val_loss: 1.0271 - val_accuracy: 0.5538\n",
      "Epoch 876/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0618 - accuracy: 0.5405 - val_loss: 1.0249 - val_accuracy: 0.5529\n",
      "Epoch 877/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0637 - accuracy: 0.5422 - val_loss: 1.0242 - val_accuracy: 0.5500\n",
      "Epoch 878/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0639 - accuracy: 0.5456 - val_loss: 1.0140 - val_accuracy: 0.5712\n",
      "Epoch 879/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0600 - accuracy: 0.5420 - val_loss: 1.0167 - val_accuracy: 0.5548\n",
      "Epoch 880/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0645 - accuracy: 0.5458 - val_loss: 1.0170 - val_accuracy: 0.5567\n",
      "Epoch 881/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0595 - accuracy: 0.5451 - val_loss: 1.0187 - val_accuracy: 0.5519\n",
      "Epoch 882/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0585 - accuracy: 0.5437 - val_loss: 1.0150 - val_accuracy: 0.5529\n",
      "Epoch 883/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0630 - accuracy: 0.5468 - val_loss: 1.0173 - val_accuracy: 0.5558\n",
      "Epoch 884/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0609 - accuracy: 0.5465 - val_loss: 1.0216 - val_accuracy: 0.5567\n",
      "Epoch 885/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0610 - accuracy: 0.5432 - val_loss: 1.0163 - val_accuracy: 0.5615\n",
      "Epoch 886/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0663 - accuracy: 0.5369 - val_loss: 1.0195 - val_accuracy: 0.5654\n",
      "Epoch 887/1500\n",
      "4157/4157 [==============================] - 0s 35us/step - loss: 1.0574 - accuracy: 0.5458 - val_loss: 1.0178 - val_accuracy: 0.5587\n",
      "Epoch 888/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0625 - accuracy: 0.5458 - val_loss: 1.0262 - val_accuracy: 0.5529\n",
      "Epoch 889/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0611 - accuracy: 0.5449 - val_loss: 1.0278 - val_accuracy: 0.5548\n",
      "Epoch 890/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0607 - accuracy: 0.5439 - val_loss: 1.0204 - val_accuracy: 0.5606\n",
      "Epoch 891/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0532 - accuracy: 0.5487 - val_loss: 1.0233 - val_accuracy: 0.5538\n",
      "Epoch 892/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0587 - accuracy: 0.5478 - val_loss: 1.0266 - val_accuracy: 0.5615\n",
      "Epoch 893/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0625 - accuracy: 0.5521 - val_loss: 1.0412 - val_accuracy: 0.5548\n",
      "Epoch 894/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0616 - accuracy: 0.5413 - val_loss: 1.0180 - val_accuracy: 0.5510\n",
      "Epoch 895/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0541 - accuracy: 0.5506 - val_loss: 1.0147 - val_accuracy: 0.5567\n",
      "Epoch 896/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0633 - accuracy: 0.5413 - val_loss: 1.0087 - val_accuracy: 0.5606\n",
      "Epoch 897/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0621 - accuracy: 0.5355 - val_loss: 1.0116 - val_accuracy: 0.5587\n",
      "Epoch 898/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0595 - accuracy: 0.5420 - val_loss: 1.0268 - val_accuracy: 0.5519\n",
      "Epoch 899/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0608 - accuracy: 0.5413 - val_loss: 1.0201 - val_accuracy: 0.5519\n",
      "Epoch 900/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0588 - accuracy: 0.5420 - val_loss: 1.0143 - val_accuracy: 0.5663\n",
      "Epoch 901/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0578 - accuracy: 0.5509 - val_loss: 1.0160 - val_accuracy: 0.5567\n",
      "Epoch 902/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0536 - accuracy: 0.5518 - val_loss: 1.0207 - val_accuracy: 0.5625\n",
      "Epoch 903/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0560 - accuracy: 0.5451 - val_loss: 1.0186 - val_accuracy: 0.5558\n",
      "Epoch 904/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0573 - accuracy: 0.5449 - val_loss: 1.0194 - val_accuracy: 0.5615\n",
      "Epoch 905/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0615 - accuracy: 0.5480 - val_loss: 1.0175 - val_accuracy: 0.5558\n",
      "Epoch 906/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0572 - accuracy: 0.5490 - val_loss: 1.0127 - val_accuracy: 0.5567\n",
      "Epoch 907/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0552 - accuracy: 0.5480 - val_loss: 1.0217 - val_accuracy: 0.5567\n",
      "Epoch 908/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0556 - accuracy: 0.5497 - val_loss: 1.0179 - val_accuracy: 0.5577\n",
      "Epoch 909/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0582 - accuracy: 0.5482 - val_loss: 1.0252 - val_accuracy: 0.5481\n",
      "Epoch 910/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0629 - accuracy: 0.5357 - val_loss: 1.0192 - val_accuracy: 0.5587\n",
      "Epoch 911/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0592 - accuracy: 0.5415 - val_loss: 1.0169 - val_accuracy: 0.5615\n",
      "Epoch 912/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0579 - accuracy: 0.5485 - val_loss: 1.0219 - val_accuracy: 0.5490\n",
      "Epoch 913/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0563 - accuracy: 0.5429 - val_loss: 1.0171 - val_accuracy: 0.5538\n",
      "Epoch 914/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0568 - accuracy: 0.5444 - val_loss: 1.0203 - val_accuracy: 0.5548\n",
      "Epoch 915/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0590 - accuracy: 0.5449 - val_loss: 1.0215 - val_accuracy: 0.5596\n",
      "Epoch 916/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0597 - accuracy: 0.5405 - val_loss: 1.0136 - val_accuracy: 0.5529\n",
      "Epoch 917/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0601 - accuracy: 0.5415 - val_loss: 1.0193 - val_accuracy: 0.5529\n",
      "Epoch 918/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0616 - accuracy: 0.5449 - val_loss: 1.0261 - val_accuracy: 0.5596\n",
      "Epoch 919/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0620 - accuracy: 0.5492 - val_loss: 1.0225 - val_accuracy: 0.5490\n",
      "Epoch 920/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0614 - accuracy: 0.5504 - val_loss: 1.0185 - val_accuracy: 0.5510\n",
      "Epoch 921/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0539 - accuracy: 0.5516 - val_loss: 1.0190 - val_accuracy: 0.5673\n",
      "Epoch 922/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0557 - accuracy: 0.5478 - val_loss: 1.0132 - val_accuracy: 0.5606\n",
      "Epoch 923/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0581 - accuracy: 0.5497 - val_loss: 1.0185 - val_accuracy: 0.5529\n",
      "Epoch 924/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0596 - accuracy: 0.5451 - val_loss: 1.0267 - val_accuracy: 0.5596\n",
      "Epoch 925/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0527 - accuracy: 0.5497 - val_loss: 1.0206 - val_accuracy: 0.5548\n",
      "Epoch 926/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0579 - accuracy: 0.5453 - val_loss: 1.0155 - val_accuracy: 0.5567\n",
      "Epoch 927/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0531 - accuracy: 0.5468 - val_loss: 1.0181 - val_accuracy: 0.5548\n",
      "Epoch 928/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0595 - accuracy: 0.5429 - val_loss: 1.0233 - val_accuracy: 0.5548\n",
      "Epoch 929/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0558 - accuracy: 0.5456 - val_loss: 1.0220 - val_accuracy: 0.5519\n",
      "Epoch 930/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0556 - accuracy: 0.5480 - val_loss: 1.0180 - val_accuracy: 0.5635\n",
      "Epoch 931/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0545 - accuracy: 0.5478 - val_loss: 1.0227 - val_accuracy: 0.5529\n",
      "Epoch 932/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0612 - accuracy: 0.5393 - val_loss: 1.0199 - val_accuracy: 0.5577\n",
      "Epoch 933/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0546 - accuracy: 0.5485 - val_loss: 1.0212 - val_accuracy: 0.5567\n",
      "Epoch 934/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0541 - accuracy: 0.5458 - val_loss: 1.0231 - val_accuracy: 0.5500\n",
      "Epoch 935/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0578 - accuracy: 0.5463 - val_loss: 1.0271 - val_accuracy: 0.5529\n",
      "Epoch 936/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0573 - accuracy: 0.5511 - val_loss: 1.0223 - val_accuracy: 0.5519\n",
      "Epoch 937/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0584 - accuracy: 0.5425 - val_loss: 1.0227 - val_accuracy: 0.5538\n",
      "Epoch 938/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0568 - accuracy: 0.5482 - val_loss: 1.0214 - val_accuracy: 0.5596\n",
      "Epoch 939/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0541 - accuracy: 0.5437 - val_loss: 1.0187 - val_accuracy: 0.5519\n",
      "Epoch 940/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0505 - accuracy: 0.5511 - val_loss: 1.0211 - val_accuracy: 0.5529\n",
      "Epoch 941/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0577 - accuracy: 0.5408 - val_loss: 1.0127 - val_accuracy: 0.5635\n",
      "Epoch 942/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0596 - accuracy: 0.5439 - val_loss: 1.0216 - val_accuracy: 0.5625\n",
      "Epoch 943/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0565 - accuracy: 0.5417 - val_loss: 1.0115 - val_accuracy: 0.5635\n",
      "Epoch 944/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0544 - accuracy: 0.5497 - val_loss: 1.0224 - val_accuracy: 0.5606\n",
      "Epoch 945/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0546 - accuracy: 0.5461 - val_loss: 1.0201 - val_accuracy: 0.5596\n",
      "Epoch 946/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0522 - accuracy: 0.5506 - val_loss: 1.0191 - val_accuracy: 0.5577\n",
      "Epoch 947/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0580 - accuracy: 0.5473 - val_loss: 1.0197 - val_accuracy: 0.5606\n",
      "Epoch 948/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0607 - accuracy: 0.5379 - val_loss: 1.0171 - val_accuracy: 0.5596\n",
      "Epoch 949/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0531 - accuracy: 0.5405 - val_loss: 1.0225 - val_accuracy: 0.5635\n",
      "Epoch 950/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0549 - accuracy: 0.5413 - val_loss: 1.0274 - val_accuracy: 0.5567\n",
      "Epoch 951/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0570 - accuracy: 0.5528 - val_loss: 1.0273 - val_accuracy: 0.5471\n",
      "Epoch 952/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0493 - accuracy: 0.5509 - val_loss: 1.0233 - val_accuracy: 0.5644\n",
      "Epoch 953/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0524 - accuracy: 0.5499 - val_loss: 1.0268 - val_accuracy: 0.5548\n",
      "Epoch 954/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0565 - accuracy: 0.5497 - val_loss: 1.0146 - val_accuracy: 0.5644\n",
      "Epoch 955/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0563 - accuracy: 0.5470 - val_loss: 1.0194 - val_accuracy: 0.5567\n",
      "Epoch 956/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0510 - accuracy: 0.5439 - val_loss: 1.0254 - val_accuracy: 0.5510\n",
      "Epoch 957/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0543 - accuracy: 0.5434 - val_loss: 1.0268 - val_accuracy: 0.5654\n",
      "Epoch 958/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0540 - accuracy: 0.5506 - val_loss: 1.0278 - val_accuracy: 0.5510\n",
      "Epoch 959/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0566 - accuracy: 0.5463 - val_loss: 1.0243 - val_accuracy: 0.5510\n",
      "Epoch 960/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0527 - accuracy: 0.5478 - val_loss: 1.0213 - val_accuracy: 0.5558\n",
      "Epoch 961/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0540 - accuracy: 0.5482 - val_loss: 1.0300 - val_accuracy: 0.5596\n",
      "Epoch 962/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0529 - accuracy: 0.5461 - val_loss: 1.0297 - val_accuracy: 0.5587\n",
      "Epoch 963/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0581 - accuracy: 0.5413 - val_loss: 1.0208 - val_accuracy: 0.5558\n",
      "Epoch 964/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0534 - accuracy: 0.5516 - val_loss: 1.0228 - val_accuracy: 0.5644\n",
      "Epoch 965/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0562 - accuracy: 0.5432 - val_loss: 1.0202 - val_accuracy: 0.5740\n",
      "Epoch 966/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0514 - accuracy: 0.5492 - val_loss: 1.0279 - val_accuracy: 0.5596\n",
      "Epoch 967/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0530 - accuracy: 0.5446 - val_loss: 1.0236 - val_accuracy: 0.5567\n",
      "Epoch 968/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0575 - accuracy: 0.5425 - val_loss: 1.0239 - val_accuracy: 0.5596\n",
      "Epoch 969/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0518 - accuracy: 0.5502 - val_loss: 1.0243 - val_accuracy: 0.5548\n",
      "Epoch 970/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0565 - accuracy: 0.5408 - val_loss: 1.0299 - val_accuracy: 0.5519\n",
      "Epoch 971/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0538 - accuracy: 0.5504 - val_loss: 1.0302 - val_accuracy: 0.5538\n",
      "Epoch 972/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0585 - accuracy: 0.5490 - val_loss: 1.0290 - val_accuracy: 0.5587\n",
      "Epoch 973/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0542 - accuracy: 0.5482 - val_loss: 1.0295 - val_accuracy: 0.5490\n",
      "Epoch 974/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0471 - accuracy: 0.5473 - val_loss: 1.0322 - val_accuracy: 0.5529\n",
      "Epoch 975/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0535 - accuracy: 0.5490 - val_loss: 1.0230 - val_accuracy: 0.5577\n",
      "Epoch 976/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0503 - accuracy: 0.5494 - val_loss: 1.0228 - val_accuracy: 0.5615\n",
      "Epoch 977/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0527 - accuracy: 0.5530 - val_loss: 1.0217 - val_accuracy: 0.5538\n",
      "Epoch 978/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0558 - accuracy: 0.5439 - val_loss: 1.0313 - val_accuracy: 0.5510\n",
      "Epoch 979/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0501 - accuracy: 0.5542 - val_loss: 1.0345 - val_accuracy: 0.5519\n",
      "Epoch 980/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0614 - accuracy: 0.5389 - val_loss: 1.0261 - val_accuracy: 0.5615\n",
      "Epoch 981/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0522 - accuracy: 0.5429 - val_loss: 1.0252 - val_accuracy: 0.5558\n",
      "Epoch 982/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0510 - accuracy: 0.5523 - val_loss: 1.0260 - val_accuracy: 0.5663\n",
      "Epoch 983/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0610 - accuracy: 0.5533 - val_loss: 1.0119 - val_accuracy: 0.5625\n",
      "Epoch 984/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0559 - accuracy: 0.5420 - val_loss: 1.0156 - val_accuracy: 0.5606\n",
      "Epoch 985/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0494 - accuracy: 0.5509 - val_loss: 1.0250 - val_accuracy: 0.5596\n",
      "Epoch 986/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0501 - accuracy: 0.5453 - val_loss: 1.0207 - val_accuracy: 0.5683\n",
      "Epoch 987/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0454 - accuracy: 0.5494 - val_loss: 1.0188 - val_accuracy: 0.5548\n",
      "Epoch 988/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0567 - accuracy: 0.5413 - val_loss: 1.0238 - val_accuracy: 0.5500\n",
      "Epoch 989/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0539 - accuracy: 0.5410 - val_loss: 1.0224 - val_accuracy: 0.5712\n",
      "Epoch 990/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0503 - accuracy: 0.5427 - val_loss: 1.0234 - val_accuracy: 0.5663\n",
      "Epoch 991/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0531 - accuracy: 0.5557 - val_loss: 1.0183 - val_accuracy: 0.5702\n",
      "Epoch 992/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0515 - accuracy: 0.5499 - val_loss: 1.0204 - val_accuracy: 0.5625\n",
      "Epoch 993/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0560 - accuracy: 0.5415 - val_loss: 1.0163 - val_accuracy: 0.5538\n",
      "Epoch 994/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0535 - accuracy: 0.5463 - val_loss: 1.0202 - val_accuracy: 0.5548\n",
      "Epoch 995/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0519 - accuracy: 0.5458 - val_loss: 1.0229 - val_accuracy: 0.5644\n",
      "Epoch 996/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0527 - accuracy: 0.5521 - val_loss: 1.0246 - val_accuracy: 0.5567\n",
      "Epoch 997/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0510 - accuracy: 0.5482 - val_loss: 1.0270 - val_accuracy: 0.5510\n",
      "Epoch 998/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0469 - accuracy: 0.5521 - val_loss: 1.0308 - val_accuracy: 0.5529\n",
      "Epoch 999/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0509 - accuracy: 0.5487 - val_loss: 1.0210 - val_accuracy: 0.5625\n",
      "Epoch 1000/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0515 - accuracy: 0.5516 - val_loss: 1.0227 - val_accuracy: 0.5625\n",
      "Epoch 1001/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0532 - accuracy: 0.5480 - val_loss: 1.0232 - val_accuracy: 0.5625\n",
      "Epoch 1002/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0507 - accuracy: 0.5482 - val_loss: 1.0144 - val_accuracy: 0.5615\n",
      "Epoch 1003/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0468 - accuracy: 0.5518 - val_loss: 1.0122 - val_accuracy: 0.5692\n",
      "Epoch 1004/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0509 - accuracy: 0.5502 - val_loss: 1.0105 - val_accuracy: 0.5606\n",
      "Epoch 1005/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0470 - accuracy: 0.5465 - val_loss: 1.0116 - val_accuracy: 0.5788\n",
      "Epoch 1006/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0449 - accuracy: 0.5468 - val_loss: 1.0182 - val_accuracy: 0.5510\n",
      "Epoch 1007/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0465 - accuracy: 0.5463 - val_loss: 1.0188 - val_accuracy: 0.5663\n",
      "Epoch 1008/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0559 - accuracy: 0.5429 - val_loss: 1.0252 - val_accuracy: 0.5587\n",
      "Epoch 1009/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0527 - accuracy: 0.5514 - val_loss: 1.0212 - val_accuracy: 0.5510\n",
      "Epoch 1010/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0513 - accuracy: 0.5420 - val_loss: 1.0118 - val_accuracy: 0.5673\n",
      "Epoch 1011/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0501 - accuracy: 0.5458 - val_loss: 1.0185 - val_accuracy: 0.5625\n",
      "Epoch 1012/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0549 - accuracy: 0.5468 - val_loss: 1.0292 - val_accuracy: 0.5548\n",
      "Epoch 1013/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0514 - accuracy: 0.5509 - val_loss: 1.0198 - val_accuracy: 0.5587\n",
      "Epoch 1014/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0448 - accuracy: 0.5571 - val_loss: 1.0206 - val_accuracy: 0.5760\n",
      "Epoch 1015/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0494 - accuracy: 0.5461 - val_loss: 1.0236 - val_accuracy: 0.5596\n",
      "Epoch 1016/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0578 - accuracy: 0.5427 - val_loss: 1.0158 - val_accuracy: 0.5596\n",
      "Epoch 1017/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0545 - accuracy: 0.5441 - val_loss: 1.0144 - val_accuracy: 0.5644\n",
      "Epoch 1018/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0496 - accuracy: 0.5499 - val_loss: 1.0198 - val_accuracy: 0.5519\n",
      "Epoch 1019/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0477 - accuracy: 0.5516 - val_loss: 1.0202 - val_accuracy: 0.5606\n",
      "Epoch 1020/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0471 - accuracy: 0.5429 - val_loss: 1.0236 - val_accuracy: 0.5683\n",
      "Epoch 1021/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0498 - accuracy: 0.5521 - val_loss: 1.0203 - val_accuracy: 0.5625\n",
      "Epoch 1022/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0544 - accuracy: 0.5499 - val_loss: 1.0281 - val_accuracy: 0.5462\n",
      "Epoch 1023/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0499 - accuracy: 0.5403 - val_loss: 1.0194 - val_accuracy: 0.5635\n",
      "Epoch 1024/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0447 - accuracy: 0.5504 - val_loss: 1.0169 - val_accuracy: 0.5654\n",
      "Epoch 1025/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0417 - accuracy: 0.5509 - val_loss: 1.0224 - val_accuracy: 0.5635\n",
      "Epoch 1026/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0442 - accuracy: 0.5502 - val_loss: 1.0189 - val_accuracy: 0.5577\n",
      "Epoch 1027/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0513 - accuracy: 0.5502 - val_loss: 1.0201 - val_accuracy: 0.5683\n",
      "Epoch 1028/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0511 - accuracy: 0.5545 - val_loss: 1.0244 - val_accuracy: 0.5538\n",
      "Epoch 1029/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0496 - accuracy: 0.5449 - val_loss: 1.0204 - val_accuracy: 0.5587\n",
      "Epoch 1030/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0506 - accuracy: 0.5463 - val_loss: 1.0221 - val_accuracy: 0.5500\n",
      "Epoch 1031/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0492 - accuracy: 0.5554 - val_loss: 1.0267 - val_accuracy: 0.5558\n",
      "Epoch 1032/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0529 - accuracy: 0.5451 - val_loss: 1.0263 - val_accuracy: 0.5625\n",
      "Epoch 1033/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0447 - accuracy: 0.5446 - val_loss: 1.0252 - val_accuracy: 0.5625\n",
      "Epoch 1034/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0502 - accuracy: 0.5497 - val_loss: 1.0167 - val_accuracy: 0.5615\n",
      "Epoch 1035/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0478 - accuracy: 0.5504 - val_loss: 1.0165 - val_accuracy: 0.5731\n",
      "Epoch 1036/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0471 - accuracy: 0.5511 - val_loss: 1.0217 - val_accuracy: 0.5721\n",
      "Epoch 1037/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0481 - accuracy: 0.5461 - val_loss: 1.0193 - val_accuracy: 0.5673\n",
      "Epoch 1038/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0484 - accuracy: 0.5465 - val_loss: 1.0188 - val_accuracy: 0.5721\n",
      "Epoch 1039/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0509 - accuracy: 0.5437 - val_loss: 1.0232 - val_accuracy: 0.5606\n",
      "Epoch 1040/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0454 - accuracy: 0.5509 - val_loss: 1.0160 - val_accuracy: 0.5692\n",
      "Epoch 1041/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0475 - accuracy: 0.5461 - val_loss: 1.0180 - val_accuracy: 0.5558\n",
      "Epoch 1042/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0482 - accuracy: 0.5528 - val_loss: 1.0241 - val_accuracy: 0.5635\n",
      "Epoch 1043/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0451 - accuracy: 0.5463 - val_loss: 1.0205 - val_accuracy: 0.5712\n",
      "Epoch 1044/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0440 - accuracy: 0.5458 - val_loss: 1.0132 - val_accuracy: 0.5663\n",
      "Epoch 1045/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0450 - accuracy: 0.5449 - val_loss: 1.0204 - val_accuracy: 0.5635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1046/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0411 - accuracy: 0.5487 - val_loss: 1.0178 - val_accuracy: 0.5615\n",
      "Epoch 1047/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0464 - accuracy: 0.5492 - val_loss: 1.0309 - val_accuracy: 0.5490\n",
      "Epoch 1048/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0425 - accuracy: 0.5499 - val_loss: 1.0200 - val_accuracy: 0.5615\n",
      "Epoch 1049/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0502 - accuracy: 0.5432 - val_loss: 1.0206 - val_accuracy: 0.5683\n",
      "Epoch 1050/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0425 - accuracy: 0.5535 - val_loss: 1.0317 - val_accuracy: 0.5615\n",
      "Epoch 1051/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0466 - accuracy: 0.5504 - val_loss: 1.0179 - val_accuracy: 0.5692\n",
      "Epoch 1052/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0430 - accuracy: 0.5494 - val_loss: 1.0233 - val_accuracy: 0.5721\n",
      "Epoch 1053/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0505 - accuracy: 0.5451 - val_loss: 1.0233 - val_accuracy: 0.5587\n",
      "Epoch 1054/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0494 - accuracy: 0.5504 - val_loss: 1.0316 - val_accuracy: 0.5577\n",
      "Epoch 1055/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0506 - accuracy: 0.5511 - val_loss: 1.0203 - val_accuracy: 0.5635\n",
      "Epoch 1056/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0471 - accuracy: 0.5475 - val_loss: 1.0293 - val_accuracy: 0.5596\n",
      "Epoch 1057/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0499 - accuracy: 0.5463 - val_loss: 1.0328 - val_accuracy: 0.5740\n",
      "Epoch 1058/1500\n",
      "4157/4157 [==============================] - 0s 38us/step - loss: 1.0525 - accuracy: 0.5465 - val_loss: 1.0314 - val_accuracy: 0.5673\n",
      "Epoch 1059/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0440 - accuracy: 0.5550 - val_loss: 1.0272 - val_accuracy: 0.5606\n",
      "Epoch 1060/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0480 - accuracy: 0.5494 - val_loss: 1.0353 - val_accuracy: 0.5606\n",
      "Epoch 1061/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0494 - accuracy: 0.5499 - val_loss: 1.0250 - val_accuracy: 0.5692\n",
      "Epoch 1062/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0421 - accuracy: 0.5591 - val_loss: 1.0380 - val_accuracy: 0.5587\n",
      "Epoch 1063/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0466 - accuracy: 0.5465 - val_loss: 1.0288 - val_accuracy: 0.5654\n",
      "Epoch 1064/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0505 - accuracy: 0.5494 - val_loss: 1.0254 - val_accuracy: 0.5654\n",
      "Epoch 1065/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0441 - accuracy: 0.5545 - val_loss: 1.0230 - val_accuracy: 0.5673\n",
      "Epoch 1066/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0490 - accuracy: 0.5499 - val_loss: 1.0258 - val_accuracy: 0.5635\n",
      "Epoch 1067/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0433 - accuracy: 0.5547 - val_loss: 1.0200 - val_accuracy: 0.5615\n",
      "Epoch 1068/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0421 - accuracy: 0.5499 - val_loss: 1.0263 - val_accuracy: 0.5625\n",
      "Epoch 1069/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0460 - accuracy: 0.5463 - val_loss: 1.0285 - val_accuracy: 0.5731\n",
      "Epoch 1070/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0515 - accuracy: 0.5444 - val_loss: 1.0278 - val_accuracy: 0.5644\n",
      "Epoch 1071/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0486 - accuracy: 0.5468 - val_loss: 1.0352 - val_accuracy: 0.5519\n",
      "Epoch 1072/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0433 - accuracy: 0.5478 - val_loss: 1.0300 - val_accuracy: 0.5692\n",
      "Epoch 1073/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0440 - accuracy: 0.5504 - val_loss: 1.0326 - val_accuracy: 0.5606\n",
      "Epoch 1074/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0440 - accuracy: 0.5559 - val_loss: 1.0254 - val_accuracy: 0.5644\n",
      "Epoch 1075/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0454 - accuracy: 0.5511 - val_loss: 1.0385 - val_accuracy: 0.5635\n",
      "Epoch 1076/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0494 - accuracy: 0.5490 - val_loss: 1.0248 - val_accuracy: 0.5615\n",
      "Epoch 1077/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0445 - accuracy: 0.5468 - val_loss: 1.0310 - val_accuracy: 0.5673\n",
      "Epoch 1078/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0458 - accuracy: 0.5482 - val_loss: 1.0285 - val_accuracy: 0.5606\n",
      "Epoch 1079/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0426 - accuracy: 0.5475 - val_loss: 1.0292 - val_accuracy: 0.5567\n",
      "Epoch 1080/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0407 - accuracy: 0.5530 - val_loss: 1.0242 - val_accuracy: 0.5635\n",
      "Epoch 1081/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0381 - accuracy: 0.5506 - val_loss: 1.0232 - val_accuracy: 0.5635\n",
      "Epoch 1082/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0426 - accuracy: 0.5506 - val_loss: 1.0360 - val_accuracy: 0.5606\n",
      "Epoch 1083/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0426 - accuracy: 0.5487 - val_loss: 1.0233 - val_accuracy: 0.5654\n",
      "Epoch 1084/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0415 - accuracy: 0.5494 - val_loss: 1.0240 - val_accuracy: 0.5692\n",
      "Epoch 1085/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0483 - accuracy: 0.5506 - val_loss: 1.0209 - val_accuracy: 0.5673\n",
      "Epoch 1086/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0391 - accuracy: 0.5538 - val_loss: 1.0163 - val_accuracy: 0.5606\n",
      "Epoch 1087/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0452 - accuracy: 0.5545 - val_loss: 1.0192 - val_accuracy: 0.5663\n",
      "Epoch 1088/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0462 - accuracy: 0.5485 - val_loss: 1.0262 - val_accuracy: 0.5663\n",
      "Epoch 1089/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0432 - accuracy: 0.5502 - val_loss: 1.0265 - val_accuracy: 0.5721\n",
      "Epoch 1090/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0423 - accuracy: 0.5487 - val_loss: 1.0298 - val_accuracy: 0.5692\n",
      "Epoch 1091/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0440 - accuracy: 0.5521 - val_loss: 1.0200 - val_accuracy: 0.5663\n",
      "Epoch 1092/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0454 - accuracy: 0.5441 - val_loss: 1.0203 - val_accuracy: 0.5673\n",
      "Epoch 1093/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0480 - accuracy: 0.5482 - val_loss: 1.0238 - val_accuracy: 0.5635\n",
      "Epoch 1094/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0454 - accuracy: 0.5506 - val_loss: 1.0232 - val_accuracy: 0.5712\n",
      "Epoch 1095/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0431 - accuracy: 0.5574 - val_loss: 1.0217 - val_accuracy: 0.5721\n",
      "Epoch 1096/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0411 - accuracy: 0.5511 - val_loss: 1.0123 - val_accuracy: 0.5740\n",
      "Epoch 1097/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0441 - accuracy: 0.5518 - val_loss: 1.0201 - val_accuracy: 0.5673\n",
      "Epoch 1098/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0463 - accuracy: 0.5420 - val_loss: 1.0170 - val_accuracy: 0.5673\n",
      "Epoch 1099/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0478 - accuracy: 0.5499 - val_loss: 1.0228 - val_accuracy: 0.5673\n",
      "Epoch 1100/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0392 - accuracy: 0.5547 - val_loss: 1.0162 - val_accuracy: 0.5587\n",
      "Epoch 1101/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0466 - accuracy: 0.5478 - val_loss: 1.0112 - val_accuracy: 0.5712\n",
      "Epoch 1102/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0424 - accuracy: 0.5461 - val_loss: 1.0146 - val_accuracy: 0.5663\n",
      "Epoch 1103/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0421 - accuracy: 0.5429 - val_loss: 1.0159 - val_accuracy: 0.5644\n",
      "Epoch 1104/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0448 - accuracy: 0.5425 - val_loss: 1.0243 - val_accuracy: 0.5615\n",
      "Epoch 1105/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0411 - accuracy: 0.5470 - val_loss: 1.0220 - val_accuracy: 0.5654\n",
      "Epoch 1106/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0445 - accuracy: 0.5429 - val_loss: 1.0164 - val_accuracy: 0.5692\n",
      "Epoch 1107/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0408 - accuracy: 0.5540 - val_loss: 1.0248 - val_accuracy: 0.5625\n",
      "Epoch 1108/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0408 - accuracy: 0.5490 - val_loss: 1.0208 - val_accuracy: 0.5635\n",
      "Epoch 1109/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0404 - accuracy: 0.5557 - val_loss: 1.0296 - val_accuracy: 0.5702\n",
      "Epoch 1110/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0465 - accuracy: 0.5480 - val_loss: 1.0178 - val_accuracy: 0.5760\n",
      "Epoch 1111/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0410 - accuracy: 0.5490 - val_loss: 1.0361 - val_accuracy: 0.5635\n",
      "Epoch 1112/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0428 - accuracy: 0.5434 - val_loss: 1.0261 - val_accuracy: 0.5702\n",
      "Epoch 1113/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0445 - accuracy: 0.5482 - val_loss: 1.0341 - val_accuracy: 0.5712\n",
      "Epoch 1114/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0356 - accuracy: 0.5574 - val_loss: 1.0331 - val_accuracy: 0.5654\n",
      "Epoch 1115/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0372 - accuracy: 0.5542 - val_loss: 1.0310 - val_accuracy: 0.5644\n",
      "Epoch 1116/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0473 - accuracy: 0.5588 - val_loss: 1.0183 - val_accuracy: 0.5654\n",
      "Epoch 1117/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0471 - accuracy: 0.5514 - val_loss: 1.0181 - val_accuracy: 0.5683\n",
      "Epoch 1118/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0399 - accuracy: 0.5550 - val_loss: 1.0249 - val_accuracy: 0.5712\n",
      "Epoch 1119/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0428 - accuracy: 0.5504 - val_loss: 1.0290 - val_accuracy: 0.5606\n",
      "Epoch 1120/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0469 - accuracy: 0.5427 - val_loss: 1.0427 - val_accuracy: 0.5577\n",
      "Epoch 1121/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0481 - accuracy: 0.5502 - val_loss: 1.0263 - val_accuracy: 0.5606\n",
      "Epoch 1122/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0417 - accuracy: 0.5564 - val_loss: 1.0212 - val_accuracy: 0.5587\n",
      "Epoch 1123/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0423 - accuracy: 0.5514 - val_loss: 1.0216 - val_accuracy: 0.5673\n",
      "Epoch 1124/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0432 - accuracy: 0.5480 - val_loss: 1.0269 - val_accuracy: 0.5663\n",
      "Epoch 1125/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0497 - accuracy: 0.5502 - val_loss: 1.0360 - val_accuracy: 0.5702\n",
      "Epoch 1126/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0384 - accuracy: 0.5509 - val_loss: 1.0343 - val_accuracy: 0.5596\n",
      "Epoch 1127/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0457 - accuracy: 0.5413 - val_loss: 1.0181 - val_accuracy: 0.5673\n",
      "Epoch 1128/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0451 - accuracy: 0.5482 - val_loss: 1.0205 - val_accuracy: 0.5683\n",
      "Epoch 1129/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0441 - accuracy: 0.5518 - val_loss: 1.0179 - val_accuracy: 0.5673\n",
      "Epoch 1130/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0461 - accuracy: 0.5458 - val_loss: 1.0134 - val_accuracy: 0.5663\n",
      "Epoch 1131/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0418 - accuracy: 0.5511 - val_loss: 1.0237 - val_accuracy: 0.5644\n",
      "Epoch 1132/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0429 - accuracy: 0.5504 - val_loss: 1.0263 - val_accuracy: 0.5654\n",
      "Epoch 1133/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0352 - accuracy: 0.5475 - val_loss: 1.0256 - val_accuracy: 0.5663\n",
      "Epoch 1134/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0328 - accuracy: 0.5571 - val_loss: 1.0328 - val_accuracy: 0.5625\n",
      "Epoch 1135/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0425 - accuracy: 0.5511 - val_loss: 1.0199 - val_accuracy: 0.5673\n",
      "Epoch 1136/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0433 - accuracy: 0.5559 - val_loss: 1.0224 - val_accuracy: 0.5692\n",
      "Epoch 1137/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0390 - accuracy: 0.5473 - val_loss: 1.0129 - val_accuracy: 0.5721\n",
      "Epoch 1138/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0442 - accuracy: 0.5545 - val_loss: 1.0173 - val_accuracy: 0.5750\n",
      "Epoch 1139/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0425 - accuracy: 0.5540 - val_loss: 1.0215 - val_accuracy: 0.5702\n",
      "Epoch 1140/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0433 - accuracy: 0.5523 - val_loss: 1.0205 - val_accuracy: 0.5683\n",
      "Epoch 1141/1500\n",
      "4157/4157 [==============================] - 0s 41us/step - loss: 1.0392 - accuracy: 0.5559 - val_loss: 1.0186 - val_accuracy: 0.5673\n",
      "Epoch 1142/1500\n",
      "4157/4157 [==============================] - 0s 49us/step - loss: 1.0393 - accuracy: 0.5518 - val_loss: 1.0320 - val_accuracy: 0.5615\n",
      "Epoch 1143/1500\n",
      "4157/4157 [==============================] - 0s 43us/step - loss: 1.0414 - accuracy: 0.5506 - val_loss: 1.0284 - val_accuracy: 0.5712\n",
      "Epoch 1144/1500\n",
      "4157/4157 [==============================] - 0s 46us/step - loss: 1.0456 - accuracy: 0.5473 - val_loss: 1.0230 - val_accuracy: 0.5712\n",
      "Epoch 1145/1500\n",
      "4157/4157 [==============================] - 0s 53us/step - loss: 1.0436 - accuracy: 0.5547 - val_loss: 1.0327 - val_accuracy: 0.5663\n",
      "Epoch 1146/1500\n",
      "4157/4157 [==============================] - 0s 38us/step - loss: 1.0416 - accuracy: 0.5533 - val_loss: 1.0244 - val_accuracy: 0.5663\n",
      "Epoch 1147/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0385 - accuracy: 0.5439 - val_loss: 1.0367 - val_accuracy: 0.5587\n",
      "Epoch 1148/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0401 - accuracy: 0.5562 - val_loss: 1.0190 - val_accuracy: 0.5673\n",
      "Epoch 1149/1500\n",
      "4157/4157 [==============================] - 0s 47us/step - loss: 1.0348 - accuracy: 0.5559 - val_loss: 1.0260 - val_accuracy: 0.5683\n",
      "Epoch 1150/1500\n",
      "4157/4157 [==============================] - 0s 54us/step - loss: 1.0428 - accuracy: 0.5579 - val_loss: 1.0251 - val_accuracy: 0.5635\n",
      "Epoch 1151/1500\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 1.0429 - accuracy: 0.54 - 0s 44us/step - loss: 1.0429 - accuracy: 0.5518 - val_loss: 1.0298 - val_accuracy: 0.5712\n",
      "Epoch 1152/1500\n",
      "4157/4157 [==============================] - 0s 48us/step - loss: 1.0426 - accuracy: 0.5550 - val_loss: 1.0194 - val_accuracy: 0.5625\n",
      "Epoch 1153/1500\n",
      "4157/4157 [==============================] - 0s 53us/step - loss: 1.0434 - accuracy: 0.5509 - val_loss: 1.0170 - val_accuracy: 0.5740\n",
      "Epoch 1154/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 37us/step - loss: 1.0415 - accuracy: 0.5502 - val_loss: 1.0221 - val_accuracy: 0.5760\n",
      "Epoch 1155/1500\n",
      "4157/4157 [==============================] - 0s 37us/step - loss: 1.0379 - accuracy: 0.5651 - val_loss: 1.0251 - val_accuracy: 0.5615\n",
      "Epoch 1156/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0367 - accuracy: 0.5579 - val_loss: 1.0308 - val_accuracy: 0.5654\n",
      "Epoch 1157/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0422 - accuracy: 0.5485 - val_loss: 1.0285 - val_accuracy: 0.5673\n",
      "Epoch 1158/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0373 - accuracy: 0.5540 - val_loss: 1.0291 - val_accuracy: 0.5673\n",
      "Epoch 1159/1500\n",
      "4157/4157 [==============================] - 0s 40us/step - loss: 1.0386 - accuracy: 0.5603 - val_loss: 1.0282 - val_accuracy: 0.5712\n",
      "Epoch 1160/1500\n",
      "4157/4157 [==============================] - 0s 37us/step - loss: 1.0389 - accuracy: 0.5535 - val_loss: 1.0270 - val_accuracy: 0.5702\n",
      "Epoch 1161/1500\n",
      "4157/4157 [==============================] - 0s 43us/step - loss: 1.0413 - accuracy: 0.5487 - val_loss: 1.0299 - val_accuracy: 0.5673\n",
      "Epoch 1162/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0505 - accuracy: 0.5422 - val_loss: 1.0326 - val_accuracy: 0.5615\n",
      "Epoch 1163/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0417 - accuracy: 0.5516 - val_loss: 1.0311 - val_accuracy: 0.5654\n",
      "Epoch 1164/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0394 - accuracy: 0.5571 - val_loss: 1.0313 - val_accuracy: 0.5654\n",
      "Epoch 1165/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0434 - accuracy: 0.5535 - val_loss: 1.0320 - val_accuracy: 0.5731\n",
      "Epoch 1166/1500\n",
      "4157/4157 [==============================] - 0s 37us/step - loss: 1.0391 - accuracy: 0.5504 - val_loss: 1.0265 - val_accuracy: 0.5644\n",
      "Epoch 1167/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0414 - accuracy: 0.5475 - val_loss: 1.0309 - val_accuracy: 0.5644\n",
      "Epoch 1168/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0395 - accuracy: 0.5521 - val_loss: 1.0306 - val_accuracy: 0.5644\n",
      "Epoch 1169/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0413 - accuracy: 0.5526 - val_loss: 1.0245 - val_accuracy: 0.5635\n",
      "Epoch 1170/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5509 - val_loss: 1.0228 - val_accuracy: 0.5692\n",
      "Epoch 1171/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0402 - accuracy: 0.5528 - val_loss: 1.0301 - val_accuracy: 0.5644\n",
      "Epoch 1172/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0368 - accuracy: 0.5530 - val_loss: 1.0251 - val_accuracy: 0.5683\n",
      "Epoch 1173/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0371 - accuracy: 0.5557 - val_loss: 1.0290 - val_accuracy: 0.5663\n",
      "Epoch 1174/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0421 - accuracy: 0.5518 - val_loss: 1.0259 - val_accuracy: 0.5644\n",
      "Epoch 1175/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0353 - accuracy: 0.5480 - val_loss: 1.0321 - val_accuracy: 0.5663\n",
      "Epoch 1176/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0384 - accuracy: 0.5509 - val_loss: 1.0251 - val_accuracy: 0.5644\n",
      "Epoch 1177/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0336 - accuracy: 0.5545 - val_loss: 1.0279 - val_accuracy: 0.5692\n",
      "Epoch 1178/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0382 - accuracy: 0.5468 - val_loss: 1.0320 - val_accuracy: 0.5654\n",
      "Epoch 1179/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0411 - accuracy: 0.5509 - val_loss: 1.0331 - val_accuracy: 0.5721\n",
      "Epoch 1180/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0381 - accuracy: 0.5552 - val_loss: 1.0340 - val_accuracy: 0.5721\n",
      "Epoch 1181/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0382 - accuracy: 0.5451 - val_loss: 1.0321 - val_accuracy: 0.5625\n",
      "Epoch 1182/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0382 - accuracy: 0.5579 - val_loss: 1.0392 - val_accuracy: 0.5558\n",
      "Epoch 1183/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0422 - accuracy: 0.5465 - val_loss: 1.0300 - val_accuracy: 0.5654\n",
      "Epoch 1184/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0375 - accuracy: 0.5514 - val_loss: 1.0340 - val_accuracy: 0.5635\n",
      "Epoch 1185/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0391 - accuracy: 0.5468 - val_loss: 1.0334 - val_accuracy: 0.5596\n",
      "Epoch 1186/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0354 - accuracy: 0.5530 - val_loss: 1.0360 - val_accuracy: 0.5702\n",
      "Epoch 1187/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0371 - accuracy: 0.5557 - val_loss: 1.0318 - val_accuracy: 0.5644\n",
      "Epoch 1188/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0398 - accuracy: 0.5480 - val_loss: 1.0336 - val_accuracy: 0.5712\n",
      "Epoch 1189/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0386 - accuracy: 0.5463 - val_loss: 1.0368 - val_accuracy: 0.5625\n",
      "Epoch 1190/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0345 - accuracy: 0.5545 - val_loss: 1.0297 - val_accuracy: 0.5577\n",
      "Epoch 1191/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0349 - accuracy: 0.5494 - val_loss: 1.0352 - val_accuracy: 0.5625\n",
      "Epoch 1192/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0368 - accuracy: 0.5521 - val_loss: 1.0414 - val_accuracy: 0.5548\n",
      "Epoch 1193/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0427 - accuracy: 0.5550 - val_loss: 1.0227 - val_accuracy: 0.5663\n",
      "Epoch 1194/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0372 - accuracy: 0.5499 - val_loss: 1.0280 - val_accuracy: 0.5663\n",
      "Epoch 1195/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0402 - accuracy: 0.5514 - val_loss: 1.0396 - val_accuracy: 0.5683\n",
      "Epoch 1196/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0346 - accuracy: 0.5535 - val_loss: 1.0396 - val_accuracy: 0.5558\n",
      "Epoch 1197/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0355 - accuracy: 0.5564 - val_loss: 1.0335 - val_accuracy: 0.5654\n",
      "Epoch 1198/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0403 - accuracy: 0.5576 - val_loss: 1.0224 - val_accuracy: 0.5644\n",
      "Epoch 1199/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0323 - accuracy: 0.5540 - val_loss: 1.0284 - val_accuracy: 0.5683\n",
      "Epoch 1200/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0334 - accuracy: 0.5571 - val_loss: 1.0308 - val_accuracy: 0.5654\n",
      "Epoch 1201/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0361 - accuracy: 0.5557 - val_loss: 1.0245 - val_accuracy: 0.5596\n",
      "Epoch 1202/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0363 - accuracy: 0.5509 - val_loss: 1.0235 - val_accuracy: 0.5673\n",
      "Epoch 1203/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0411 - accuracy: 0.5554 - val_loss: 1.0298 - val_accuracy: 0.5644\n",
      "Epoch 1204/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0346 - accuracy: 0.5499 - val_loss: 1.0325 - val_accuracy: 0.5692\n",
      "Epoch 1205/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0370 - accuracy: 0.5499 - val_loss: 1.0242 - val_accuracy: 0.5625\n",
      "Epoch 1206/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0380 - accuracy: 0.5550 - val_loss: 1.0292 - val_accuracy: 0.5702\n",
      "Epoch 1207/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0426 - accuracy: 0.5449 - val_loss: 1.0210 - val_accuracy: 0.5712\n",
      "Epoch 1208/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0360 - accuracy: 0.5463 - val_loss: 1.0246 - val_accuracy: 0.5731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1209/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0319 - accuracy: 0.5499 - val_loss: 1.0309 - val_accuracy: 0.5567\n",
      "Epoch 1210/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0394 - accuracy: 0.5490 - val_loss: 1.0180 - val_accuracy: 0.5769\n",
      "Epoch 1211/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0317 - accuracy: 0.5516 - val_loss: 1.0309 - val_accuracy: 0.5673\n",
      "Epoch 1212/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0471 - accuracy: 0.5499 - val_loss: 1.0260 - val_accuracy: 0.5740\n",
      "Epoch 1213/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0358 - accuracy: 0.5528 - val_loss: 1.0252 - val_accuracy: 0.5692\n",
      "Epoch 1214/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0398 - accuracy: 0.5453 - val_loss: 1.0307 - val_accuracy: 0.5760\n",
      "Epoch 1215/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0390 - accuracy: 0.5569 - val_loss: 1.0247 - val_accuracy: 0.5673\n",
      "Epoch 1216/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0324 - accuracy: 0.5521 - val_loss: 1.0244 - val_accuracy: 0.5750\n",
      "Epoch 1217/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0397 - accuracy: 0.5499 - val_loss: 1.0233 - val_accuracy: 0.5712\n",
      "Epoch 1218/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0368 - accuracy: 0.5533 - val_loss: 1.0306 - val_accuracy: 0.5663\n",
      "Epoch 1219/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0350 - accuracy: 0.5504 - val_loss: 1.0282 - val_accuracy: 0.5712\n",
      "Epoch 1220/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0307 - accuracy: 0.5509 - val_loss: 1.0190 - val_accuracy: 0.5702\n",
      "Epoch 1221/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0341 - accuracy: 0.5622 - val_loss: 1.0212 - val_accuracy: 0.5625\n",
      "Epoch 1222/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0378 - accuracy: 0.5542 - val_loss: 1.0294 - val_accuracy: 0.5712\n",
      "Epoch 1223/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0376 - accuracy: 0.5461 - val_loss: 1.0286 - val_accuracy: 0.5654\n",
      "Epoch 1224/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0314 - accuracy: 0.5511 - val_loss: 1.0277 - val_accuracy: 0.5769\n",
      "Epoch 1225/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0380 - accuracy: 0.5516 - val_loss: 1.0260 - val_accuracy: 0.5798\n",
      "Epoch 1226/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0391 - accuracy: 0.5509 - val_loss: 1.0244 - val_accuracy: 0.5750\n",
      "Epoch 1227/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0406 - accuracy: 0.5463 - val_loss: 1.0298 - val_accuracy: 0.5808\n",
      "Epoch 1228/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0426 - accuracy: 0.5518 - val_loss: 1.0337 - val_accuracy: 0.5644\n",
      "Epoch 1229/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0344 - accuracy: 0.5502 - val_loss: 1.0298 - val_accuracy: 0.5788\n",
      "Epoch 1230/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0351 - accuracy: 0.5571 - val_loss: 1.0294 - val_accuracy: 0.5635\n",
      "Epoch 1231/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0352 - accuracy: 0.5547 - val_loss: 1.0273 - val_accuracy: 0.5644\n",
      "Epoch 1232/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5567 - val_loss: 1.0321 - val_accuracy: 0.5567\n",
      "Epoch 1233/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0372 - accuracy: 0.5516 - val_loss: 1.0322 - val_accuracy: 0.5654\n",
      "Epoch 1234/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0357 - accuracy: 0.5557 - val_loss: 1.0368 - val_accuracy: 0.5644\n",
      "Epoch 1235/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0322 - accuracy: 0.5607 - val_loss: 1.0382 - val_accuracy: 0.5577\n",
      "Epoch 1236/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0410 - accuracy: 0.5478 - val_loss: 1.0481 - val_accuracy: 0.5615\n",
      "Epoch 1237/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0331 - accuracy: 0.5591 - val_loss: 1.0312 - val_accuracy: 0.5635\n",
      "Epoch 1238/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0399 - accuracy: 0.5538 - val_loss: 1.0280 - val_accuracy: 0.5683\n",
      "Epoch 1239/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0313 - accuracy: 0.5511 - val_loss: 1.0288 - val_accuracy: 0.5721\n",
      "Epoch 1240/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0329 - accuracy: 0.5571 - val_loss: 1.0246 - val_accuracy: 0.5798\n",
      "Epoch 1241/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0317 - accuracy: 0.5547 - val_loss: 1.0295 - val_accuracy: 0.5750\n",
      "Epoch 1242/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0335 - accuracy: 0.5528 - val_loss: 1.0241 - val_accuracy: 0.5740\n",
      "Epoch 1243/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0344 - accuracy: 0.5610 - val_loss: 1.0294 - val_accuracy: 0.5750\n",
      "Epoch 1244/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0348 - accuracy: 0.5591 - val_loss: 1.0302 - val_accuracy: 0.5740\n",
      "Epoch 1245/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0310 - accuracy: 0.5473 - val_loss: 1.0264 - val_accuracy: 0.5692\n",
      "Epoch 1246/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0391 - accuracy: 0.5533 - val_loss: 1.0154 - val_accuracy: 0.5692\n",
      "Epoch 1247/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0327 - accuracy: 0.5490 - val_loss: 1.0261 - val_accuracy: 0.5673\n",
      "Epoch 1248/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0379 - accuracy: 0.5509 - val_loss: 1.0258 - val_accuracy: 0.5712\n",
      "Epoch 1249/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0336 - accuracy: 0.5622 - val_loss: 1.0317 - val_accuracy: 0.5673\n",
      "Epoch 1250/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0403 - accuracy: 0.5526 - val_loss: 1.0229 - val_accuracy: 0.5731\n",
      "Epoch 1251/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0338 - accuracy: 0.5478 - val_loss: 1.0201 - val_accuracy: 0.5779\n",
      "Epoch 1252/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0395 - accuracy: 0.5468 - val_loss: 1.0264 - val_accuracy: 0.5769\n",
      "Epoch 1253/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0371 - accuracy: 0.5514 - val_loss: 1.0230 - val_accuracy: 0.5721\n",
      "Epoch 1254/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0348 - accuracy: 0.5542 - val_loss: 1.0281 - val_accuracy: 0.5750\n",
      "Epoch 1255/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0348 - accuracy: 0.5554 - val_loss: 1.0230 - val_accuracy: 0.5663\n",
      "Epoch 1256/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0316 - accuracy: 0.5562 - val_loss: 1.0289 - val_accuracy: 0.5740\n",
      "Epoch 1257/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0277 - accuracy: 0.5579 - val_loss: 1.0272 - val_accuracy: 0.5644\n",
      "Epoch 1258/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0315 - accuracy: 0.5487 - val_loss: 1.0306 - val_accuracy: 0.5750\n",
      "Epoch 1259/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0352 - accuracy: 0.5540 - val_loss: 1.0202 - val_accuracy: 0.5740\n",
      "Epoch 1260/1500\n",
      "4157/4157 [==============================] - 0s 43us/step - loss: 1.0398 - accuracy: 0.5465 - val_loss: 1.0272 - val_accuracy: 0.5702\n",
      "Epoch 1261/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0317 - accuracy: 0.5624 - val_loss: 1.0277 - val_accuracy: 0.5798\n",
      "Epoch 1262/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0284 - accuracy: 0.5449 - val_loss: 1.0208 - val_accuracy: 0.5731\n",
      "Epoch 1263/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0307 - accuracy: 0.5530 - val_loss: 1.0227 - val_accuracy: 0.5683\n",
      "Epoch 1264/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0400 - accuracy: 0.5545 - val_loss: 1.0215 - val_accuracy: 0.5731\n",
      "Epoch 1265/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0336 - accuracy: 0.5504 - val_loss: 1.0236 - val_accuracy: 0.5683\n",
      "Epoch 1266/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5516 - val_loss: 1.0180 - val_accuracy: 0.5663\n",
      "Epoch 1267/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0374 - accuracy: 0.5463 - val_loss: 1.0217 - val_accuracy: 0.5808\n",
      "Epoch 1268/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0362 - accuracy: 0.5504 - val_loss: 1.0200 - val_accuracy: 0.5654\n",
      "Epoch 1269/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0364 - accuracy: 0.5552 - val_loss: 1.0313 - val_accuracy: 0.5740\n",
      "Epoch 1270/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0292 - accuracy: 0.5603 - val_loss: 1.0330 - val_accuracy: 0.5750\n",
      "Epoch 1271/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0335 - accuracy: 0.5586 - val_loss: 1.0280 - val_accuracy: 0.5683\n",
      "Epoch 1272/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5557 - val_loss: 1.0250 - val_accuracy: 0.5740\n",
      "Epoch 1273/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0277 - accuracy: 0.5612 - val_loss: 1.0287 - val_accuracy: 0.5788\n",
      "Epoch 1274/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0289 - accuracy: 0.5603 - val_loss: 1.0344 - val_accuracy: 0.5740\n",
      "Epoch 1275/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0344 - accuracy: 0.5627 - val_loss: 1.0259 - val_accuracy: 0.5683\n",
      "Epoch 1276/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0363 - accuracy: 0.5535 - val_loss: 1.0343 - val_accuracy: 0.5740\n",
      "Epoch 1277/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0371 - accuracy: 0.5497 - val_loss: 1.0293 - val_accuracy: 0.5721\n",
      "Epoch 1278/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0347 - accuracy: 0.5511 - val_loss: 1.0297 - val_accuracy: 0.5692\n",
      "Epoch 1279/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0357 - accuracy: 0.5538 - val_loss: 1.0353 - val_accuracy: 0.5702\n",
      "Epoch 1280/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0372 - accuracy: 0.5518 - val_loss: 1.0234 - val_accuracy: 0.5788\n",
      "Epoch 1281/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0397 - accuracy: 0.5540 - val_loss: 1.0211 - val_accuracy: 0.5702\n",
      "Epoch 1282/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0442 - accuracy: 0.5482 - val_loss: 1.0277 - val_accuracy: 0.5750\n",
      "Epoch 1283/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0338 - accuracy: 0.5571 - val_loss: 1.0279 - val_accuracy: 0.5769\n",
      "Epoch 1284/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0372 - accuracy: 0.5456 - val_loss: 1.0326 - val_accuracy: 0.5702\n",
      "Epoch 1285/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0336 - accuracy: 0.5562 - val_loss: 1.0237 - val_accuracy: 0.5731\n",
      "Epoch 1286/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0434 - accuracy: 0.5547 - val_loss: 1.0253 - val_accuracy: 0.5702\n",
      "Epoch 1287/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0312 - accuracy: 0.5528 - val_loss: 1.0312 - val_accuracy: 0.5731\n",
      "Epoch 1288/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0376 - accuracy: 0.5533 - val_loss: 1.0321 - val_accuracy: 0.5788\n",
      "Epoch 1289/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0330 - accuracy: 0.5593 - val_loss: 1.0289 - val_accuracy: 0.5683\n",
      "Epoch 1290/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0310 - accuracy: 0.5538 - val_loss: 1.0351 - val_accuracy: 0.5692\n",
      "Epoch 1291/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0360 - accuracy: 0.5598 - val_loss: 1.0367 - val_accuracy: 0.5798\n",
      "Epoch 1292/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0415 - accuracy: 0.5494 - val_loss: 1.0338 - val_accuracy: 0.5721\n",
      "Epoch 1293/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0298 - accuracy: 0.5576 - val_loss: 1.0304 - val_accuracy: 0.5740\n",
      "Epoch 1294/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0304 - accuracy: 0.5564 - val_loss: 1.0416 - val_accuracy: 0.5750\n",
      "Epoch 1295/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0322 - accuracy: 0.5574 - val_loss: 1.0296 - val_accuracy: 0.5596\n",
      "Epoch 1296/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0339 - accuracy: 0.5579 - val_loss: 1.0167 - val_accuracy: 0.5692\n",
      "Epoch 1297/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0338 - accuracy: 0.5583 - val_loss: 1.0237 - val_accuracy: 0.5712\n",
      "Epoch 1298/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0343 - accuracy: 0.5538 - val_loss: 1.0240 - val_accuracy: 0.5683\n",
      "Epoch 1299/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0296 - accuracy: 0.5600 - val_loss: 1.0288 - val_accuracy: 0.5740\n",
      "Epoch 1300/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0294 - accuracy: 0.5603 - val_loss: 1.0283 - val_accuracy: 0.5779\n",
      "Epoch 1301/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0300 - accuracy: 0.5542 - val_loss: 1.0135 - val_accuracy: 0.5702\n",
      "Epoch 1302/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0271 - accuracy: 0.5559 - val_loss: 1.0330 - val_accuracy: 0.5760\n",
      "Epoch 1303/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0269 - accuracy: 0.5475 - val_loss: 1.0370 - val_accuracy: 0.5654\n",
      "Epoch 1304/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0278 - accuracy: 0.5545 - val_loss: 1.0343 - val_accuracy: 0.5663\n",
      "Epoch 1305/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0429 - accuracy: 0.5595 - val_loss: 1.0224 - val_accuracy: 0.5740\n",
      "Epoch 1306/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5612 - val_loss: 1.0325 - val_accuracy: 0.5769\n",
      "Epoch 1307/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0370 - accuracy: 0.5588 - val_loss: 1.0313 - val_accuracy: 0.5788\n",
      "Epoch 1308/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0339 - accuracy: 0.5576 - val_loss: 1.0249 - val_accuracy: 0.5721\n",
      "Epoch 1309/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0301 - accuracy: 0.5564 - val_loss: 1.0275 - val_accuracy: 0.5673\n",
      "Epoch 1310/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0347 - accuracy: 0.5588 - val_loss: 1.0230 - val_accuracy: 0.5712\n",
      "Epoch 1311/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0337 - accuracy: 0.5615 - val_loss: 1.0299 - val_accuracy: 0.5798\n",
      "Epoch 1312/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0352 - accuracy: 0.5506 - val_loss: 1.0386 - val_accuracy: 0.5702\n",
      "Epoch 1313/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0326 - accuracy: 0.5523 - val_loss: 1.0345 - val_accuracy: 0.5760\n",
      "Epoch 1314/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0364 - accuracy: 0.5550 - val_loss: 1.0315 - val_accuracy: 0.5740\n",
      "Epoch 1315/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0358 - accuracy: 0.5482 - val_loss: 1.0429 - val_accuracy: 0.5654\n",
      "Epoch 1316/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0292 - accuracy: 0.5540 - val_loss: 1.0307 - val_accuracy: 0.5750\n",
      "Epoch 1317/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0300 - accuracy: 0.5554 - val_loss: 1.0276 - val_accuracy: 0.5740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1318/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0339 - accuracy: 0.5612 - val_loss: 1.0269 - val_accuracy: 0.5731\n",
      "Epoch 1319/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0362 - accuracy: 0.5492 - val_loss: 1.0231 - val_accuracy: 0.5750\n",
      "Epoch 1320/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0274 - accuracy: 0.5567 - val_loss: 1.0412 - val_accuracy: 0.5654\n",
      "Epoch 1321/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0329 - accuracy: 0.5499 - val_loss: 1.0317 - val_accuracy: 0.5760\n",
      "Epoch 1322/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0327 - accuracy: 0.5571 - val_loss: 1.0324 - val_accuracy: 0.5673\n",
      "Epoch 1323/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0310 - accuracy: 0.5615 - val_loss: 1.0333 - val_accuracy: 0.5663\n",
      "Epoch 1324/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0273 - accuracy: 0.5552 - val_loss: 1.0213 - val_accuracy: 0.5731\n",
      "Epoch 1325/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5492 - val_loss: 1.0305 - val_accuracy: 0.5673\n",
      "Epoch 1326/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0308 - accuracy: 0.5591 - val_loss: 1.0277 - val_accuracy: 0.5606\n",
      "Epoch 1327/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0271 - accuracy: 0.5554 - val_loss: 1.0305 - val_accuracy: 0.5731\n",
      "Epoch 1328/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0368 - accuracy: 0.5526 - val_loss: 1.0403 - val_accuracy: 0.5606\n",
      "Epoch 1329/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0323 - accuracy: 0.5552 - val_loss: 1.0342 - val_accuracy: 0.5731\n",
      "Epoch 1330/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0375 - accuracy: 0.5514 - val_loss: 1.0299 - val_accuracy: 0.5760\n",
      "Epoch 1331/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0288 - accuracy: 0.5591 - val_loss: 1.0339 - val_accuracy: 0.5692\n",
      "Epoch 1332/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0350 - accuracy: 0.5526 - val_loss: 1.0378 - val_accuracy: 0.5683\n",
      "Epoch 1333/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0314 - accuracy: 0.5552 - val_loss: 1.0356 - val_accuracy: 0.5731\n",
      "Epoch 1334/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0311 - accuracy: 0.5588 - val_loss: 1.0287 - val_accuracy: 0.5663\n",
      "Epoch 1335/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0314 - accuracy: 0.5586 - val_loss: 1.0429 - val_accuracy: 0.5740\n",
      "Epoch 1336/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0286 - accuracy: 0.5574 - val_loss: 1.0229 - val_accuracy: 0.5740\n",
      "Epoch 1337/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0290 - accuracy: 0.5581 - val_loss: 1.0400 - val_accuracy: 0.5673\n",
      "Epoch 1338/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0304 - accuracy: 0.5528 - val_loss: 1.0281 - val_accuracy: 0.5663\n",
      "Epoch 1339/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5518 - val_loss: 1.0328 - val_accuracy: 0.5673\n",
      "Epoch 1340/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0291 - accuracy: 0.5521 - val_loss: 1.0332 - val_accuracy: 0.5702\n",
      "Epoch 1341/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0335 - accuracy: 0.5494 - val_loss: 1.0283 - val_accuracy: 0.5731\n",
      "Epoch 1342/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0365 - accuracy: 0.5557 - val_loss: 1.0316 - val_accuracy: 0.5721\n",
      "Epoch 1343/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0308 - accuracy: 0.5550 - val_loss: 1.0280 - val_accuracy: 0.5702\n",
      "Epoch 1344/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0271 - accuracy: 0.5631 - val_loss: 1.0343 - val_accuracy: 0.5731\n",
      "Epoch 1345/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0306 - accuracy: 0.5567 - val_loss: 1.0339 - val_accuracy: 0.5712\n",
      "Epoch 1346/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0319 - accuracy: 0.5593 - val_loss: 1.0358 - val_accuracy: 0.5712\n",
      "Epoch 1347/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0289 - accuracy: 0.5557 - val_loss: 1.0262 - val_accuracy: 0.5721\n",
      "Epoch 1348/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0330 - accuracy: 0.5581 - val_loss: 1.0259 - val_accuracy: 0.5740\n",
      "Epoch 1349/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0298 - accuracy: 0.5562 - val_loss: 1.0293 - val_accuracy: 0.5712\n",
      "Epoch 1350/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0323 - accuracy: 0.5499 - val_loss: 1.0280 - val_accuracy: 0.5721\n",
      "Epoch 1351/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0279 - accuracy: 0.5550 - val_loss: 1.0204 - val_accuracy: 0.5740\n",
      "Epoch 1352/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0295 - accuracy: 0.5542 - val_loss: 1.0161 - val_accuracy: 0.5750\n",
      "Epoch 1353/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0289 - accuracy: 0.5605 - val_loss: 1.0229 - val_accuracy: 0.5731\n",
      "Epoch 1354/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0321 - accuracy: 0.5557 - val_loss: 1.0318 - val_accuracy: 0.5702\n",
      "Epoch 1355/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0325 - accuracy: 0.5535 - val_loss: 1.0376 - val_accuracy: 0.5731\n",
      "Epoch 1356/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0307 - accuracy: 0.5545 - val_loss: 1.0404 - val_accuracy: 0.5712\n",
      "Epoch 1357/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0292 - accuracy: 0.5547 - val_loss: 1.0310 - val_accuracy: 0.5692\n",
      "Epoch 1358/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0317 - accuracy: 0.5535 - val_loss: 1.0348 - val_accuracy: 0.5673\n",
      "Epoch 1359/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0322 - accuracy: 0.5569 - val_loss: 1.0332 - val_accuracy: 0.5673\n",
      "Epoch 1360/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0322 - accuracy: 0.5595 - val_loss: 1.0346 - val_accuracy: 0.5673\n",
      "Epoch 1361/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0251 - accuracy: 0.5547 - val_loss: 1.0359 - val_accuracy: 0.5731\n",
      "Epoch 1362/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0317 - accuracy: 0.5559 - val_loss: 1.0289 - val_accuracy: 0.5692\n",
      "Epoch 1363/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0344 - accuracy: 0.5583 - val_loss: 1.0274 - val_accuracy: 0.5673\n",
      "Epoch 1364/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0269 - accuracy: 0.5552 - val_loss: 1.0359 - val_accuracy: 0.5740\n",
      "Epoch 1365/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0295 - accuracy: 0.5574 - val_loss: 1.0276 - val_accuracy: 0.5673\n",
      "Epoch 1366/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0336 - accuracy: 0.5574 - val_loss: 1.0245 - val_accuracy: 0.5663\n",
      "Epoch 1367/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0325 - accuracy: 0.5526 - val_loss: 1.0233 - val_accuracy: 0.5769\n",
      "Epoch 1368/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0288 - accuracy: 0.5557 - val_loss: 1.0307 - val_accuracy: 0.5731\n",
      "Epoch 1369/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0343 - accuracy: 0.5538 - val_loss: 1.0334 - val_accuracy: 0.5712\n",
      "Epoch 1370/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0303 - accuracy: 0.5615 - val_loss: 1.0264 - val_accuracy: 0.5731\n",
      "Epoch 1371/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0280 - accuracy: 0.5641 - val_loss: 1.0218 - val_accuracy: 0.5683\n",
      "Epoch 1372/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0263 - accuracy: 0.5559 - val_loss: 1.0241 - val_accuracy: 0.5750\n",
      "Epoch 1373/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0255 - accuracy: 0.5545 - val_loss: 1.0367 - val_accuracy: 0.5663\n",
      "Epoch 1374/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0268 - accuracy: 0.5559 - val_loss: 1.0321 - val_accuracy: 0.5683\n",
      "Epoch 1375/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0229 - accuracy: 0.5576 - val_loss: 1.0495 - val_accuracy: 0.5683\n",
      "Epoch 1376/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0288 - accuracy: 0.5550 - val_loss: 1.0474 - val_accuracy: 0.5644\n",
      "Epoch 1377/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0221 - accuracy: 0.5574 - val_loss: 1.0412 - val_accuracy: 0.5625\n",
      "Epoch 1378/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0280 - accuracy: 0.5530 - val_loss: 1.0361 - val_accuracy: 0.5673\n",
      "Epoch 1379/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0253 - accuracy: 0.5564 - val_loss: 1.0300 - val_accuracy: 0.5702\n",
      "Epoch 1380/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0349 - accuracy: 0.5499 - val_loss: 1.0368 - val_accuracy: 0.5673\n",
      "Epoch 1381/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0307 - accuracy: 0.5586 - val_loss: 1.0281 - val_accuracy: 0.5683\n",
      "Epoch 1382/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0260 - accuracy: 0.5530 - val_loss: 1.0344 - val_accuracy: 0.5702\n",
      "Epoch 1383/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0302 - accuracy: 0.5605 - val_loss: 1.0336 - val_accuracy: 0.5673\n",
      "Epoch 1384/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0332 - accuracy: 0.5542 - val_loss: 1.0270 - val_accuracy: 0.5721\n",
      "Epoch 1385/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0314 - accuracy: 0.5612 - val_loss: 1.0343 - val_accuracy: 0.5567\n",
      "Epoch 1386/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0288 - accuracy: 0.5478 - val_loss: 1.0353 - val_accuracy: 0.5654\n",
      "Epoch 1387/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0353 - accuracy: 0.5480 - val_loss: 1.0400 - val_accuracy: 0.5615\n",
      "Epoch 1388/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0261 - accuracy: 0.5617 - val_loss: 1.0391 - val_accuracy: 0.5721\n",
      "Epoch 1389/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0256 - accuracy: 0.5530 - val_loss: 1.0228 - val_accuracy: 0.5654\n",
      "Epoch 1390/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0321 - accuracy: 0.5526 - val_loss: 1.0220 - val_accuracy: 0.5683\n",
      "Epoch 1391/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0301 - accuracy: 0.5643 - val_loss: 1.0323 - val_accuracy: 0.5760\n",
      "Epoch 1392/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0315 - accuracy: 0.5598 - val_loss: 1.0298 - val_accuracy: 0.5673\n",
      "Epoch 1393/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0312 - accuracy: 0.5581 - val_loss: 1.0308 - val_accuracy: 0.5663\n",
      "Epoch 1394/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0224 - accuracy: 0.5576 - val_loss: 1.0294 - val_accuracy: 0.5712\n",
      "Epoch 1395/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0284 - accuracy: 0.5586 - val_loss: 1.0382 - val_accuracy: 0.5625\n",
      "Epoch 1396/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0283 - accuracy: 0.5586 - val_loss: 1.0349 - val_accuracy: 0.5663\n",
      "Epoch 1397/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0369 - accuracy: 0.5581 - val_loss: 1.0267 - val_accuracy: 0.5615\n",
      "Epoch 1398/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0295 - accuracy: 0.5600 - val_loss: 1.0199 - val_accuracy: 0.5683\n",
      "Epoch 1399/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0339 - accuracy: 0.5528 - val_loss: 1.0297 - val_accuracy: 0.5654\n",
      "Epoch 1400/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0259 - accuracy: 0.5550 - val_loss: 1.0332 - val_accuracy: 0.5625\n",
      "Epoch 1401/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0262 - accuracy: 0.5554 - val_loss: 1.0429 - val_accuracy: 0.5654\n",
      "Epoch 1402/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0309 - accuracy: 0.5612 - val_loss: 1.0439 - val_accuracy: 0.5663\n",
      "Epoch 1403/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0293 - accuracy: 0.5600 - val_loss: 1.0370 - val_accuracy: 0.5663\n",
      "Epoch 1404/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0320 - accuracy: 0.5579 - val_loss: 1.0239 - val_accuracy: 0.5644\n",
      "Epoch 1405/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0230 - accuracy: 0.5603 - val_loss: 1.0280 - val_accuracy: 0.5644\n",
      "Epoch 1406/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0289 - accuracy: 0.5617 - val_loss: 1.0292 - val_accuracy: 0.5702\n",
      "Epoch 1407/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0300 - accuracy: 0.5492 - val_loss: 1.0265 - val_accuracy: 0.5702\n",
      "Epoch 1408/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0253 - accuracy: 0.5581 - val_loss: 1.0274 - val_accuracy: 0.5712\n",
      "Epoch 1409/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0238 - accuracy: 0.5562 - val_loss: 1.0263 - val_accuracy: 0.5692\n",
      "Epoch 1410/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0335 - accuracy: 0.5554 - val_loss: 1.0397 - val_accuracy: 0.5712\n",
      "Epoch 1411/1500\n",
      "4157/4157 [==============================] - 0s 35us/step - loss: 1.0259 - accuracy: 0.5598 - val_loss: 1.0548 - val_accuracy: 0.5683\n",
      "Epoch 1412/1500\n",
      "4157/4157 [==============================] - 0s 51us/step - loss: 1.0305 - accuracy: 0.5485 - val_loss: 1.0555 - val_accuracy: 0.5683\n",
      "Epoch 1413/1500\n",
      "4157/4157 [==============================] - 0s 49us/step - loss: 1.0307 - accuracy: 0.5523 - val_loss: 1.0473 - val_accuracy: 0.5692\n",
      "Epoch 1414/1500\n",
      "4157/4157 [==============================] - 0s 41us/step - loss: 1.0293 - accuracy: 0.5569 - val_loss: 1.0488 - val_accuracy: 0.5625\n",
      "Epoch 1415/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0249 - accuracy: 0.5612 - val_loss: 1.0351 - val_accuracy: 0.5663\n",
      "Epoch 1416/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0295 - accuracy: 0.5617 - val_loss: 1.0348 - val_accuracy: 0.5683\n",
      "Epoch 1417/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0248 - accuracy: 0.5603 - val_loss: 1.0320 - val_accuracy: 0.5692\n",
      "Epoch 1418/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0275 - accuracy: 0.5605 - val_loss: 1.0317 - val_accuracy: 0.5683\n",
      "Epoch 1419/1500\n",
      "4157/4157 [==============================] - 0s 39us/step - loss: 1.0322 - accuracy: 0.5516 - val_loss: 1.0374 - val_accuracy: 0.5596\n",
      "Epoch 1420/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0262 - accuracy: 0.5607 - val_loss: 1.0381 - val_accuracy: 0.5625\n",
      "Epoch 1421/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0275 - accuracy: 0.5583 - val_loss: 1.0524 - val_accuracy: 0.5606\n",
      "Epoch 1422/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0293 - accuracy: 0.5581 - val_loss: 1.0423 - val_accuracy: 0.5692\n",
      "Epoch 1423/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0268 - accuracy: 0.5530 - val_loss: 1.0309 - val_accuracy: 0.5712\n",
      "Epoch 1424/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0235 - accuracy: 0.5567 - val_loss: 1.0334 - val_accuracy: 0.5635\n",
      "Epoch 1425/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0255 - accuracy: 0.5567 - val_loss: 1.0453 - val_accuracy: 0.5683\n",
      "Epoch 1426/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0235 - accuracy: 0.5569 - val_loss: 1.0352 - val_accuracy: 0.5731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1427/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0241 - accuracy: 0.5583 - val_loss: 1.0296 - val_accuracy: 0.5692\n",
      "Epoch 1428/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0254 - accuracy: 0.5576 - val_loss: 1.0356 - val_accuracy: 0.5702\n",
      "Epoch 1429/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0254 - accuracy: 0.5550 - val_loss: 1.0451 - val_accuracy: 0.5673\n",
      "Epoch 1430/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0249 - accuracy: 0.5547 - val_loss: 1.0368 - val_accuracy: 0.5721\n",
      "Epoch 1431/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0251 - accuracy: 0.5540 - val_loss: 1.0303 - val_accuracy: 0.5692\n",
      "Epoch 1432/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0275 - accuracy: 0.5526 - val_loss: 1.0258 - val_accuracy: 0.5692\n",
      "Epoch 1433/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0253 - accuracy: 0.5588 - val_loss: 1.0342 - val_accuracy: 0.5692\n",
      "Epoch 1434/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0338 - accuracy: 0.5523 - val_loss: 1.0255 - val_accuracy: 0.5721\n",
      "Epoch 1435/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0239 - accuracy: 0.5586 - val_loss: 1.0382 - val_accuracy: 0.5635\n",
      "Epoch 1436/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0239 - accuracy: 0.5550 - val_loss: 1.0500 - val_accuracy: 0.5702\n",
      "Epoch 1437/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0244 - accuracy: 0.5542 - val_loss: 1.0249 - val_accuracy: 0.5702\n",
      "Epoch 1438/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0252 - accuracy: 0.5689 - val_loss: 1.0247 - val_accuracy: 0.5635\n",
      "Epoch 1439/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0271 - accuracy: 0.5554 - val_loss: 1.0255 - val_accuracy: 0.5683\n",
      "Epoch 1440/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0239 - accuracy: 0.5579 - val_loss: 1.0169 - val_accuracy: 0.5644\n",
      "Epoch 1441/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0194 - accuracy: 0.5634 - val_loss: 1.0302 - val_accuracy: 0.5760\n",
      "Epoch 1442/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0260 - accuracy: 0.5533 - val_loss: 1.0305 - val_accuracy: 0.5587\n",
      "Epoch 1443/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0282 - accuracy: 0.5610 - val_loss: 1.0338 - val_accuracy: 0.5615\n",
      "Epoch 1444/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0249 - accuracy: 0.5607 - val_loss: 1.0360 - val_accuracy: 0.5596\n",
      "Epoch 1445/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0247 - accuracy: 0.5593 - val_loss: 1.0340 - val_accuracy: 0.5606\n",
      "Epoch 1446/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0334 - accuracy: 0.5581 - val_loss: 1.0306 - val_accuracy: 0.5625\n",
      "Epoch 1447/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0271 - accuracy: 0.5514 - val_loss: 1.0376 - val_accuracy: 0.5654\n",
      "Epoch 1448/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0223 - accuracy: 0.5598 - val_loss: 1.0324 - val_accuracy: 0.5635\n",
      "Epoch 1449/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0187 - accuracy: 0.5622 - val_loss: 1.0216 - val_accuracy: 0.5712\n",
      "Epoch 1450/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0231 - accuracy: 0.5547 - val_loss: 1.0285 - val_accuracy: 0.5663\n",
      "Epoch 1451/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0272 - accuracy: 0.5567 - val_loss: 1.0207 - val_accuracy: 0.5663\n",
      "Epoch 1452/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0257 - accuracy: 0.5530 - val_loss: 1.0344 - val_accuracy: 0.5644\n",
      "Epoch 1453/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0245 - accuracy: 0.5581 - val_loss: 1.0295 - val_accuracy: 0.5692\n",
      "Epoch 1454/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0313 - accuracy: 0.5631 - val_loss: 1.0359 - val_accuracy: 0.5596\n",
      "Epoch 1455/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0252 - accuracy: 0.5603 - val_loss: 1.0328 - val_accuracy: 0.5731\n",
      "Epoch 1456/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0278 - accuracy: 0.5571 - val_loss: 1.0201 - val_accuracy: 0.5654\n",
      "Epoch 1457/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0202 - accuracy: 0.5603 - val_loss: 1.0408 - val_accuracy: 0.5644\n",
      "Epoch 1458/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0238 - accuracy: 0.5612 - val_loss: 1.0319 - val_accuracy: 0.5702\n",
      "Epoch 1459/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0343 - accuracy: 0.5579 - val_loss: 1.0195 - val_accuracy: 0.5683\n",
      "Epoch 1460/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0262 - accuracy: 0.5518 - val_loss: 1.0294 - val_accuracy: 0.5663\n",
      "Epoch 1461/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0243 - accuracy: 0.5641 - val_loss: 1.0271 - val_accuracy: 0.5692\n",
      "Epoch 1462/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0240 - accuracy: 0.5591 - val_loss: 1.0327 - val_accuracy: 0.5654\n",
      "Epoch 1463/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0297 - accuracy: 0.5518 - val_loss: 1.0385 - val_accuracy: 0.5625\n",
      "Epoch 1464/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0263 - accuracy: 0.5526 - val_loss: 1.0334 - val_accuracy: 0.5731\n",
      "Epoch 1465/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0241 - accuracy: 0.5595 - val_loss: 1.0412 - val_accuracy: 0.5721\n",
      "Epoch 1466/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0290 - accuracy: 0.5485 - val_loss: 1.0491 - val_accuracy: 0.5721\n",
      "Epoch 1467/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0303 - accuracy: 0.5550 - val_loss: 1.0568 - val_accuracy: 0.5510\n",
      "Epoch 1468/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0216 - accuracy: 0.5547 - val_loss: 1.0335 - val_accuracy: 0.5625\n",
      "Epoch 1469/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0203 - accuracy: 0.5581 - val_loss: 1.0548 - val_accuracy: 0.5644\n",
      "Epoch 1470/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0250 - accuracy: 0.5567 - val_loss: 1.0594 - val_accuracy: 0.5606\n",
      "Epoch 1471/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0234 - accuracy: 0.5588 - val_loss: 1.0520 - val_accuracy: 0.5673\n",
      "Epoch 1472/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0205 - accuracy: 0.5612 - val_loss: 1.0373 - val_accuracy: 0.5673\n",
      "Epoch 1473/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0279 - accuracy: 0.5571 - val_loss: 1.0353 - val_accuracy: 0.5635\n",
      "Epoch 1474/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0286 - accuracy: 0.5607 - val_loss: 1.0431 - val_accuracy: 0.5712\n",
      "Epoch 1475/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0220 - accuracy: 0.5574 - val_loss: 1.0545 - val_accuracy: 0.5654\n",
      "Epoch 1476/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0297 - accuracy: 0.5586 - val_loss: 1.0374 - val_accuracy: 0.5721\n",
      "Epoch 1477/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0308 - accuracy: 0.5521 - val_loss: 1.0430 - val_accuracy: 0.5663\n",
      "Epoch 1478/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0252 - accuracy: 0.5562 - val_loss: 1.0477 - val_accuracy: 0.5731\n",
      "Epoch 1479/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0284 - accuracy: 0.5603 - val_loss: 1.0497 - val_accuracy: 0.5673\n",
      "Epoch 1480/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0311 - accuracy: 0.5583 - val_loss: 1.0379 - val_accuracy: 0.5644\n",
      "Epoch 1481/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0249 - accuracy: 0.5588 - val_loss: 1.0331 - val_accuracy: 0.5740\n",
      "Epoch 1482/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0259 - accuracy: 0.5627 - val_loss: 1.0457 - val_accuracy: 0.5635\n",
      "Epoch 1483/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0309 - accuracy: 0.5588 - val_loss: 1.0500 - val_accuracy: 0.5702\n",
      "Epoch 1484/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0200 - accuracy: 0.5533 - val_loss: 1.0441 - val_accuracy: 0.5635\n",
      "Epoch 1485/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0277 - accuracy: 0.5598 - val_loss: 1.0348 - val_accuracy: 0.5644\n",
      "Epoch 1486/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0244 - accuracy: 0.5571 - val_loss: 1.0354 - val_accuracy: 0.5702\n",
      "Epoch 1487/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0252 - accuracy: 0.5574 - val_loss: 1.0396 - val_accuracy: 0.5635\n",
      "Epoch 1488/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0236 - accuracy: 0.5656 - val_loss: 1.0446 - val_accuracy: 0.5596\n",
      "Epoch 1489/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0247 - accuracy: 0.5576 - val_loss: 1.0404 - val_accuracy: 0.5625\n",
      "Epoch 1490/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0320 - accuracy: 0.5516 - val_loss: 1.0430 - val_accuracy: 0.5654\n",
      "Epoch 1491/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0198 - accuracy: 0.5670 - val_loss: 1.0449 - val_accuracy: 0.5654\n",
      "Epoch 1492/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0254 - accuracy: 0.5552 - val_loss: 1.0491 - val_accuracy: 0.5644\n",
      "Epoch 1493/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0302 - accuracy: 0.5562 - val_loss: 1.0371 - val_accuracy: 0.5721\n",
      "Epoch 1494/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0204 - accuracy: 0.5487 - val_loss: 1.0501 - val_accuracy: 0.5663\n",
      "Epoch 1495/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0250 - accuracy: 0.5593 - val_loss: 1.0426 - val_accuracy: 0.5702\n",
      "Epoch 1496/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0269 - accuracy: 0.5607 - val_loss: 1.0456 - val_accuracy: 0.5644\n",
      "Epoch 1497/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0267 - accuracy: 0.5624 - val_loss: 1.0435 - val_accuracy: 0.5673\n",
      "Epoch 1498/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0317 - accuracy: 0.5627 - val_loss: 1.0282 - val_accuracy: 0.5654\n",
      "Epoch 1499/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0168 - accuracy: 0.5675 - val_loss: 1.0487 - val_accuracy: 0.5625\n",
      "Epoch 1500/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0234 - accuracy: 0.5622 - val_loss: 1.0389 - val_accuracy: 0.5721\n",
      "1300/1300 [==============================] - 0s 8us/step\n",
      "\n",
      "Test Loss: [1.06979055588062, 0.5569230914115906]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################################################\n",
    "x_train_red, y_train_red, x_test_red, y_test_red = generate_data(red_wine, 0.8)\n",
    "y_train_red = one_hot_enc(y_train_red)\n",
    "y_test_red = one_hot_enc(y_test_red)\n",
    "\n",
    "x_train = np.append(x_train, x_train_red, axis=0)\n",
    "y_train = np.append(y_train, y_train_red, axis=0)\n",
    "x_test = np.append(x_test, x_test_red, axis=0)\n",
    "y_test = np.append(y_test, y_test_red, axis=0)\n",
    "\n",
    "model = DNN(n_in, n_h, n_h2, n_h3, n_h4, n_h5, n_h6, n_h7, n_h8, n_h9, n_out)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1500,\n",
    "                    batch_size=BATCH_SIZE, validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "performance_test = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f'\\nTest Loss: {performance_test}')\n",
    "\n",
    "plot_loss(history)\n",
    "plt.show()\n",
    "plot_acc(history)\n",
    "plt.show()\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WindClassifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "f7eb9da2086e92ec6b3f9d89598363e45a1a635b7cda3a5d64804cd6cbde1def"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
