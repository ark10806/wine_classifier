{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "text",
    "id": "AH7bAAGcobV3"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-ccc1ecde25f7>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-ccc1ecde25f7>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    이번 과제에서는 케라스(Keras)를 활용하여, 와인의 품질을 분류하는 인공신경망 분류기를 만들어 볼 것입니다.\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 와인 감별사 : 와인의 Quality를 분류하는 Classifier 만들기\n",
    "\n",
    "## 1. 과제 설명\n",
    "이번 과제에서는 케라스(Keras)를 활용하여, 와인의 품질을 분류하는 인공신경망 분류기를 만들어 볼 것입니다.\n",
    "케라스는 Tensorflow, Theano 등의 딥 러닝 라이브러리 위에서 동작하는 오픈 소스 라이브러리로, 보다 쉬운 API를 제공함으로써 모델 설계 및 학습, 테스트가 간단하다는 장점이 있습니다. \n",
    "\n",
    "### 1.1 케라스 설치를 위한 필수 라이브러리\n",
    "케라스를 설치하기 전에 먼저 필수적으로 설치해야 할 것들이 있습니다.\n",
    "* Anaconda : Python 3.x 버전, Numpy, Pandas, SciPy, sklearn 등 필수 라이브러리들이 포함된 통합 배포 팩\n",
    "<br> 아나콘다 설치 : https://www.anaconda.com/distribution/#download-section\n",
    "* Tensorflow : Google에서 개발한 오픈 소스 딥 러닝 라이브러리. <b>설치된 Python 버전과 호환되는 것으로 설치할것!</b>\n",
    "<br> 텐서플로우 설치 : https://www.tensorflow.org/install/pip\n",
    "<br> * CPU 버전을 설치할 것을 권장. \n",
    "\n",
    "### 1.2 케라스 설치\n",
    "위 라이브러리들을 설치한 후, 케라스를 설치합니다.\n",
    "* https://keras.io/#installation\n",
    "\n",
    "### 1.3 케라스 설치 확인\n",
    "케라스가 올바르게 설치되었는지 확인하기 위해, 케라스를 Import한 뒤 버전을 출력해봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdWzUjvZobV4",
    "outputId": "e8e9a35e-98d5-48e1-f9c1-978077d96b36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lWlwSKksobV_"
   },
   "source": [
    "위와 같이 케라스의 버전이 출력되면 정상입니다. (출력되는 버전은 위 예시와 다를 수도 있음)<br> 나중에 신경망을 만들기 위한 클래스들도 함께 Import 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ruFtS02AobWA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from keras import layers, models\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZggQC1JiobWC"
   },
   "source": [
    "---\n",
    "## 2. Data Set 설명\n",
    " 본 과제에서 사용할 데이터 셋은 UCI에서 제공되는 Wine Quality Data Set입니다. (https://archive.ics.uci.edu/ml/datasets/Wine+Quality) 데이터는 레드 와인 1599개, 화이트 와인 4898개의 화학적 특성을 포함하고 있습니다. 데이터는 두 개의 CSV(Comma-seperated values)형태로 제공되며, 구성은 다음과 같습니다.\n",
    "* 화이트 와인 / 레드 와인 CSV 파일\n",
    "* 11개의 실수(Real) 입력 변수 (X)\n",
    "    * fixed acidity\n",
    "    * volatile acidity\n",
    "    * citric acid\n",
    "    * residual sugar\n",
    "    * chlorides\n",
    "    * free sulfur dioxide\n",
    "    * total sulfur dioxide\n",
    "    * density\n",
    "    * pH\n",
    "    * sulphates\n",
    "    * alcohol\n",
    "* 1개의 클래스 레이블 (Y)\n",
    "   * quality (0~10, 0: Very poor, 10: Very excellent)\n",
    "* Missing Value 없음\n",
    "* 클래스들이 불균등하게 분포함.\n",
    "\n",
    "더 자세한 사항은 블랙보드에 함께 올라가있는 설명 파일을 참고하도록 합시다.\n",
    "\n",
    "### 2.1 데이터 로드\n",
    "데이터 분석에서 가장 많이 사용되는 라이브러리 중 하나인 Pandas와 Numpy를 Import하겠습니다. Pandas는 데이터 분석에 유용한 데이터 타입인 DataFrame을 제공하며, Numpy는 효율적이고 빠른 매트릭스 연산을 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5kTZyX1obWD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.__version__\n",
    "pd.options.display.max_rows=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0thM0X0obWG",
    "outputId": "424a3336-02e9-4d28-b9db-725719c2e71b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HCI_seungchan\\Jupyter\\wine_classifier\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHEmT15sobWJ"
   },
   "source": [
    "Pandas를 이용해서 CSV 파일을 읽어들이도록 합시다. white_wine 변수에는 화이트 와인 데이터를, red_wine 변수에는 레드 와인 데이터를 읽어들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t0s-aG2SobWJ"
   },
   "outputs": [],
   "source": [
    "#########################코드########################\n",
    "\n",
    "\n",
    "white_wine = pd.read_csv('./wine_data/winequality-white.csv')\n",
    "red_wine = pd.read_csv('./wine_data/winequality-red.csv')\n",
    "\n",
    "\n",
    "\n",
    "#####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3zUEFZtobWM"
   },
   "source": [
    "### 2.2 데이터 전처리\n",
    "데이터를 읽어들인 뒤, 읽어들인 데이터프레임을 display 함수를 통해 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IR2Bk48fobWM",
    "outputId": "378265b5-1cf8-4927-d318-c196f9e658bd"
   },
   "outputs": [],
   "source": [
    "display(white_wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aoIonV7KobWP",
    "outputId": "4e225517-5e4c-4291-8371-da3ba36acc3f"
   },
   "outputs": [],
   "source": [
    "# print(red_wine.loc[0])\n",
    "# display(red_wine)\n",
    "red_wine.shape\n",
    "# from keras import datasets\n",
    "# (x,y),(x_, y_)  = datasets.mnist.load_data()\n",
    "# print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YA0L1jCDobWS"
   },
   "source": [
    "이제 데이터프레임을 입력 변수와 정답 셋(클래스 레이블)으로 나누는 함수를 작성하겠습니다.<br>\n",
    "<b>generate_data</b>함수는 데이터프레임 객체와 테스트 셋 비율을 입력으로 받아, 네 개의 numpy array를 반환합니다. 트레이닝 셋과 테스트 셋의 비율은 training_set_ratio에 의해 결정됩니다.\n",
    "* Function : generate_data\n",
    " * 입력\n",
    "     * pd.DataFrame : df\n",
    "     * double : training_set_ratio  \n",
    " * 출력\n",
    "     * np.array : X_train\n",
    "     * np.array : Y_train\n",
    "     * np.array : X_test\n",
    "     * np.array : Y_test\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sHHRgjpWobWT"
   },
   "outputs": [],
   "source": [
    "#####################################################\n",
    "def normalize(total_data: np.array) -> None:\n",
    "    for i in range(np.shape(total_data)[1]-1):\n",
    "        col_zero_base = total_data[:,i] - total_data[:,i].min()\n",
    "        total_data[:,i] = ( col_zero_base ) / ( col_zero_base.max() )\n",
    "\n",
    "def generate_data(df: pd.DataFrame, t_r: float):\n",
    "    total_data = df.to_numpy()\n",
    "    normalize(total_data)\n",
    "\n",
    "    np.random.shuffle(total_data)\n",
    "    n_train_set = int(np.shape(total_data)[0] * t_r)\n",
    "\n",
    "    x_train = total_data[:n_train_set, :-1]\n",
    "    y_train = total_data[:n_train_set, -1:]\n",
    "\n",
    "    x_test = total_data[n_train_set:, :-1]\n",
    "    y_test = total_data[n_train_set:, -1:]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "#####################################################\n",
    "\n",
    "global one_hot_codes\n",
    "one_hot_codes = []\n",
    "def make_label():\n",
    "    global one_hot_codes\n",
    "    tmp = [0] * 10\n",
    "    for i in range(10):\n",
    "        tmp[i] = 1\n",
    "        one_hot_codes.append(tmp.copy())\n",
    "        tmp[i] = 0\n",
    "\n",
    "def one_hot_enc(y_label: np.array) -> np.array:\n",
    "    onehot_y = []\n",
    "    for i in range(np.shape(y_label)[0]):\n",
    "        idx = int(y_label[i][0])\n",
    "        if(idx < 0 or idx > 9):\n",
    "            print(idx)\n",
    "        onehot_y.append(one_hot_codes[idx])\n",
    "    \n",
    "    onehot_y = np.array(onehot_y)\n",
    "    return onehot_y\n",
    "\n",
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train','Test'], loc=0)\n",
    "\n",
    "def plot_acc(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model acc')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train','Test'], loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-kAXFUkobWV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25961538, 0.43137255, 0.10240964, ..., 0.49090909, 0.11627907,\n",
       "        0.32258065],\n",
       "       [0.27884615, 0.15686275, 0.21686747, ..., 0.56363636, 0.34883721,\n",
       "        0.46774194],\n",
       "       [0.45192308, 0.08823529, 0.44578313, ..., 0.50909091, 0.20930233,\n",
       "        0.70967742],\n",
       "       ...,\n",
       "       [0.41346154, 0.41176471, 0.28313253, ..., 0.44545455, 0.23255814,\n",
       "        0.46774194],\n",
       "       [0.47115385, 0.2254902 , 0.43975904, ..., 0.21818182, 0.76744186,\n",
       "        0.11290323],\n",
       "       [0.35576923, 0.29411765, 0.3373494 , ..., 0.37272727, 0.5       ,\n",
       "        0.30645161]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_label()\n",
    "x_train, y_train, x_test, y_test = generate_data(white_wine, 0.8)\n",
    "y_train = one_hot_enc(y_train)\n",
    "y_test = one_hot_enc(y_test)\n",
    "\n",
    "display(x_train)\n",
    "display(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctr0KTQ7obWX"
   },
   "source": [
    "작성한 함수를 호출하여 화이트 와인 데이터에 대해 트레이닝 셋과 테스트 셋의 입력과 정답이 적절하게 생성되었는지 확인합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWOKgPSaobWY"
   },
   "source": [
    "# 3. 케라스를 이용한 모델 생성, 학습, 테스트\n",
    "입력 데이터와 정답 셋이 만들어졌으니 케라스를 사용하여 각 데이터에 대한 분류기를 생성하고, 트레이닝 셋으로 학습시킨 뒤 테스트 정확도를 관찰합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FO4OxZuhobWZ"
   },
   "source": [
    "# 과제\n",
    "### 1. 화이트 와인 분류 모델과 레드 와인 분류 모델 설계 및 학습\n",
    "* 하나의 히든 레이어에 32개의 노드를 가진 인공신경망 모델 생성 및 모델 학습\n",
    "* 트레이닝 Epoch에 따라 Loss의 변화를 그래프로 시각화\n",
    "* 테스트 셋에 대한 정확도 기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gE8UhHrNobWZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4157 samples, validate on 1040 samples\n",
      "Epoch 1/500\n",
      "4157/4157 [==============================] - 0s 52us/step - loss: 2.2434 - accuracy: 0.1496 - val_loss: 2.1582 - val_accuracy: 0.1000\n",
      "Epoch 2/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 2.0676 - accuracy: 0.4186 - val_loss: 1.9304 - val_accuracy: 0.5183\n",
      "Epoch 3/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.8763 - accuracy: 0.4802 - val_loss: 1.6848 - val_accuracy: 0.5212\n",
      "Epoch 4/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.6779 - accuracy: 0.4900 - val_loss: 1.4720 - val_accuracy: 0.4885\n",
      "Epoch 5/500\n",
      "4157/4157 [==============================] - 0s 7us/step - loss: 1.5151 - accuracy: 0.4879 - val_loss: 1.3368 - val_accuracy: 0.4788\n",
      "Epoch 6/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.4134 - accuracy: 0.4638 - val_loss: 1.2643 - val_accuracy: 0.4375\n",
      "Epoch 7/500\n",
      "4157/4157 [==============================] - 0s 7us/step - loss: 1.3558 - accuracy: 0.4561 - val_loss: 1.2239 - val_accuracy: 0.4394\n",
      "Epoch 8/500\n",
      "4157/4157 [==============================] - 0s 7us/step - loss: 1.3200 - accuracy: 0.4645 - val_loss: 1.1922 - val_accuracy: 0.4962\n",
      "Epoch 9/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.2945 - accuracy: 0.4715 - val_loss: 1.1692 - val_accuracy: 0.5135\n",
      "Epoch 10/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.2750 - accuracy: 0.4770 - val_loss: 1.1534 - val_accuracy: 0.5288\n",
      "Epoch 11/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.2587 - accuracy: 0.4857 - val_loss: 1.1373 - val_accuracy: 0.5404\n",
      "Epoch 12/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.2456 - accuracy: 0.4905 - val_loss: 1.1247 - val_accuracy: 0.5510\n",
      "Epoch 13/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.2338 - accuracy: 0.4874 - val_loss: 1.1131 - val_accuracy: 0.5692\n",
      "Epoch 14/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.2238 - accuracy: 0.4900 - val_loss: 1.1024 - val_accuracy: 0.5692\n",
      "Epoch 15/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.2149 - accuracy: 0.4963 - val_loss: 1.0938 - val_accuracy: 0.5567\n",
      "Epoch 16/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.2072 - accuracy: 0.5052 - val_loss: 1.0851 - val_accuracy: 0.5490\n",
      "Epoch 17/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1994 - accuracy: 0.5016 - val_loss: 1.0794 - val_accuracy: 0.5490\n",
      "Epoch 18/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1916 - accuracy: 0.5071 - val_loss: 1.0728 - val_accuracy: 0.5490\n",
      "Epoch 19/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1853 - accuracy: 0.5085 - val_loss: 1.0687 - val_accuracy: 0.5510\n",
      "Epoch 20/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1796 - accuracy: 0.5069 - val_loss: 1.0651 - val_accuracy: 0.5481\n",
      "Epoch 21/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1745 - accuracy: 0.5100 - val_loss: 1.0599 - val_accuracy: 0.5510\n",
      "Epoch 22/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1700 - accuracy: 0.5095 - val_loss: 1.0596 - val_accuracy: 0.5452\n",
      "Epoch 23/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1661 - accuracy: 0.5085 - val_loss: 1.0537 - val_accuracy: 0.5577\n",
      "Epoch 24/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1620 - accuracy: 0.5105 - val_loss: 1.0537 - val_accuracy: 0.5481\n",
      "Epoch 25/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1583 - accuracy: 0.5148 - val_loss: 1.0478 - val_accuracy: 0.5587\n",
      "Epoch 26/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1549 - accuracy: 0.5146 - val_loss: 1.0488 - val_accuracy: 0.5490\n",
      "Epoch 27/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1522 - accuracy: 0.5129 - val_loss: 1.0470 - val_accuracy: 0.5519\n",
      "Epoch 28/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1490 - accuracy: 0.5162 - val_loss: 1.0435 - val_accuracy: 0.5567\n",
      "Epoch 29/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1468 - accuracy: 0.5174 - val_loss: 1.0432 - val_accuracy: 0.5558\n",
      "Epoch 30/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1442 - accuracy: 0.5218 - val_loss: 1.0396 - val_accuracy: 0.5577\n",
      "Epoch 31/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1420 - accuracy: 0.5177 - val_loss: 1.0416 - val_accuracy: 0.5538\n",
      "Epoch 32/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1397 - accuracy: 0.5223 - val_loss: 1.0358 - val_accuracy: 0.5615\n",
      "Epoch 33/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1374 - accuracy: 0.5198 - val_loss: 1.0379 - val_accuracy: 0.5606\n",
      "Epoch 34/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1357 - accuracy: 0.5230 - val_loss: 1.0378 - val_accuracy: 0.5596\n",
      "Epoch 35/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1338 - accuracy: 0.5225 - val_loss: 1.0373 - val_accuracy: 0.5606\n",
      "Epoch 36/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1321 - accuracy: 0.5227 - val_loss: 1.0341 - val_accuracy: 0.5596\n",
      "Epoch 37/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1306 - accuracy: 0.5208 - val_loss: 1.0307 - val_accuracy: 0.5702\n",
      "Epoch 38/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1293 - accuracy: 0.5225 - val_loss: 1.0331 - val_accuracy: 0.5683\n",
      "Epoch 39/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1273 - accuracy: 0.5191 - val_loss: 1.0345 - val_accuracy: 0.5606\n",
      "Epoch 40/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1263 - accuracy: 0.5220 - val_loss: 1.0335 - val_accuracy: 0.5606\n",
      "Epoch 41/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1241 - accuracy: 0.5247 - val_loss: 1.0320 - val_accuracy: 0.5625\n",
      "Epoch 42/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1229 - accuracy: 0.5232 - val_loss: 1.0310 - val_accuracy: 0.5644\n",
      "Epoch 43/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1218 - accuracy: 0.5271 - val_loss: 1.0302 - val_accuracy: 0.5644\n",
      "Epoch 44/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1200 - accuracy: 0.5244 - val_loss: 1.0290 - val_accuracy: 0.5788\n",
      "Epoch 45/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1191 - accuracy: 0.5280 - val_loss: 1.0302 - val_accuracy: 0.5654\n",
      "Epoch 46/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1178 - accuracy: 0.5283 - val_loss: 1.0291 - val_accuracy: 0.5721\n",
      "Epoch 47/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1171 - accuracy: 0.5273 - val_loss: 1.0299 - val_accuracy: 0.5712\n",
      "Epoch 48/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1167 - accuracy: 0.5304 - val_loss: 1.0259 - val_accuracy: 0.5779\n",
      "Epoch 49/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1155 - accuracy: 0.5237 - val_loss: 1.0340 - val_accuracy: 0.5587\n",
      "Epoch 50/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1140 - accuracy: 0.5309 - val_loss: 1.0272 - val_accuracy: 0.5721\n",
      "Epoch 51/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1136 - accuracy: 0.5285 - val_loss: 1.0308 - val_accuracy: 0.5615\n",
      "Epoch 52/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1120 - accuracy: 0.5326 - val_loss: 1.0284 - val_accuracy: 0.5731\n",
      "Epoch 53/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1109 - accuracy: 0.5316 - val_loss: 1.0286 - val_accuracy: 0.5644\n",
      "Epoch 54/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1101 - accuracy: 0.5321 - val_loss: 1.0277 - val_accuracy: 0.5712\n",
      "Epoch 55/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1095 - accuracy: 0.5340 - val_loss: 1.0266 - val_accuracy: 0.5740\n",
      "Epoch 56/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1086 - accuracy: 0.5290 - val_loss: 1.0283 - val_accuracy: 0.5721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1077 - accuracy: 0.5352 - val_loss: 1.0259 - val_accuracy: 0.5760\n",
      "Epoch 58/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1071 - accuracy: 0.5319 - val_loss: 1.0257 - val_accuracy: 0.5740\n",
      "Epoch 59/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1063 - accuracy: 0.5343 - val_loss: 1.0289 - val_accuracy: 0.5644\n",
      "Epoch 60/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1060 - accuracy: 0.5299 - val_loss: 1.0271 - val_accuracy: 0.5654\n",
      "Epoch 61/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1051 - accuracy: 0.5362 - val_loss: 1.0267 - val_accuracy: 0.5740\n",
      "Epoch 62/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1047 - accuracy: 0.5304 - val_loss: 1.0276 - val_accuracy: 0.5663\n",
      "Epoch 63/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1039 - accuracy: 0.5376 - val_loss: 1.0279 - val_accuracy: 0.5615\n",
      "Epoch 64/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1034 - accuracy: 0.5314 - val_loss: 1.0279 - val_accuracy: 0.5644\n",
      "Epoch 65/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1025 - accuracy: 0.5364 - val_loss: 1.0266 - val_accuracy: 0.5635\n",
      "Epoch 66/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1016 - accuracy: 0.5345 - val_loss: 1.0263 - val_accuracy: 0.5683\n",
      "Epoch 67/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1010 - accuracy: 0.5384 - val_loss: 1.0248 - val_accuracy: 0.5683\n",
      "Epoch 68/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1006 - accuracy: 0.5348 - val_loss: 1.0279 - val_accuracy: 0.5644\n",
      "Epoch 69/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.1002 - accuracy: 0.5374 - val_loss: 1.0267 - val_accuracy: 0.5635\n",
      "Epoch 70/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0993 - accuracy: 0.5389 - val_loss: 1.0238 - val_accuracy: 0.5654\n",
      "Epoch 71/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0991 - accuracy: 0.5367 - val_loss: 1.0252 - val_accuracy: 0.5663\n",
      "Epoch 72/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0986 - accuracy: 0.5362 - val_loss: 1.0215 - val_accuracy: 0.5663\n",
      "Epoch 73/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0982 - accuracy: 0.5364 - val_loss: 1.0241 - val_accuracy: 0.5663\n",
      "Epoch 74/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0973 - accuracy: 0.5362 - val_loss: 1.0252 - val_accuracy: 0.5596\n",
      "Epoch 75/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0970 - accuracy: 0.5360 - val_loss: 1.0223 - val_accuracy: 0.5654\n",
      "Epoch 76/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0965 - accuracy: 0.5316 - val_loss: 1.0231 - val_accuracy: 0.5673\n",
      "Epoch 77/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0960 - accuracy: 0.5362 - val_loss: 1.0228 - val_accuracy: 0.5644\n",
      "Epoch 78/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0959 - accuracy: 0.5348 - val_loss: 1.0245 - val_accuracy: 0.5663\n",
      "Epoch 79/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0957 - accuracy: 0.5350 - val_loss: 1.0216 - val_accuracy: 0.5663\n",
      "Epoch 80/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0943 - accuracy: 0.5384 - val_loss: 1.0223 - val_accuracy: 0.5673\n",
      "Epoch 81/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0945 - accuracy: 0.5364 - val_loss: 1.0211 - val_accuracy: 0.5663\n",
      "Epoch 82/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0941 - accuracy: 0.5376 - val_loss: 1.0209 - val_accuracy: 0.5673\n",
      "Epoch 83/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0933 - accuracy: 0.5391 - val_loss: 1.0214 - val_accuracy: 0.5673\n",
      "Epoch 84/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0933 - accuracy: 0.5379 - val_loss: 1.0187 - val_accuracy: 0.5625\n",
      "Epoch 85/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0925 - accuracy: 0.5384 - val_loss: 1.0204 - val_accuracy: 0.5692\n",
      "Epoch 86/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0919 - accuracy: 0.5360 - val_loss: 1.0192 - val_accuracy: 0.5654\n",
      "Epoch 87/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0918 - accuracy: 0.5386 - val_loss: 1.0201 - val_accuracy: 0.5721\n",
      "Epoch 88/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0911 - accuracy: 0.5379 - val_loss: 1.0168 - val_accuracy: 0.5740\n",
      "Epoch 89/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0910 - accuracy: 0.5379 - val_loss: 1.0177 - val_accuracy: 0.5721\n",
      "Epoch 90/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0906 - accuracy: 0.5357 - val_loss: 1.0187 - val_accuracy: 0.5731\n",
      "Epoch 91/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0902 - accuracy: 0.5381 - val_loss: 1.0176 - val_accuracy: 0.5702\n",
      "Epoch 92/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0901 - accuracy: 0.5362 - val_loss: 1.0180 - val_accuracy: 0.5702\n",
      "Epoch 93/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0892 - accuracy: 0.5376 - val_loss: 1.0168 - val_accuracy: 0.5721\n",
      "Epoch 94/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0889 - accuracy: 0.5376 - val_loss: 1.0156 - val_accuracy: 0.5760\n",
      "Epoch 95/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0886 - accuracy: 0.5376 - val_loss: 1.0173 - val_accuracy: 0.5712\n",
      "Epoch 96/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0885 - accuracy: 0.5374 - val_loss: 1.0147 - val_accuracy: 0.5740\n",
      "Epoch 97/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0887 - accuracy: 0.5362 - val_loss: 1.0156 - val_accuracy: 0.5731\n",
      "Epoch 98/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0879 - accuracy: 0.5376 - val_loss: 1.0147 - val_accuracy: 0.5750\n",
      "Epoch 99/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0871 - accuracy: 0.5386 - val_loss: 1.0125 - val_accuracy: 0.5740\n",
      "Epoch 100/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0866 - accuracy: 0.5379 - val_loss: 1.0135 - val_accuracy: 0.5740\n",
      "Epoch 101/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0862 - accuracy: 0.5405 - val_loss: 1.0130 - val_accuracy: 0.5731\n",
      "Epoch 102/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0858 - accuracy: 0.5405 - val_loss: 1.0137 - val_accuracy: 0.5731\n",
      "Epoch 103/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0857 - accuracy: 0.5374 - val_loss: 1.0123 - val_accuracy: 0.5721\n",
      "Epoch 104/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0860 - accuracy: 0.5360 - val_loss: 1.0133 - val_accuracy: 0.5731\n",
      "Epoch 105/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0853 - accuracy: 0.5374 - val_loss: 1.0119 - val_accuracy: 0.5731\n",
      "Epoch 106/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0844 - accuracy: 0.5391 - val_loss: 1.0119 - val_accuracy: 0.5760\n",
      "Epoch 107/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0841 - accuracy: 0.5372 - val_loss: 1.0110 - val_accuracy: 0.5721\n",
      "Epoch 108/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0840 - accuracy: 0.5393 - val_loss: 1.0111 - val_accuracy: 0.5712\n",
      "Epoch 109/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0837 - accuracy: 0.5391 - val_loss: 1.0116 - val_accuracy: 0.5740\n",
      "Epoch 110/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0834 - accuracy: 0.5403 - val_loss: 1.0110 - val_accuracy: 0.5740\n",
      "Epoch 111/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0834 - accuracy: 0.5405 - val_loss: 1.0120 - val_accuracy: 0.5788\n",
      "Epoch 112/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0825 - accuracy: 0.5403 - val_loss: 1.0088 - val_accuracy: 0.5769\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0824 - accuracy: 0.5405 - val_loss: 1.0102 - val_accuracy: 0.5760\n",
      "Epoch 114/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0819 - accuracy: 0.5425 - val_loss: 1.0096 - val_accuracy: 0.5721\n",
      "Epoch 115/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0819 - accuracy: 0.5410 - val_loss: 1.0087 - val_accuracy: 0.5721\n",
      "Epoch 116/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0813 - accuracy: 0.5398 - val_loss: 1.0103 - val_accuracy: 0.5788\n",
      "Epoch 117/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0820 - accuracy: 0.5393 - val_loss: 1.0106 - val_accuracy: 0.5788\n",
      "Epoch 118/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0803 - accuracy: 0.5396 - val_loss: 1.0079 - val_accuracy: 0.5740\n",
      "Epoch 119/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0801 - accuracy: 0.5420 - val_loss: 1.0084 - val_accuracy: 0.5731\n",
      "Epoch 120/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0810 - accuracy: 0.5386 - val_loss: 1.0098 - val_accuracy: 0.5760\n",
      "Epoch 121/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0800 - accuracy: 0.5427 - val_loss: 1.0080 - val_accuracy: 0.5721\n",
      "Epoch 122/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0791 - accuracy: 0.5434 - val_loss: 1.0074 - val_accuracy: 0.5760\n",
      "Epoch 123/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0795 - accuracy: 0.5401 - val_loss: 1.0075 - val_accuracy: 0.5779\n",
      "Epoch 124/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0797 - accuracy: 0.5417 - val_loss: 1.0053 - val_accuracy: 0.5731\n",
      "Epoch 125/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0791 - accuracy: 0.5420 - val_loss: 1.0065 - val_accuracy: 0.5769\n",
      "Epoch 126/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0785 - accuracy: 0.5449 - val_loss: 1.0054 - val_accuracy: 0.5779\n",
      "Epoch 127/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0794 - accuracy: 0.5446 - val_loss: 1.0041 - val_accuracy: 0.5712\n",
      "Epoch 128/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0790 - accuracy: 0.5425 - val_loss: 1.0081 - val_accuracy: 0.5779\n",
      "Epoch 129/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0782 - accuracy: 0.5434 - val_loss: 1.0032 - val_accuracy: 0.5788\n",
      "Epoch 130/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0780 - accuracy: 0.5415 - val_loss: 1.0062 - val_accuracy: 0.5779\n",
      "Epoch 131/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0766 - accuracy: 0.5427 - val_loss: 1.0036 - val_accuracy: 0.5769\n",
      "Epoch 132/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0767 - accuracy: 0.5403 - val_loss: 1.0032 - val_accuracy: 0.5779\n",
      "Epoch 133/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0770 - accuracy: 0.5441 - val_loss: 1.0049 - val_accuracy: 0.5808\n",
      "Epoch 134/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0758 - accuracy: 0.5417 - val_loss: 1.0039 - val_accuracy: 0.5769\n",
      "Epoch 135/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0766 - accuracy: 0.5403 - val_loss: 1.0044 - val_accuracy: 0.5817\n",
      "Epoch 136/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0758 - accuracy: 0.5451 - val_loss: 1.0024 - val_accuracy: 0.5750\n",
      "Epoch 137/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0752 - accuracy: 0.5415 - val_loss: 1.0024 - val_accuracy: 0.5760\n",
      "Epoch 138/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0744 - accuracy: 0.5403 - val_loss: 1.0028 - val_accuracy: 0.5798\n",
      "Epoch 139/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0743 - accuracy: 0.5461 - val_loss: 1.0018 - val_accuracy: 0.5750\n",
      "Epoch 140/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0747 - accuracy: 0.5470 - val_loss: 1.0044 - val_accuracy: 0.5808\n",
      "Epoch 141/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0736 - accuracy: 0.5410 - val_loss: 1.0017 - val_accuracy: 0.5769\n",
      "Epoch 142/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0733 - accuracy: 0.5432 - val_loss: 1.0013 - val_accuracy: 0.5779\n",
      "Epoch 143/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0730 - accuracy: 0.5413 - val_loss: 1.0025 - val_accuracy: 0.5760\n",
      "Epoch 144/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0731 - accuracy: 0.5497 - val_loss: 1.0042 - val_accuracy: 0.5817\n",
      "Epoch 145/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0727 - accuracy: 0.5429 - val_loss: 1.0011 - val_accuracy: 0.5779\n",
      "Epoch 146/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0724 - accuracy: 0.5456 - val_loss: 1.0014 - val_accuracy: 0.5788\n",
      "Epoch 147/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0719 - accuracy: 0.5427 - val_loss: 0.9989 - val_accuracy: 0.5798\n",
      "Epoch 148/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0718 - accuracy: 0.5439 - val_loss: 1.0013 - val_accuracy: 0.5827\n",
      "Epoch 149/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0714 - accuracy: 0.5468 - val_loss: 1.0019 - val_accuracy: 0.5798\n",
      "Epoch 150/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0712 - accuracy: 0.5444 - val_loss: 0.9997 - val_accuracy: 0.5827\n",
      "Epoch 151/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0705 - accuracy: 0.5437 - val_loss: 1.0002 - val_accuracy: 0.5808\n",
      "Epoch 152/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0706 - accuracy: 0.5475 - val_loss: 1.0003 - val_accuracy: 0.5808\n",
      "Epoch 153/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0704 - accuracy: 0.5456 - val_loss: 1.0001 - val_accuracy: 0.5808\n",
      "Epoch 154/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0713 - accuracy: 0.5444 - val_loss: 1.0011 - val_accuracy: 0.5788\n",
      "Epoch 155/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0697 - accuracy: 0.5439 - val_loss: 0.9984 - val_accuracy: 0.5798\n",
      "Epoch 156/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0706 - accuracy: 0.5439 - val_loss: 1.0001 - val_accuracy: 0.5798\n",
      "Epoch 157/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0697 - accuracy: 0.5458 - val_loss: 0.9991 - val_accuracy: 0.5798\n",
      "Epoch 158/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0695 - accuracy: 0.5444 - val_loss: 0.9993 - val_accuracy: 0.5779\n",
      "Epoch 159/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0683 - accuracy: 0.5485 - val_loss: 0.9995 - val_accuracy: 0.5798\n",
      "Epoch 160/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0687 - accuracy: 0.5475 - val_loss: 0.9977 - val_accuracy: 0.5788\n",
      "Epoch 161/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0678 - accuracy: 0.5499 - val_loss: 0.9998 - val_accuracy: 0.5808\n",
      "Epoch 162/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0677 - accuracy: 0.5470 - val_loss: 1.0009 - val_accuracy: 0.5817\n",
      "Epoch 163/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0672 - accuracy: 0.5470 - val_loss: 0.9989 - val_accuracy: 0.5817\n",
      "Epoch 164/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0672 - accuracy: 0.5463 - val_loss: 1.0002 - val_accuracy: 0.5837\n",
      "Epoch 165/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0671 - accuracy: 0.5475 - val_loss: 0.9965 - val_accuracy: 0.5808\n",
      "Epoch 166/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0674 - accuracy: 0.5494 - val_loss: 0.9994 - val_accuracy: 0.5817\n",
      "Epoch 167/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0662 - accuracy: 0.5478 - val_loss: 0.9985 - val_accuracy: 0.5837\n",
      "Epoch 168/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0660 - accuracy: 0.5499 - val_loss: 0.9993 - val_accuracy: 0.5808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0656 - accuracy: 0.5487 - val_loss: 0.9986 - val_accuracy: 0.5837\n",
      "Epoch 170/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0656 - accuracy: 0.5490 - val_loss: 1.0002 - val_accuracy: 0.5827\n",
      "Epoch 171/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0654 - accuracy: 0.5492 - val_loss: 1.0010 - val_accuracy: 0.5837\n",
      "Epoch 172/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0651 - accuracy: 0.5487 - val_loss: 0.9983 - val_accuracy: 0.5750\n",
      "Epoch 173/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0651 - accuracy: 0.5475 - val_loss: 0.9982 - val_accuracy: 0.5817\n",
      "Epoch 174/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0647 - accuracy: 0.5478 - val_loss: 0.9980 - val_accuracy: 0.5788\n",
      "Epoch 175/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0644 - accuracy: 0.5492 - val_loss: 0.9988 - val_accuracy: 0.5817\n",
      "Epoch 176/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0638 - accuracy: 0.5487 - val_loss: 0.9997 - val_accuracy: 0.5817\n",
      "Epoch 177/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0645 - accuracy: 0.5497 - val_loss: 1.0014 - val_accuracy: 0.5798\n",
      "Epoch 178/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0638 - accuracy: 0.5461 - val_loss: 0.9969 - val_accuracy: 0.5788\n",
      "Epoch 179/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0639 - accuracy: 0.5487 - val_loss: 1.0029 - val_accuracy: 0.5808\n",
      "Epoch 180/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0631 - accuracy: 0.5511 - val_loss: 0.9977 - val_accuracy: 0.5837\n",
      "Epoch 181/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0630 - accuracy: 0.5485 - val_loss: 1.0013 - val_accuracy: 0.5846\n",
      "Epoch 182/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0626 - accuracy: 0.5521 - val_loss: 0.9986 - val_accuracy: 0.5808\n",
      "Epoch 183/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0623 - accuracy: 0.5509 - val_loss: 0.9986 - val_accuracy: 0.5788\n",
      "Epoch 184/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0627 - accuracy: 0.5506 - val_loss: 1.0000 - val_accuracy: 0.5817\n",
      "Epoch 185/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0624 - accuracy: 0.5518 - val_loss: 0.9991 - val_accuracy: 0.5808\n",
      "Epoch 186/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0618 - accuracy: 0.5499 - val_loss: 0.9984 - val_accuracy: 0.5808\n",
      "Epoch 187/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0613 - accuracy: 0.5516 - val_loss: 1.0010 - val_accuracy: 0.5846\n",
      "Epoch 188/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0610 - accuracy: 0.5478 - val_loss: 0.9974 - val_accuracy: 0.5769\n",
      "Epoch 189/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0606 - accuracy: 0.5502 - val_loss: 1.0001 - val_accuracy: 0.5808\n",
      "Epoch 190/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0606 - accuracy: 0.5499 - val_loss: 0.9999 - val_accuracy: 0.5808\n",
      "Epoch 191/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0603 - accuracy: 0.5516 - val_loss: 0.9984 - val_accuracy: 0.5788\n",
      "Epoch 192/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0598 - accuracy: 0.5494 - val_loss: 0.9989 - val_accuracy: 0.5808\n",
      "Epoch 193/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0603 - accuracy: 0.5499 - val_loss: 0.9982 - val_accuracy: 0.5788\n",
      "Epoch 194/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0598 - accuracy: 0.5473 - val_loss: 0.9991 - val_accuracy: 0.5808\n",
      "Epoch 195/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0601 - accuracy: 0.5509 - val_loss: 1.0010 - val_accuracy: 0.5827\n",
      "Epoch 196/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0592 - accuracy: 0.5504 - val_loss: 0.9976 - val_accuracy: 0.5837\n",
      "Epoch 197/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0593 - accuracy: 0.5502 - val_loss: 1.0003 - val_accuracy: 0.5808\n",
      "Epoch 198/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0588 - accuracy: 0.5487 - val_loss: 0.9988 - val_accuracy: 0.5827\n",
      "Epoch 199/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0588 - accuracy: 0.5528 - val_loss: 0.9990 - val_accuracy: 0.5808\n",
      "Epoch 200/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0587 - accuracy: 0.5509 - val_loss: 0.9987 - val_accuracy: 0.5808\n",
      "Epoch 201/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0595 - accuracy: 0.5487 - val_loss: 1.0027 - val_accuracy: 0.5827\n",
      "Epoch 202/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0580 - accuracy: 0.5542 - val_loss: 0.9970 - val_accuracy: 0.5827\n",
      "Epoch 203/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0577 - accuracy: 0.5530 - val_loss: 1.0012 - val_accuracy: 0.5808\n",
      "Epoch 204/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0578 - accuracy: 0.5545 - val_loss: 0.9988 - val_accuracy: 0.5827\n",
      "Epoch 205/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0572 - accuracy: 0.5514 - val_loss: 0.9990 - val_accuracy: 0.5808\n",
      "Epoch 206/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0569 - accuracy: 0.5538 - val_loss: 0.9991 - val_accuracy: 0.5808\n",
      "Epoch 207/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0570 - accuracy: 0.5526 - val_loss: 0.9986 - val_accuracy: 0.5760\n",
      "Epoch 208/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0567 - accuracy: 0.5540 - val_loss: 1.0007 - val_accuracy: 0.5808\n",
      "Epoch 209/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0567 - accuracy: 0.5502 - val_loss: 0.9989 - val_accuracy: 0.5817\n",
      "Epoch 210/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0565 - accuracy: 0.5502 - val_loss: 0.9989 - val_accuracy: 0.5817\n",
      "Epoch 211/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0563 - accuracy: 0.5499 - val_loss: 1.0005 - val_accuracy: 0.5827\n",
      "Epoch 212/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0561 - accuracy: 0.5523 - val_loss: 1.0013 - val_accuracy: 0.5817\n",
      "Epoch 213/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0556 - accuracy: 0.5494 - val_loss: 1.0007 - val_accuracy: 0.5808\n",
      "Epoch 214/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0557 - accuracy: 0.5538 - val_loss: 0.9985 - val_accuracy: 0.5837\n",
      "Epoch 215/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0555 - accuracy: 0.5490 - val_loss: 0.9994 - val_accuracy: 0.5856\n",
      "Epoch 216/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0549 - accuracy: 0.5509 - val_loss: 0.9997 - val_accuracy: 0.5808\n",
      "Epoch 217/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0547 - accuracy: 0.5518 - val_loss: 0.9993 - val_accuracy: 0.5827\n",
      "Epoch 218/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0545 - accuracy: 0.5504 - val_loss: 0.9996 - val_accuracy: 0.5837\n",
      "Epoch 219/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0550 - accuracy: 0.5497 - val_loss: 1.0035 - val_accuracy: 0.5827\n",
      "Epoch 220/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0546 - accuracy: 0.5523 - val_loss: 0.9991 - val_accuracy: 0.5798\n",
      "Epoch 221/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0536 - accuracy: 0.5542 - val_loss: 1.0018 - val_accuracy: 0.5788\n",
      "Epoch 222/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0541 - accuracy: 0.5504 - val_loss: 0.9990 - val_accuracy: 0.5846\n",
      "Epoch 223/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0538 - accuracy: 0.5554 - val_loss: 1.0011 - val_accuracy: 0.5798\n",
      "Epoch 224/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0537 - accuracy: 0.5504 - val_loss: 0.9994 - val_accuracy: 0.5798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0536 - accuracy: 0.5521 - val_loss: 0.9999 - val_accuracy: 0.5798\n",
      "Epoch 226/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0531 - accuracy: 0.5504 - val_loss: 1.0000 - val_accuracy: 0.5808\n",
      "Epoch 227/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0536 - accuracy: 0.5518 - val_loss: 1.0011 - val_accuracy: 0.5817\n",
      "Epoch 228/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0534 - accuracy: 0.5530 - val_loss: 0.9991 - val_accuracy: 0.5808\n",
      "Epoch 229/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0529 - accuracy: 0.5540 - val_loss: 0.9993 - val_accuracy: 0.5808\n",
      "Epoch 230/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0526 - accuracy: 0.5499 - val_loss: 0.9997 - val_accuracy: 0.5788\n",
      "Epoch 231/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0535 - accuracy: 0.5506 - val_loss: 1.0007 - val_accuracy: 0.5798\n",
      "Epoch 232/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0519 - accuracy: 0.5526 - val_loss: 1.0015 - val_accuracy: 0.5808\n",
      "Epoch 233/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0521 - accuracy: 0.5514 - val_loss: 0.9987 - val_accuracy: 0.5827\n",
      "Epoch 234/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0519 - accuracy: 0.5504 - val_loss: 1.0006 - val_accuracy: 0.5779\n",
      "Epoch 235/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0517 - accuracy: 0.5518 - val_loss: 1.0010 - val_accuracy: 0.5808\n",
      "Epoch 236/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0514 - accuracy: 0.5535 - val_loss: 0.9994 - val_accuracy: 0.5827\n",
      "Epoch 237/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0512 - accuracy: 0.5509 - val_loss: 1.0023 - val_accuracy: 0.5779\n",
      "Epoch 238/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0509 - accuracy: 0.5533 - val_loss: 0.9995 - val_accuracy: 0.5808\n",
      "Epoch 239/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0512 - accuracy: 0.5526 - val_loss: 1.0018 - val_accuracy: 0.5788\n",
      "Epoch 240/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0507 - accuracy: 0.5494 - val_loss: 0.9978 - val_accuracy: 0.5808\n",
      "Epoch 241/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0508 - accuracy: 0.5518 - val_loss: 1.0007 - val_accuracy: 0.5798\n",
      "Epoch 242/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0503 - accuracy: 0.5497 - val_loss: 1.0009 - val_accuracy: 0.5808\n",
      "Epoch 243/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0504 - accuracy: 0.5523 - val_loss: 1.0033 - val_accuracy: 0.5808\n",
      "Epoch 244/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0510 - accuracy: 0.5547 - val_loss: 0.9994 - val_accuracy: 0.5779\n",
      "Epoch 245/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0499 - accuracy: 0.5545 - val_loss: 1.0005 - val_accuracy: 0.5808\n",
      "Epoch 246/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0498 - accuracy: 0.5526 - val_loss: 0.9991 - val_accuracy: 0.5779\n",
      "Epoch 247/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0497 - accuracy: 0.5518 - val_loss: 1.0014 - val_accuracy: 0.5760\n",
      "Epoch 248/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0499 - accuracy: 0.5521 - val_loss: 0.9991 - val_accuracy: 0.5779\n",
      "Epoch 249/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0499 - accuracy: 0.5523 - val_loss: 1.0015 - val_accuracy: 0.5788\n",
      "Epoch 250/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0486 - accuracy: 0.5550 - val_loss: 1.0000 - val_accuracy: 0.5788\n",
      "Epoch 251/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0486 - accuracy: 0.5533 - val_loss: 1.0005 - val_accuracy: 0.5798\n",
      "Epoch 252/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0491 - accuracy: 0.5497 - val_loss: 1.0014 - val_accuracy: 0.5760\n",
      "Epoch 253/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0485 - accuracy: 0.5533 - val_loss: 1.0025 - val_accuracy: 0.5779\n",
      "Epoch 254/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0479 - accuracy: 0.5511 - val_loss: 1.0013 - val_accuracy: 0.5788\n",
      "Epoch 255/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0482 - accuracy: 0.5514 - val_loss: 1.0027 - val_accuracy: 0.5837\n",
      "Epoch 256/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0481 - accuracy: 0.5494 - val_loss: 1.0003 - val_accuracy: 0.5788\n",
      "Epoch 257/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0485 - accuracy: 0.5514 - val_loss: 1.0009 - val_accuracy: 0.5798\n",
      "Epoch 258/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0479 - accuracy: 0.5518 - val_loss: 1.0013 - val_accuracy: 0.5798\n",
      "Epoch 259/500\n",
      "4157/4157 [==============================] - 0s 7us/step - loss: 1.0477 - accuracy: 0.5511 - val_loss: 0.9992 - val_accuracy: 0.5779\n",
      "Epoch 260/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0473 - accuracy: 0.5523 - val_loss: 1.0027 - val_accuracy: 0.5827\n",
      "Epoch 261/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0468 - accuracy: 0.5557 - val_loss: 1.0003 - val_accuracy: 0.5788\n",
      "Epoch 262/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0471 - accuracy: 0.5518 - val_loss: 1.0033 - val_accuracy: 0.5827\n",
      "Epoch 263/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0471 - accuracy: 0.5564 - val_loss: 0.9997 - val_accuracy: 0.5788\n",
      "Epoch 264/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0472 - accuracy: 0.5516 - val_loss: 1.0040 - val_accuracy: 0.5837\n",
      "Epoch 265/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0467 - accuracy: 0.5506 - val_loss: 1.0020 - val_accuracy: 0.5788\n",
      "Epoch 266/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0461 - accuracy: 0.5521 - val_loss: 1.0031 - val_accuracy: 0.5827\n",
      "Epoch 267/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0463 - accuracy: 0.5506 - val_loss: 1.0006 - val_accuracy: 0.5779\n",
      "Epoch 268/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0461 - accuracy: 0.5526 - val_loss: 1.0027 - val_accuracy: 0.5837\n",
      "Epoch 269/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0459 - accuracy: 0.5538 - val_loss: 1.0013 - val_accuracy: 0.5788\n",
      "Epoch 270/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0455 - accuracy: 0.5516 - val_loss: 1.0028 - val_accuracy: 0.5798\n",
      "Epoch 271/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0453 - accuracy: 0.5530 - val_loss: 1.0028 - val_accuracy: 0.5837\n",
      "Epoch 272/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0452 - accuracy: 0.5533 - val_loss: 1.0023 - val_accuracy: 0.5769\n",
      "Epoch 273/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0453 - accuracy: 0.5514 - val_loss: 1.0021 - val_accuracy: 0.5798\n",
      "Epoch 274/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0455 - accuracy: 0.5535 - val_loss: 1.0018 - val_accuracy: 0.5788\n",
      "Epoch 275/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0447 - accuracy: 0.5523 - val_loss: 1.0021 - val_accuracy: 0.5808\n",
      "Epoch 276/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0445 - accuracy: 0.5523 - val_loss: 1.0028 - val_accuracy: 0.5798\n",
      "Epoch 277/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0442 - accuracy: 0.5509 - val_loss: 1.0021 - val_accuracy: 0.5846\n",
      "Epoch 278/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0444 - accuracy: 0.5523 - val_loss: 1.0049 - val_accuracy: 0.5817\n",
      "Epoch 279/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0446 - accuracy: 0.5538 - val_loss: 1.0026 - val_accuracy: 0.5769\n",
      "Epoch 280/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0442 - accuracy: 0.5523 - val_loss: 1.0028 - val_accuracy: 0.5808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0449 - accuracy: 0.5497 - val_loss: 1.0042 - val_accuracy: 0.5827\n",
      "Epoch 282/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0439 - accuracy: 0.5523 - val_loss: 1.0022 - val_accuracy: 0.5856\n",
      "Epoch 283/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0441 - accuracy: 0.5514 - val_loss: 1.0047 - val_accuracy: 0.5856\n",
      "Epoch 284/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0435 - accuracy: 0.5540 - val_loss: 1.0030 - val_accuracy: 0.5798\n",
      "Epoch 285/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0442 - accuracy: 0.5535 - val_loss: 1.0025 - val_accuracy: 0.5798\n",
      "Epoch 286/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0433 - accuracy: 0.5576 - val_loss: 1.0018 - val_accuracy: 0.5846\n",
      "Epoch 287/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0432 - accuracy: 0.5499 - val_loss: 1.0050 - val_accuracy: 0.5846\n",
      "Epoch 288/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0433 - accuracy: 0.5521 - val_loss: 1.0039 - val_accuracy: 0.5808\n",
      "Epoch 289/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0427 - accuracy: 0.5545 - val_loss: 1.0022 - val_accuracy: 0.5788\n",
      "Epoch 290/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0431 - accuracy: 0.5504 - val_loss: 1.0036 - val_accuracy: 0.5817\n",
      "Epoch 291/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0421 - accuracy: 0.5523 - val_loss: 1.0045 - val_accuracy: 0.5827\n",
      "Epoch 292/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0423 - accuracy: 0.5509 - val_loss: 1.0050 - val_accuracy: 0.5760\n",
      "Epoch 293/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0419 - accuracy: 0.5559 - val_loss: 1.0031 - val_accuracy: 0.5750\n",
      "Epoch 294/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0423 - accuracy: 0.5521 - val_loss: 1.0052 - val_accuracy: 0.5808\n",
      "Epoch 295/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0420 - accuracy: 0.5550 - val_loss: 1.0016 - val_accuracy: 0.5808\n",
      "Epoch 296/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0421 - accuracy: 0.5518 - val_loss: 1.0044 - val_accuracy: 0.5837\n",
      "Epoch 297/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0417 - accuracy: 0.5521 - val_loss: 1.0038 - val_accuracy: 0.5808\n",
      "Epoch 298/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0417 - accuracy: 0.5528 - val_loss: 1.0042 - val_accuracy: 0.5788\n",
      "Epoch 299/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0417 - accuracy: 0.5540 - val_loss: 1.0043 - val_accuracy: 0.5817\n",
      "Epoch 300/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0408 - accuracy: 0.5535 - val_loss: 1.0030 - val_accuracy: 0.5827\n",
      "Epoch 301/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0410 - accuracy: 0.5514 - val_loss: 1.0045 - val_accuracy: 0.5827\n",
      "Epoch 302/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0411 - accuracy: 0.5528 - val_loss: 1.0041 - val_accuracy: 0.5827\n",
      "Epoch 303/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0408 - accuracy: 0.5533 - val_loss: 1.0041 - val_accuracy: 0.5827\n",
      "Epoch 304/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0404 - accuracy: 0.5528 - val_loss: 1.0035 - val_accuracy: 0.5808\n",
      "Epoch 305/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0403 - accuracy: 0.5502 - val_loss: 1.0070 - val_accuracy: 0.5798\n",
      "Epoch 306/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0403 - accuracy: 0.5533 - val_loss: 1.0045 - val_accuracy: 0.5808\n",
      "Epoch 307/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0410 - accuracy: 0.5509 - val_loss: 1.0087 - val_accuracy: 0.5769\n",
      "Epoch 308/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0405 - accuracy: 0.5574 - val_loss: 1.0049 - val_accuracy: 0.5798\n",
      "Epoch 309/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0407 - accuracy: 0.5538 - val_loss: 1.0041 - val_accuracy: 0.5798\n",
      "Epoch 310/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0399 - accuracy: 0.5518 - val_loss: 1.0062 - val_accuracy: 0.5760\n",
      "Epoch 311/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0403 - accuracy: 0.5530 - val_loss: 1.0081 - val_accuracy: 0.5760\n",
      "Epoch 312/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0399 - accuracy: 0.5557 - val_loss: 1.0030 - val_accuracy: 0.5769\n",
      "Epoch 313/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0391 - accuracy: 0.5530 - val_loss: 1.0064 - val_accuracy: 0.5788\n",
      "Epoch 314/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0394 - accuracy: 0.5574 - val_loss: 1.0041 - val_accuracy: 0.5798\n",
      "Epoch 315/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0401 - accuracy: 0.5535 - val_loss: 1.0046 - val_accuracy: 0.5808\n",
      "Epoch 316/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0396 - accuracy: 0.5615 - val_loss: 1.0045 - val_accuracy: 0.5808\n",
      "Epoch 317/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0392 - accuracy: 0.5514 - val_loss: 1.0063 - val_accuracy: 0.5788\n",
      "Epoch 318/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0386 - accuracy: 0.5550 - val_loss: 1.0066 - val_accuracy: 0.5798\n",
      "Epoch 319/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0392 - accuracy: 0.5526 - val_loss: 1.0062 - val_accuracy: 0.5779\n",
      "Epoch 320/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0384 - accuracy: 0.5557 - val_loss: 1.0065 - val_accuracy: 0.5769\n",
      "Epoch 321/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0381 - accuracy: 0.5514 - val_loss: 1.0056 - val_accuracy: 0.5798\n",
      "Epoch 322/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0381 - accuracy: 0.5506 - val_loss: 1.0084 - val_accuracy: 0.5760\n",
      "Epoch 323/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0379 - accuracy: 0.5542 - val_loss: 1.0061 - val_accuracy: 0.5779\n",
      "Epoch 324/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0378 - accuracy: 0.5545 - val_loss: 1.0068 - val_accuracy: 0.5788\n",
      "Epoch 325/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0376 - accuracy: 0.5535 - val_loss: 1.0062 - val_accuracy: 0.5779\n",
      "Epoch 326/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0381 - accuracy: 0.5554 - val_loss: 1.0073 - val_accuracy: 0.5779\n",
      "Epoch 327/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0381 - accuracy: 0.5571 - val_loss: 1.0051 - val_accuracy: 0.5740\n",
      "Epoch 328/500\n",
      "4157/4157 [==============================] - 0s 7us/step - loss: 1.0384 - accuracy: 0.5542 - val_loss: 1.0050 - val_accuracy: 0.5788\n",
      "Epoch 329/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0381 - accuracy: 0.5526 - val_loss: 1.0098 - val_accuracy: 0.5779\n",
      "Epoch 330/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0370 - accuracy: 0.5545 - val_loss: 1.0064 - val_accuracy: 0.5779\n",
      "Epoch 331/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0369 - accuracy: 0.5540 - val_loss: 1.0065 - val_accuracy: 0.5808\n",
      "Epoch 332/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0368 - accuracy: 0.5535 - val_loss: 1.0076 - val_accuracy: 0.5769\n",
      "Epoch 333/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0372 - accuracy: 0.5564 - val_loss: 1.0094 - val_accuracy: 0.5808\n",
      "Epoch 334/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0373 - accuracy: 0.5559 - val_loss: 1.0069 - val_accuracy: 0.5779\n",
      "Epoch 335/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0360 - accuracy: 0.5564 - val_loss: 1.0085 - val_accuracy: 0.5779\n",
      "Epoch 336/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0365 - accuracy: 0.5542 - val_loss: 1.0073 - val_accuracy: 0.5769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0357 - accuracy: 0.5533 - val_loss: 1.0087 - val_accuracy: 0.5750\n",
      "Epoch 338/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0360 - accuracy: 0.5547 - val_loss: 1.0078 - val_accuracy: 0.5750\n",
      "Epoch 339/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0356 - accuracy: 0.5552 - val_loss: 1.0088 - val_accuracy: 0.5788\n",
      "Epoch 340/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0354 - accuracy: 0.5540 - val_loss: 1.0092 - val_accuracy: 0.5750\n",
      "Epoch 341/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0355 - accuracy: 0.5538 - val_loss: 1.0081 - val_accuracy: 0.5760\n",
      "Epoch 342/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0360 - accuracy: 0.5528 - val_loss: 1.0086 - val_accuracy: 0.5769\n",
      "Epoch 343/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0353 - accuracy: 0.5545 - val_loss: 1.0091 - val_accuracy: 0.5798\n",
      "Epoch 344/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0353 - accuracy: 0.5559 - val_loss: 1.0091 - val_accuracy: 0.5779\n",
      "Epoch 345/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0353 - accuracy: 0.5554 - val_loss: 1.0086 - val_accuracy: 0.5769\n",
      "Epoch 346/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0348 - accuracy: 0.5533 - val_loss: 1.0079 - val_accuracy: 0.5750\n",
      "Epoch 347/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0354 - accuracy: 0.5550 - val_loss: 1.0108 - val_accuracy: 0.5779\n",
      "Epoch 348/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0343 - accuracy: 0.5538 - val_loss: 1.0080 - val_accuracy: 0.5750\n",
      "Epoch 349/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0346 - accuracy: 0.5552 - val_loss: 1.0104 - val_accuracy: 0.5760\n",
      "Epoch 350/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0343 - accuracy: 0.5535 - val_loss: 1.0115 - val_accuracy: 0.5769\n",
      "Epoch 351/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0344 - accuracy: 0.5554 - val_loss: 1.0087 - val_accuracy: 0.5760\n",
      "Epoch 352/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0337 - accuracy: 0.5528 - val_loss: 1.0109 - val_accuracy: 0.5750\n",
      "Epoch 353/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0339 - accuracy: 0.5535 - val_loss: 1.0110 - val_accuracy: 0.5760\n",
      "Epoch 354/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0340 - accuracy: 0.5562 - val_loss: 1.0100 - val_accuracy: 0.5779\n",
      "Epoch 355/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0337 - accuracy: 0.5535 - val_loss: 1.0115 - val_accuracy: 0.5740\n",
      "Epoch 356/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0342 - accuracy: 0.5542 - val_loss: 1.0111 - val_accuracy: 0.5760\n",
      "Epoch 357/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0339 - accuracy: 0.5562 - val_loss: 1.0140 - val_accuracy: 0.5788\n",
      "Epoch 358/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0341 - accuracy: 0.5564 - val_loss: 1.0104 - val_accuracy: 0.5721\n",
      "Epoch 359/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0339 - accuracy: 0.5559 - val_loss: 1.0105 - val_accuracy: 0.5788\n",
      "Epoch 360/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0338 - accuracy: 0.5562 - val_loss: 1.0126 - val_accuracy: 0.5760\n",
      "Epoch 361/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0346 - accuracy: 0.5554 - val_loss: 1.0130 - val_accuracy: 0.5788\n",
      "Epoch 362/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0336 - accuracy: 0.5557 - val_loss: 1.0128 - val_accuracy: 0.5750\n",
      "Epoch 363/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0326 - accuracy: 0.5547 - val_loss: 1.0111 - val_accuracy: 0.5760\n",
      "Epoch 364/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0326 - accuracy: 0.5535 - val_loss: 1.0123 - val_accuracy: 0.5731\n",
      "Epoch 365/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0326 - accuracy: 0.5557 - val_loss: 1.0118 - val_accuracy: 0.5750\n",
      "Epoch 366/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0326 - accuracy: 0.5559 - val_loss: 1.0140 - val_accuracy: 0.5788\n",
      "Epoch 367/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0336 - accuracy: 0.5567 - val_loss: 1.0104 - val_accuracy: 0.5683\n",
      "Epoch 368/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0333 - accuracy: 0.5571 - val_loss: 1.0129 - val_accuracy: 0.5721\n",
      "Epoch 369/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0329 - accuracy: 0.5516 - val_loss: 1.0148 - val_accuracy: 0.5798\n",
      "Epoch 370/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0322 - accuracy: 0.5579 - val_loss: 1.0121 - val_accuracy: 0.5740\n",
      "Epoch 371/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0320 - accuracy: 0.5581 - val_loss: 1.0144 - val_accuracy: 0.5798\n",
      "Epoch 372/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0317 - accuracy: 0.5562 - val_loss: 1.0133 - val_accuracy: 0.5769\n",
      "Epoch 373/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0319 - accuracy: 0.5552 - val_loss: 1.0120 - val_accuracy: 0.5750\n",
      "Epoch 374/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0316 - accuracy: 0.5559 - val_loss: 1.0161 - val_accuracy: 0.5798\n",
      "Epoch 375/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0318 - accuracy: 0.5562 - val_loss: 1.0116 - val_accuracy: 0.5712\n",
      "Epoch 376/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0321 - accuracy: 0.5533 - val_loss: 1.0137 - val_accuracy: 0.5808\n",
      "Epoch 377/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0316 - accuracy: 0.5559 - val_loss: 1.0144 - val_accuracy: 0.5798\n",
      "Epoch 378/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0317 - accuracy: 0.5591 - val_loss: 1.0127 - val_accuracy: 0.5702\n",
      "Epoch 379/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0320 - accuracy: 0.5538 - val_loss: 1.0168 - val_accuracy: 0.5769\n",
      "Epoch 380/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0318 - accuracy: 0.5571 - val_loss: 1.0140 - val_accuracy: 0.5769\n",
      "Epoch 381/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0312 - accuracy: 0.5547 - val_loss: 1.0132 - val_accuracy: 0.5808\n",
      "Epoch 382/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0310 - accuracy: 0.5550 - val_loss: 1.0128 - val_accuracy: 0.5760\n",
      "Epoch 383/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0318 - accuracy: 0.5605 - val_loss: 1.0140 - val_accuracy: 0.5721\n",
      "Epoch 384/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0306 - accuracy: 0.5521 - val_loss: 1.0144 - val_accuracy: 0.5769\n",
      "Epoch 385/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0305 - accuracy: 0.5557 - val_loss: 1.0143 - val_accuracy: 0.5721\n",
      "Epoch 386/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0304 - accuracy: 0.5574 - val_loss: 1.0169 - val_accuracy: 0.5788\n",
      "Epoch 387/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0308 - accuracy: 0.5557 - val_loss: 1.0151 - val_accuracy: 0.5712\n",
      "Epoch 388/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0305 - accuracy: 0.5547 - val_loss: 1.0129 - val_accuracy: 0.5740\n",
      "Epoch 389/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0304 - accuracy: 0.5542 - val_loss: 1.0144 - val_accuracy: 0.5769\n",
      "Epoch 390/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0306 - accuracy: 0.5538 - val_loss: 1.0170 - val_accuracy: 0.5779\n",
      "Epoch 391/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0300 - accuracy: 0.5557 - val_loss: 1.0139 - val_accuracy: 0.5760\n",
      "Epoch 392/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0299 - accuracy: 0.5569 - val_loss: 1.0149 - val_accuracy: 0.5769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0298 - accuracy: 0.5545 - val_loss: 1.0155 - val_accuracy: 0.5808\n",
      "Epoch 394/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0299 - accuracy: 0.5557 - val_loss: 1.0162 - val_accuracy: 0.5692\n",
      "Epoch 395/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0295 - accuracy: 0.5598 - val_loss: 1.0159 - val_accuracy: 0.5779\n",
      "Epoch 396/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0298 - accuracy: 0.5552 - val_loss: 1.0144 - val_accuracy: 0.5769\n",
      "Epoch 397/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0307 - accuracy: 0.5576 - val_loss: 1.0170 - val_accuracy: 0.5769\n",
      "Epoch 398/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0291 - accuracy: 0.5547 - val_loss: 1.0159 - val_accuracy: 0.5740\n",
      "Epoch 399/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0291 - accuracy: 0.5567 - val_loss: 1.0166 - val_accuracy: 0.5769\n",
      "Epoch 400/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0295 - accuracy: 0.5552 - val_loss: 1.0148 - val_accuracy: 0.5731\n",
      "Epoch 401/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0293 - accuracy: 0.5559 - val_loss: 1.0168 - val_accuracy: 0.5750\n",
      "Epoch 402/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0288 - accuracy: 0.5547 - val_loss: 1.0163 - val_accuracy: 0.5750\n",
      "Epoch 403/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0287 - accuracy: 0.5564 - val_loss: 1.0148 - val_accuracy: 0.5731\n",
      "Epoch 404/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0288 - accuracy: 0.5574 - val_loss: 1.0180 - val_accuracy: 0.5769\n",
      "Epoch 405/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0288 - accuracy: 0.5579 - val_loss: 1.0154 - val_accuracy: 0.5731\n",
      "Epoch 406/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0289 - accuracy: 0.5547 - val_loss: 1.0164 - val_accuracy: 0.5731\n",
      "Epoch 407/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0283 - accuracy: 0.5559 - val_loss: 1.0179 - val_accuracy: 0.5769\n",
      "Epoch 408/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0284 - accuracy: 0.5562 - val_loss: 1.0173 - val_accuracy: 0.5740\n",
      "Epoch 409/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0284 - accuracy: 0.5559 - val_loss: 1.0188 - val_accuracy: 0.5779\n",
      "Epoch 410/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0284 - accuracy: 0.5550 - val_loss: 1.0177 - val_accuracy: 0.5740\n",
      "Epoch 411/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0288 - accuracy: 0.5538 - val_loss: 1.0154 - val_accuracy: 0.5721\n",
      "Epoch 412/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0285 - accuracy: 0.5564 - val_loss: 1.0206 - val_accuracy: 0.5731\n",
      "Epoch 413/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0281 - accuracy: 0.5591 - val_loss: 1.0164 - val_accuracy: 0.5779\n",
      "Epoch 414/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0281 - accuracy: 0.5535 - val_loss: 1.0169 - val_accuracy: 0.5712\n",
      "Epoch 415/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0279 - accuracy: 0.5562 - val_loss: 1.0175 - val_accuracy: 0.5788\n",
      "Epoch 416/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0276 - accuracy: 0.5564 - val_loss: 1.0190 - val_accuracy: 0.5760\n",
      "Epoch 417/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0275 - accuracy: 0.5562 - val_loss: 1.0156 - val_accuracy: 0.5702\n",
      "Epoch 418/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0273 - accuracy: 0.5559 - val_loss: 1.0192 - val_accuracy: 0.5750\n",
      "Epoch 419/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0275 - accuracy: 0.5547 - val_loss: 1.0187 - val_accuracy: 0.5731\n",
      "Epoch 420/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0283 - accuracy: 0.5564 - val_loss: 1.0174 - val_accuracy: 0.5692\n",
      "Epoch 421/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0275 - accuracy: 0.5564 - val_loss: 1.0214 - val_accuracy: 0.5779\n",
      "Epoch 422/500\n",
      "4157/4157 [==============================] - 0s 7us/step - loss: 1.0274 - accuracy: 0.5542 - val_loss: 1.0167 - val_accuracy: 0.5712\n",
      "Epoch 423/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0276 - accuracy: 0.5538 - val_loss: 1.0217 - val_accuracy: 0.5779\n",
      "Epoch 424/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0269 - accuracy: 0.5581 - val_loss: 1.0177 - val_accuracy: 0.5712\n",
      "Epoch 425/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0274 - accuracy: 0.5564 - val_loss: 1.0188 - val_accuracy: 0.5750\n",
      "Epoch 426/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0272 - accuracy: 0.5538 - val_loss: 1.0201 - val_accuracy: 0.5712\n",
      "Epoch 427/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0270 - accuracy: 0.5564 - val_loss: 1.0176 - val_accuracy: 0.5769\n",
      "Epoch 428/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0264 - accuracy: 0.5569 - val_loss: 1.0183 - val_accuracy: 0.5721\n",
      "Epoch 429/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0267 - accuracy: 0.5550 - val_loss: 1.0181 - val_accuracy: 0.5731\n",
      "Epoch 430/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0263 - accuracy: 0.5562 - val_loss: 1.0190 - val_accuracy: 0.5779\n",
      "Epoch 431/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0264 - accuracy: 0.5562 - val_loss: 1.0189 - val_accuracy: 0.5721\n",
      "Epoch 432/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0270 - accuracy: 0.5550 - val_loss: 1.0194 - val_accuracy: 0.5721\n",
      "Epoch 433/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0262 - accuracy: 0.5562 - val_loss: 1.0208 - val_accuracy: 0.5769\n",
      "Epoch 434/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0266 - accuracy: 0.5605 - val_loss: 1.0173 - val_accuracy: 0.5712\n",
      "Epoch 435/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0269 - accuracy: 0.5564 - val_loss: 1.0208 - val_accuracy: 0.5750\n",
      "Epoch 436/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0267 - accuracy: 0.5581 - val_loss: 1.0201 - val_accuracy: 0.5769\n",
      "Epoch 437/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0258 - accuracy: 0.5540 - val_loss: 1.0185 - val_accuracy: 0.5712\n",
      "Epoch 438/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0263 - accuracy: 0.5552 - val_loss: 1.0183 - val_accuracy: 0.5702\n",
      "Epoch 439/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0255 - accuracy: 0.5588 - val_loss: 1.0204 - val_accuracy: 0.5731\n",
      "Epoch 440/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0254 - accuracy: 0.5530 - val_loss: 1.0197 - val_accuracy: 0.5740\n",
      "Epoch 441/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0258 - accuracy: 0.5598 - val_loss: 1.0221 - val_accuracy: 0.5750\n",
      "Epoch 442/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0267 - accuracy: 0.5583 - val_loss: 1.0207 - val_accuracy: 0.5654\n",
      "Epoch 443/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0251 - accuracy: 0.5559 - val_loss: 1.0213 - val_accuracy: 0.5760\n",
      "Epoch 444/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0252 - accuracy: 0.5603 - val_loss: 1.0200 - val_accuracy: 0.5692\n",
      "Epoch 445/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0250 - accuracy: 0.5559 - val_loss: 1.0207 - val_accuracy: 0.5740\n",
      "Epoch 446/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0250 - accuracy: 0.5591 - val_loss: 1.0222 - val_accuracy: 0.5712\n",
      "Epoch 447/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0247 - accuracy: 0.5581 - val_loss: 1.0202 - val_accuracy: 0.5692\n",
      "Epoch 448/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0256 - accuracy: 0.5528 - val_loss: 1.0202 - val_accuracy: 0.5692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0258 - accuracy: 0.5542 - val_loss: 1.0214 - val_accuracy: 0.5702\n",
      "Epoch 450/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0247 - accuracy: 0.5535 - val_loss: 1.0213 - val_accuracy: 0.5712\n",
      "Epoch 451/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0249 - accuracy: 0.5569 - val_loss: 1.0208 - val_accuracy: 0.5692\n",
      "Epoch 452/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0253 - accuracy: 0.5607 - val_loss: 1.0223 - val_accuracy: 0.5760\n",
      "Epoch 453/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0249 - accuracy: 0.5574 - val_loss: 1.0221 - val_accuracy: 0.5721\n",
      "Epoch 454/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0247 - accuracy: 0.5586 - val_loss: 1.0202 - val_accuracy: 0.5721\n",
      "Epoch 455/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0244 - accuracy: 0.5554 - val_loss: 1.0211 - val_accuracy: 0.5712\n",
      "Epoch 456/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0246 - accuracy: 0.5581 - val_loss: 1.0219 - val_accuracy: 0.5731\n",
      "Epoch 457/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0244 - accuracy: 0.5567 - val_loss: 1.0205 - val_accuracy: 0.5712\n",
      "Epoch 458/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0245 - accuracy: 0.5559 - val_loss: 1.0231 - val_accuracy: 0.5712\n",
      "Epoch 459/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0239 - accuracy: 0.5593 - val_loss: 1.0212 - val_accuracy: 0.5712\n",
      "Epoch 460/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0242 - accuracy: 0.5576 - val_loss: 1.0221 - val_accuracy: 0.5750\n",
      "Epoch 461/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0237 - accuracy: 0.5571 - val_loss: 1.0212 - val_accuracy: 0.5683\n",
      "Epoch 462/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0240 - accuracy: 0.5581 - val_loss: 1.0205 - val_accuracy: 0.5721\n",
      "Epoch 463/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0237 - accuracy: 0.5571 - val_loss: 1.0232 - val_accuracy: 0.5702\n",
      "Epoch 464/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0236 - accuracy: 0.5571 - val_loss: 1.0236 - val_accuracy: 0.5702\n",
      "Epoch 465/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0239 - accuracy: 0.5564 - val_loss: 1.0209 - val_accuracy: 0.5683\n",
      "Epoch 466/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0239 - accuracy: 0.5615 - val_loss: 1.0229 - val_accuracy: 0.5740\n",
      "Epoch 467/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0237 - accuracy: 0.5591 - val_loss: 1.0221 - val_accuracy: 0.5712\n",
      "Epoch 468/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0242 - accuracy: 0.5595 - val_loss: 1.0252 - val_accuracy: 0.5779\n",
      "Epoch 469/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0240 - accuracy: 0.5612 - val_loss: 1.0226 - val_accuracy: 0.5712\n",
      "Epoch 470/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0231 - accuracy: 0.5552 - val_loss: 1.0212 - val_accuracy: 0.5712\n",
      "Epoch 471/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0237 - accuracy: 0.5579 - val_loss: 1.0248 - val_accuracy: 0.5673\n",
      "Epoch 472/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0232 - accuracy: 0.5598 - val_loss: 1.0218 - val_accuracy: 0.5712\n",
      "Epoch 473/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0228 - accuracy: 0.5581 - val_loss: 1.0224 - val_accuracy: 0.5692\n",
      "Epoch 474/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0228 - accuracy: 0.5581 - val_loss: 1.0221 - val_accuracy: 0.5702\n",
      "Epoch 475/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0227 - accuracy: 0.5591 - val_loss: 1.0222 - val_accuracy: 0.5712\n",
      "Epoch 476/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0229 - accuracy: 0.5571 - val_loss: 1.0214 - val_accuracy: 0.5692\n",
      "Epoch 477/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0232 - accuracy: 0.5610 - val_loss: 1.0256 - val_accuracy: 0.5779\n",
      "Epoch 478/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0236 - accuracy: 0.5554 - val_loss: 1.0230 - val_accuracy: 0.5712\n",
      "Epoch 479/500\n",
      "4157/4157 [==============================] - 0s 7us/step - loss: 1.0227 - accuracy: 0.5588 - val_loss: 1.0234 - val_accuracy: 0.5731\n",
      "Epoch 480/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0227 - accuracy: 0.5550 - val_loss: 1.0210 - val_accuracy: 0.5673\n",
      "Epoch 481/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0223 - accuracy: 0.5615 - val_loss: 1.0236 - val_accuracy: 0.5702\n",
      "Epoch 482/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0223 - accuracy: 0.5581 - val_loss: 1.0225 - val_accuracy: 0.5654\n",
      "Epoch 483/500\n",
      "4157/4157 [==============================] - 0s 8us/step - loss: 1.0236 - accuracy: 0.5598 - val_loss: 1.0284 - val_accuracy: 0.5760\n",
      "Epoch 484/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0234 - accuracy: 0.5571 - val_loss: 1.0221 - val_accuracy: 0.5644\n",
      "Epoch 485/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0223 - accuracy: 0.5554 - val_loss: 1.0221 - val_accuracy: 0.5702\n",
      "Epoch 486/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0223 - accuracy: 0.5576 - val_loss: 1.0215 - val_accuracy: 0.5712\n",
      "Epoch 487/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0219 - accuracy: 0.5557 - val_loss: 1.0236 - val_accuracy: 0.5683\n",
      "Epoch 488/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0219 - accuracy: 0.5610 - val_loss: 1.0240 - val_accuracy: 0.5712\n",
      "Epoch 489/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0216 - accuracy: 0.5583 - val_loss: 1.0228 - val_accuracy: 0.5702\n",
      "Epoch 490/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0223 - accuracy: 0.5591 - val_loss: 1.0214 - val_accuracy: 0.5702\n",
      "Epoch 491/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0219 - accuracy: 0.5576 - val_loss: 1.0233 - val_accuracy: 0.5654\n",
      "Epoch 492/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0221 - accuracy: 0.5583 - val_loss: 1.0244 - val_accuracy: 0.5731\n",
      "Epoch 493/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0217 - accuracy: 0.5593 - val_loss: 1.0226 - val_accuracy: 0.5712\n",
      "Epoch 494/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0216 - accuracy: 0.5545 - val_loss: 1.0236 - val_accuracy: 0.5712\n",
      "Epoch 495/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0220 - accuracy: 0.5603 - val_loss: 1.0242 - val_accuracy: 0.5731\n",
      "Epoch 496/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0219 - accuracy: 0.5576 - val_loss: 1.0248 - val_accuracy: 0.5683\n",
      "Epoch 497/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0213 - accuracy: 0.5554 - val_loss: 1.0219 - val_accuracy: 0.5673\n",
      "Epoch 498/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0213 - accuracy: 0.5600 - val_loss: 1.0235 - val_accuracy: 0.5692\n",
      "Epoch 499/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0221 - accuracy: 0.5593 - val_loss: 1.0229 - val_accuracy: 0.5692\n",
      "Epoch 500/500\n",
      "4157/4157 [==============================] - 0s 6us/step - loss: 1.0213 - accuracy: 0.5579 - val_loss: 1.0228 - val_accuracy: 0.5702\n",
      "1300/1300 [==============================] - 0s 4us/step\n",
      "\n",
      "Test Loss: [1.0802226891884437, 0.5438461303710938]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################################################\n",
    "class ANN_classifier(models.Model):\n",
    "    def __init__(self, n_in, n_h, n_out):\n",
    "        hidden = layers.Dense(n_h)\n",
    "        output = layers.Dense(n_out)\n",
    "        relu = layers.Activation('relu')\n",
    "        softmax = layers.Activation('softmax')\n",
    "\n",
    "        x = layers.Input(shape=(n_in,))\n",
    "        h = relu(hidden(x))\n",
    "        y = softmax(output(h))\n",
    "\n",
    "        super().__init__(x, y)\n",
    "        self.compile(loss='categorical_crossentropy',\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "n_in = 11\n",
    "n_h = 32\n",
    "n_out = 10\n",
    "model = ANN_classifier(n_in, n_h, n_out)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=500,\n",
    "                    batch_size=200, validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "performance_test = model.evaluate(x_test, y_test, batch_size=200)\n",
    "\n",
    "print(f'\\nTest Loss: {performance_test}')\n",
    "\n",
    "plot_loss(history)\n",
    "plt.show()\n",
    "plot_acc(history)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5aI6JweqobWc"
   },
   "source": [
    "### 2. 각 모델의 성능을 향상시킬 수 있는 방법 적용\n",
    "* 하이퍼파라미터를 변경하여 테스트 셋에서의 정확도를 향상시킬 것\n",
    "    * 예) 레이어 수, 노드 수, Learning rate 등\n",
    "* 하이퍼파라미터를 변화시킨 각각의 모델에 대해, 트레이닝 Epoch 당 Loss의 변화를 기록하고 이를 시각화\n",
    "* 그 외 성능을 향상시킬 수 있는 모든 방법을 사용하여 가장 성능이 좋은 모델을 선택\n",
    "    * 예) Dropout, Normalization 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5JOT7FBobWc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3134 samples, validate on 784 samples\n",
      "Epoch 1/1000\n",
      "3134/3134 [==============================] - 0s 130us/step - loss: 3.3347 - accuracy: 0.0428 - val_loss: 0.5674 - val_accuracy: 0.2768\n",
      "Epoch 2/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.8239 - accuracy: 0.2288 - val_loss: 0.4636 - val_accuracy: 0.3189\n",
      "Epoch 3/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.6088 - accuracy: 0.2948 - val_loss: 0.6989 - val_accuracy: 0.1735\n",
      "Epoch 4/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.4985 - accuracy: 0.3350 - val_loss: 0.4433 - val_accuracy: 0.3469\n",
      "Epoch 5/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.4395 - accuracy: 0.3504 - val_loss: 0.4996 - val_accuracy: 0.3163\n",
      "Epoch 6/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.4268 - accuracy: 0.3449 - val_loss: 0.3068 - val_accuracy: 0.4758\n",
      "Epoch 7/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.3850 - accuracy: 0.3883 - val_loss: 0.4126 - val_accuracy: 0.3635\n",
      "Epoch 8/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.3570 - accuracy: 0.4091 - val_loss: 0.3052 - val_accuracy: 0.4732\n",
      "Epoch 9/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.3423 - accuracy: 0.4126 - val_loss: 0.3481 - val_accuracy: 0.4145\n",
      "Epoch 10/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.3232 - accuracy: 0.4282 - val_loss: 0.3888 - val_accuracy: 0.3801\n",
      "Epoch 11/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.3366 - accuracy: 0.4292 - val_loss: 0.2718 - val_accuracy: 0.5064\n",
      "Epoch 12/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.3193 - accuracy: 0.4151 - val_loss: 0.3980 - val_accuracy: 0.3865\n",
      "Epoch 13/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.3344 - accuracy: 0.4142 - val_loss: 0.2524 - val_accuracy: 0.5383\n",
      "Epoch 14/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.3132 - accuracy: 0.4295 - val_loss: 0.2978 - val_accuracy: 0.4745\n",
      "Epoch 15/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.3012 - accuracy: 0.4464 - val_loss: 0.2411 - val_accuracy: 0.5332\n",
      "Epoch 16/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2945 - accuracy: 0.4413 - val_loss: 0.2314 - val_accuracy: 0.5344\n",
      "Epoch 17/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2911 - accuracy: 0.4499 - val_loss: 0.2410 - val_accuracy: 0.5370\n",
      "Epoch 18/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2846 - accuracy: 0.4588 - val_loss: 0.2937 - val_accuracy: 0.4796\n",
      "Epoch 19/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2901 - accuracy: 0.4541 - val_loss: 0.2333 - val_accuracy: 0.5344\n",
      "Epoch 20/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2857 - accuracy: 0.4668 - val_loss: 0.2627 - val_accuracy: 0.5255\n",
      "Epoch 21/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2843 - accuracy: 0.4604 - val_loss: 0.2298 - val_accuracy: 0.5472\n",
      "Epoch 22/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2844 - accuracy: 0.4655 - val_loss: 0.2740 - val_accuracy: 0.5026\n",
      "Epoch 23/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2750 - accuracy: 0.4649 - val_loss: 0.2539 - val_accuracy: 0.5268\n",
      "Epoch 24/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2685 - accuracy: 0.4742 - val_loss: 0.2883 - val_accuracy: 0.4821\n",
      "Epoch 25/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2715 - accuracy: 0.4671 - val_loss: 0.2690 - val_accuracy: 0.5166\n",
      "Epoch 26/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2718 - accuracy: 0.4742 - val_loss: 0.2262 - val_accuracy: 0.5510\n",
      "Epoch 27/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2681 - accuracy: 0.4652 - val_loss: 0.2666 - val_accuracy: 0.5102\n",
      "Epoch 28/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2736 - accuracy: 0.4726 - val_loss: 0.2541 - val_accuracy: 0.5293\n",
      "Epoch 29/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2560 - accuracy: 0.4809 - val_loss: 0.2296 - val_accuracy: 0.5434\n",
      "Epoch 30/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2577 - accuracy: 0.4757 - val_loss: 0.2630 - val_accuracy: 0.5230\n",
      "Epoch 31/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2665 - accuracy: 0.4710 - val_loss: 0.2180 - val_accuracy: 0.5395\n",
      "Epoch 32/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2530 - accuracy: 0.4703 - val_loss: 0.2310 - val_accuracy: 0.5587\n",
      "Epoch 33/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2438 - accuracy: 0.4968 - val_loss: 0.2205 - val_accuracy: 0.5625\n",
      "Epoch 34/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2397 - accuracy: 0.5048 - val_loss: 0.2166 - val_accuracy: 0.5574\n",
      "Epoch 35/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2392 - accuracy: 0.4949 - val_loss: 0.2146 - val_accuracy: 0.5497\n",
      "Epoch 36/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2461 - accuracy: 0.5041 - val_loss: 0.2511 - val_accuracy: 0.5179\n",
      "Epoch 37/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2382 - accuracy: 0.5150 - val_loss: 0.2142 - val_accuracy: 0.5523\n",
      "Epoch 38/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2388 - accuracy: 0.4997 - val_loss: 0.2641 - val_accuracy: 0.5038\n",
      "Epoch 39/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2360 - accuracy: 0.5054 - val_loss: 0.2228 - val_accuracy: 0.5485\n",
      "Epoch 40/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2318 - accuracy: 0.5080 - val_loss: 0.2278 - val_accuracy: 0.5510\n",
      "Epoch 41/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2340 - accuracy: 0.5207 - val_loss: 0.2190 - val_accuracy: 0.5574\n",
      "Epoch 42/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2276 - accuracy: 0.5211 - val_loss: 0.2210 - val_accuracy: 0.5574\n",
      "Epoch 43/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2273 - accuracy: 0.5153 - val_loss: 0.2502 - val_accuracy: 0.5064\n",
      "Epoch 44/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.2419 - accuracy: 0.5070 - val_loss: 0.2174 - val_accuracy: 0.5510\n",
      "Epoch 45/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2289 - accuracy: 0.5268 - val_loss: 0.2166 - val_accuracy: 0.5638\n",
      "Epoch 46/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2222 - accuracy: 0.5249 - val_loss: 0.2196 - val_accuracy: 0.5587\n",
      "Epoch 47/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2239 - accuracy: 0.5255 - val_loss: 0.2074 - val_accuracy: 0.5472\n",
      "Epoch 48/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2279 - accuracy: 0.5105 - val_loss: 0.2167 - val_accuracy: 0.5714\n",
      "Epoch 49/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2255 - accuracy: 0.5102 - val_loss: 0.2124 - val_accuracy: 0.5587\n",
      "Epoch 50/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2208 - accuracy: 0.5332 - val_loss: 0.2185 - val_accuracy: 0.5548\n",
      "Epoch 51/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.2188 - accuracy: 0.5265 - val_loss: 0.2050 - val_accuracy: 0.5663\n",
      "Epoch 52/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2260 - accuracy: 0.5185 - val_loss: 0.2235 - val_accuracy: 0.5638\n",
      "Epoch 53/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2200 - accuracy: 0.5198 - val_loss: 0.2218 - val_accuracy: 0.5536\n",
      "Epoch 54/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2166 - accuracy: 0.5278 - val_loss: 0.2102 - val_accuracy: 0.5791\n",
      "Epoch 55/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2210 - accuracy: 0.5258 - val_loss: 0.2152 - val_accuracy: 0.5689\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2162 - accuracy: 0.5217 - val_loss: 0.2087 - val_accuracy: 0.5778\n",
      "Epoch 57/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2235 - accuracy: 0.5195 - val_loss: 0.2190 - val_accuracy: 0.5638\n",
      "Epoch 58/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2160 - accuracy: 0.5274 - val_loss: 0.2066 - val_accuracy: 0.5740\n",
      "Epoch 59/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.2137 - accuracy: 0.5329 - val_loss: 0.2334 - val_accuracy: 0.5485\n",
      "Epoch 60/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2181 - accuracy: 0.5265 - val_loss: 0.2085 - val_accuracy: 0.5485\n",
      "Epoch 61/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2187 - accuracy: 0.5361 - val_loss: 0.2521 - val_accuracy: 0.5332\n",
      "Epoch 62/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2221 - accuracy: 0.5258 - val_loss: 0.2378 - val_accuracy: 0.5255\n",
      "Epoch 63/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2166 - accuracy: 0.5281 - val_loss: 0.2040 - val_accuracy: 0.5702\n",
      "Epoch 64/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2140 - accuracy: 0.5243 - val_loss: 0.2366 - val_accuracy: 0.5217\n",
      "Epoch 65/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2118 - accuracy: 0.5364 - val_loss: 0.2055 - val_accuracy: 0.5638\n",
      "Epoch 66/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2116 - accuracy: 0.5418 - val_loss: 0.2357 - val_accuracy: 0.5446\n",
      "Epoch 67/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2086 - accuracy: 0.5447 - val_loss: 0.2025 - val_accuracy: 0.5816\n",
      "Epoch 68/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2134 - accuracy: 0.5246 - val_loss: 0.2088 - val_accuracy: 0.5714\n",
      "Epoch 69/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2087 - accuracy: 0.5421 - val_loss: 0.2228 - val_accuracy: 0.5510\n",
      "Epoch 70/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2084 - accuracy: 0.5491 - val_loss: 0.2026 - val_accuracy: 0.5867\n",
      "Epoch 71/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.2134 - accuracy: 0.5303 - val_loss: 0.2095 - val_accuracy: 0.5753\n",
      "Epoch 72/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2089 - accuracy: 0.5408 - val_loss: 0.2203 - val_accuracy: 0.5536\n",
      "Epoch 73/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2103 - accuracy: 0.5424 - val_loss: 0.2027 - val_accuracy: 0.5829\n",
      "Epoch 74/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2126 - accuracy: 0.5297 - val_loss: 0.2011 - val_accuracy: 0.5893\n",
      "Epoch 75/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2077 - accuracy: 0.5348 - val_loss: 0.2065 - val_accuracy: 0.5829\n",
      "Epoch 76/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2072 - accuracy: 0.5402 - val_loss: 0.2062 - val_accuracy: 0.5689\n",
      "Epoch 77/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2052 - accuracy: 0.5402 - val_loss: 0.2172 - val_accuracy: 0.5638\n",
      "Epoch 78/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2068 - accuracy: 0.5437 - val_loss: 0.2006 - val_accuracy: 0.5727\n",
      "Epoch 79/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2081 - accuracy: 0.5405 - val_loss: 0.2046 - val_accuracy: 0.5867\n",
      "Epoch 80/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.2074 - accuracy: 0.5466 - val_loss: 0.2008 - val_accuracy: 0.5778\n",
      "Epoch 81/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2063 - accuracy: 0.5453 - val_loss: 0.2174 - val_accuracy: 0.5574\n",
      "Epoch 82/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2093 - accuracy: 0.5396 - val_loss: 0.2040 - val_accuracy: 0.5791\n",
      "Epoch 83/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2127 - accuracy: 0.5348 - val_loss: 0.2327 - val_accuracy: 0.5485\n",
      "Epoch 84/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2145 - accuracy: 0.5357 - val_loss: 0.2030 - val_accuracy: 0.5689\n",
      "Epoch 85/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2113 - accuracy: 0.5383 - val_loss: 0.2023 - val_accuracy: 0.5740\n",
      "Epoch 86/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2067 - accuracy: 0.5546 - val_loss: 0.2007 - val_accuracy: 0.5663\n",
      "Epoch 87/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2064 - accuracy: 0.5408 - val_loss: 0.2172 - val_accuracy: 0.5587\n",
      "Epoch 88/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2043 - accuracy: 0.5472 - val_loss: 0.2132 - val_accuracy: 0.5599\n",
      "Epoch 89/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2032 - accuracy: 0.5562 - val_loss: 0.1992 - val_accuracy: 0.5816\n",
      "Epoch 90/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2105 - accuracy: 0.5431 - val_loss: 0.2137 - val_accuracy: 0.5702\n",
      "Epoch 91/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2070 - accuracy: 0.5428 - val_loss: 0.2035 - val_accuracy: 0.5663\n",
      "Epoch 92/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2033 - accuracy: 0.5571 - val_loss: 0.2025 - val_accuracy: 0.5676\n",
      "Epoch 93/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2059 - accuracy: 0.5418 - val_loss: 0.2007 - val_accuracy: 0.5804\n",
      "Epoch 94/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2046 - accuracy: 0.5539 - val_loss: 0.2062 - val_accuracy: 0.5612\n",
      "Epoch 95/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2077 - accuracy: 0.5523 - val_loss: 0.2037 - val_accuracy: 0.5804\n",
      "Epoch 96/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2054 - accuracy: 0.5539 - val_loss: 0.2054 - val_accuracy: 0.5855\n",
      "Epoch 97/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2043 - accuracy: 0.5622 - val_loss: 0.2104 - val_accuracy: 0.5689\n",
      "Epoch 98/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2040 - accuracy: 0.5491 - val_loss: 0.2007 - val_accuracy: 0.5727\n",
      "Epoch 99/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2094 - accuracy: 0.5466 - val_loss: 0.2040 - val_accuracy: 0.5893\n",
      "Epoch 100/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2049 - accuracy: 0.5514 - val_loss: 0.2088 - val_accuracy: 0.5753\n",
      "Epoch 101/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2017 - accuracy: 0.5514 - val_loss: 0.1990 - val_accuracy: 0.5804\n",
      "Epoch 102/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2040 - accuracy: 0.5539 - val_loss: 0.2024 - val_accuracy: 0.5702\n",
      "Epoch 103/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2080 - accuracy: 0.5456 - val_loss: 0.2176 - val_accuracy: 0.5446\n",
      "Epoch 104/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2069 - accuracy: 0.5475 - val_loss: 0.2133 - val_accuracy: 0.5663\n",
      "Epoch 105/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2047 - accuracy: 0.5412 - val_loss: 0.2086 - val_accuracy: 0.5714\n",
      "Epoch 106/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2013 - accuracy: 0.5539 - val_loss: 0.2050 - val_accuracy: 0.5574\n",
      "Epoch 107/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2086 - accuracy: 0.5488 - val_loss: 0.2054 - val_accuracy: 0.5880\n",
      "Epoch 108/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2017 - accuracy: 0.5479 - val_loss: 0.2012 - val_accuracy: 0.5804\n",
      "Epoch 109/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2029 - accuracy: 0.5517 - val_loss: 0.2058 - val_accuracy: 0.5599\n",
      "Epoch 110/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2061 - accuracy: 0.5418 - val_loss: 0.2242 - val_accuracy: 0.5625\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2123 - accuracy: 0.5392 - val_loss: 0.2185 - val_accuracy: 0.5523\n",
      "Epoch 112/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2056 - accuracy: 0.5475 - val_loss: 0.2020 - val_accuracy: 0.5816\n",
      "Epoch 113/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2039 - accuracy: 0.5549 - val_loss: 0.2026 - val_accuracy: 0.5727\n",
      "Epoch 114/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2015 - accuracy: 0.5421 - val_loss: 0.2034 - val_accuracy: 0.5791\n",
      "Epoch 115/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2020 - accuracy: 0.5475 - val_loss: 0.2148 - val_accuracy: 0.5574\n",
      "Epoch 116/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2019 - accuracy: 0.5609 - val_loss: 0.1978 - val_accuracy: 0.5829\n",
      "Epoch 117/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2071 - accuracy: 0.5482 - val_loss: 0.2002 - val_accuracy: 0.5842\n",
      "Epoch 118/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1988 - accuracy: 0.5533 - val_loss: 0.2041 - val_accuracy: 0.5804\n",
      "Epoch 119/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2004 - accuracy: 0.5632 - val_loss: 0.2063 - val_accuracy: 0.5702\n",
      "Epoch 120/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2034 - accuracy: 0.5511 - val_loss: 0.2151 - val_accuracy: 0.5510\n",
      "Epoch 121/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2023 - accuracy: 0.5549 - val_loss: 0.2054 - val_accuracy: 0.5740\n",
      "Epoch 122/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1984 - accuracy: 0.5558 - val_loss: 0.1987 - val_accuracy: 0.5740\n",
      "Epoch 123/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2031 - accuracy: 0.5466 - val_loss: 0.2153 - val_accuracy: 0.5612\n",
      "Epoch 124/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2052 - accuracy: 0.5453 - val_loss: 0.2083 - val_accuracy: 0.5702\n",
      "Epoch 125/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.2019 - accuracy: 0.5517 - val_loss: 0.1999 - val_accuracy: 0.5867\n",
      "Epoch 126/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2007 - accuracy: 0.5613 - val_loss: 0.2031 - val_accuracy: 0.5740\n",
      "Epoch 127/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2040 - accuracy: 0.5552 - val_loss: 0.2122 - val_accuracy: 0.5663\n",
      "Epoch 128/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2024 - accuracy: 0.5552 - val_loss: 0.2002 - val_accuracy: 0.5612\n",
      "Epoch 129/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1968 - accuracy: 0.5578 - val_loss: 0.2092 - val_accuracy: 0.5651\n",
      "Epoch 130/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2003 - accuracy: 0.5587 - val_loss: 0.2074 - val_accuracy: 0.5663\n",
      "Epoch 131/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1991 - accuracy: 0.5574 - val_loss: 0.1988 - val_accuracy: 0.5791\n",
      "Epoch 132/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1995 - accuracy: 0.5578 - val_loss: 0.2377 - val_accuracy: 0.5357\n",
      "Epoch 133/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2050 - accuracy: 0.5437 - val_loss: 0.2025 - val_accuracy: 0.5765\n",
      "Epoch 134/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.2041 - accuracy: 0.5542 - val_loss: 0.2348 - val_accuracy: 0.5281\n",
      "Epoch 135/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2042 - accuracy: 0.5568 - val_loss: 0.2039 - val_accuracy: 0.5804\n",
      "Epoch 136/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2000 - accuracy: 0.5526 - val_loss: 0.1999 - val_accuracy: 0.5676\n",
      "Epoch 137/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2041 - accuracy: 0.5466 - val_loss: 0.2101 - val_accuracy: 0.5689\n",
      "Epoch 138/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2012 - accuracy: 0.5542 - val_loss: 0.2029 - val_accuracy: 0.5651\n",
      "Epoch 139/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2010 - accuracy: 0.5498 - val_loss: 0.2269 - val_accuracy: 0.5561\n",
      "Epoch 140/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2022 - accuracy: 0.5546 - val_loss: 0.2040 - val_accuracy: 0.5702\n",
      "Epoch 141/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1989 - accuracy: 0.5555 - val_loss: 0.2316 - val_accuracy: 0.5510\n",
      "Epoch 142/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2081 - accuracy: 0.5485 - val_loss: 0.2013 - val_accuracy: 0.5702\n",
      "Epoch 143/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2033 - accuracy: 0.5565 - val_loss: 0.2091 - val_accuracy: 0.5689\n",
      "Epoch 144/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1998 - accuracy: 0.5571 - val_loss: 0.2166 - val_accuracy: 0.5689\n",
      "Epoch 145/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.2001 - accuracy: 0.5558 - val_loss: 0.2427 - val_accuracy: 0.5153\n",
      "Epoch 146/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2032 - accuracy: 0.5533 - val_loss: 0.2074 - val_accuracy: 0.5651\n",
      "Epoch 147/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2000 - accuracy: 0.5574 - val_loss: 0.1982 - val_accuracy: 0.5855\n",
      "Epoch 148/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1969 - accuracy: 0.5645 - val_loss: 0.2246 - val_accuracy: 0.5383\n",
      "Epoch 149/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2030 - accuracy: 0.5485 - val_loss: 0.2171 - val_accuracy: 0.5536\n",
      "Epoch 150/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2012 - accuracy: 0.5542 - val_loss: 0.2175 - val_accuracy: 0.5497\n",
      "Epoch 151/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2032 - accuracy: 0.5482 - val_loss: 0.2016 - val_accuracy: 0.5714\n",
      "Epoch 152/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2020 - accuracy: 0.5412 - val_loss: 0.2088 - val_accuracy: 0.5740\n",
      "Epoch 153/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2005 - accuracy: 0.5504 - val_loss: 0.2021 - val_accuracy: 0.5740\n",
      "Epoch 154/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2122 - accuracy: 0.5354 - val_loss: 0.2040 - val_accuracy: 0.5740\n",
      "Epoch 155/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2018 - accuracy: 0.5504 - val_loss: 0.2046 - val_accuracy: 0.5778\n",
      "Epoch 156/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1986 - accuracy: 0.5578 - val_loss: 0.2052 - val_accuracy: 0.5548\n",
      "Epoch 157/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2026 - accuracy: 0.5472 - val_loss: 0.2018 - val_accuracy: 0.5727\n",
      "Epoch 158/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1977 - accuracy: 0.5587 - val_loss: 0.2068 - val_accuracy: 0.5727\n",
      "Epoch 159/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2008 - accuracy: 0.5536 - val_loss: 0.2054 - val_accuracy: 0.5625\n",
      "Epoch 160/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1948 - accuracy: 0.5558 - val_loss: 0.2030 - val_accuracy: 0.5765\n",
      "Epoch 161/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1979 - accuracy: 0.5660 - val_loss: 0.1997 - val_accuracy: 0.5765\n",
      "Epoch 162/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1953 - accuracy: 0.5587 - val_loss: 0.1990 - val_accuracy: 0.5969\n",
      "Epoch 163/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1978 - accuracy: 0.5571 - val_loss: 0.2022 - val_accuracy: 0.5778\n",
      "Epoch 164/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1959 - accuracy: 0.5747 - val_loss: 0.2018 - val_accuracy: 0.5714\n",
      "Epoch 165/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.2039 - accuracy: 0.5578 - val_loss: 0.2127 - val_accuracy: 0.5702\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1956 - accuracy: 0.5600 - val_loss: 0.2105 - val_accuracy: 0.5714\n",
      "Epoch 167/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.2000 - accuracy: 0.5504 - val_loss: 0.2041 - val_accuracy: 0.5651\n",
      "Epoch 168/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1977 - accuracy: 0.5629 - val_loss: 0.2028 - val_accuracy: 0.5651\n",
      "Epoch 169/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1944 - accuracy: 0.5600 - val_loss: 0.2023 - val_accuracy: 0.5727\n",
      "Epoch 170/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1972 - accuracy: 0.5635 - val_loss: 0.2046 - val_accuracy: 0.5791\n",
      "Epoch 171/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1966 - accuracy: 0.5613 - val_loss: 0.1993 - val_accuracy: 0.5612\n",
      "Epoch 172/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1962 - accuracy: 0.5590 - val_loss: 0.2024 - val_accuracy: 0.5676\n",
      "Epoch 173/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1950 - accuracy: 0.5597 - val_loss: 0.2064 - val_accuracy: 0.5765\n",
      "Epoch 174/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1936 - accuracy: 0.5619 - val_loss: 0.1987 - val_accuracy: 0.5855\n",
      "Epoch 175/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1989 - accuracy: 0.5692 - val_loss: 0.1990 - val_accuracy: 0.5804\n",
      "Epoch 176/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1986 - accuracy: 0.5590 - val_loss: 0.2020 - val_accuracy: 0.5727\n",
      "Epoch 177/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1955 - accuracy: 0.5542 - val_loss: 0.2037 - val_accuracy: 0.5753\n",
      "Epoch 178/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1969 - accuracy: 0.5555 - val_loss: 0.1995 - val_accuracy: 0.5842\n",
      "Epoch 179/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1979 - accuracy: 0.5686 - val_loss: 0.2132 - val_accuracy: 0.5523\n",
      "Epoch 180/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1993 - accuracy: 0.5549 - val_loss: 0.2189 - val_accuracy: 0.5676\n",
      "Epoch 181/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1976 - accuracy: 0.5552 - val_loss: 0.2036 - val_accuracy: 0.5663\n",
      "Epoch 182/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1967 - accuracy: 0.5651 - val_loss: 0.2071 - val_accuracy: 0.5727\n",
      "Epoch 183/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1976 - accuracy: 0.5629 - val_loss: 0.2036 - val_accuracy: 0.5638\n",
      "Epoch 184/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1959 - accuracy: 0.5578 - val_loss: 0.2028 - val_accuracy: 0.5791\n",
      "Epoch 185/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1929 - accuracy: 0.5680 - val_loss: 0.2025 - val_accuracy: 0.5574\n",
      "Epoch 186/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1990 - accuracy: 0.5539 - val_loss: 0.2188 - val_accuracy: 0.5638\n",
      "Epoch 187/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.2000 - accuracy: 0.5562 - val_loss: 0.1995 - val_accuracy: 0.5663\n",
      "Epoch 188/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1946 - accuracy: 0.5629 - val_loss: 0.2095 - val_accuracy: 0.5638\n",
      "Epoch 189/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1962 - accuracy: 0.5648 - val_loss: 0.2059 - val_accuracy: 0.5625\n",
      "Epoch 190/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1972 - accuracy: 0.5466 - val_loss: 0.2020 - val_accuracy: 0.5651\n",
      "Epoch 191/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2014 - accuracy: 0.5581 - val_loss: 0.2048 - val_accuracy: 0.5702\n",
      "Epoch 192/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1961 - accuracy: 0.5625 - val_loss: 0.2035 - val_accuracy: 0.5740\n",
      "Epoch 193/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1976 - accuracy: 0.5558 - val_loss: 0.2109 - val_accuracy: 0.5740\n",
      "Epoch 194/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1970 - accuracy: 0.5590 - val_loss: 0.1997 - val_accuracy: 0.5778\n",
      "Epoch 195/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1971 - accuracy: 0.5632 - val_loss: 0.1997 - val_accuracy: 0.5753\n",
      "Epoch 196/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1967 - accuracy: 0.5542 - val_loss: 0.2038 - val_accuracy: 0.5625\n",
      "Epoch 197/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.2033 - accuracy: 0.5463 - val_loss: 0.2192 - val_accuracy: 0.5638\n",
      "Epoch 198/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1978 - accuracy: 0.5638 - val_loss: 0.2015 - val_accuracy: 0.5727\n",
      "Epoch 199/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1989 - accuracy: 0.5571 - val_loss: 0.2177 - val_accuracy: 0.5510\n",
      "Epoch 200/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2018 - accuracy: 0.5568 - val_loss: 0.2004 - val_accuracy: 0.5587\n",
      "Epoch 201/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1966 - accuracy: 0.5530 - val_loss: 0.2069 - val_accuracy: 0.5765\n",
      "Epoch 202/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1961 - accuracy: 0.5657 - val_loss: 0.2035 - val_accuracy: 0.5574\n",
      "Epoch 203/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1922 - accuracy: 0.5670 - val_loss: 0.2013 - val_accuracy: 0.5791\n",
      "Epoch 204/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1994 - accuracy: 0.5574 - val_loss: 0.2021 - val_accuracy: 0.5765\n",
      "Epoch 205/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1944 - accuracy: 0.5590 - val_loss: 0.1968 - val_accuracy: 0.5842\n",
      "Epoch 206/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1959 - accuracy: 0.5603 - val_loss: 0.2172 - val_accuracy: 0.5651\n",
      "Epoch 207/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1949 - accuracy: 0.5696 - val_loss: 0.1981 - val_accuracy: 0.5982\n",
      "Epoch 208/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1963 - accuracy: 0.5680 - val_loss: 0.2053 - val_accuracy: 0.5778\n",
      "Epoch 209/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1982 - accuracy: 0.5603 - val_loss: 0.2268 - val_accuracy: 0.5459\n",
      "Epoch 210/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1934 - accuracy: 0.5696 - val_loss: 0.1995 - val_accuracy: 0.5753\n",
      "Epoch 211/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1954 - accuracy: 0.5600 - val_loss: 0.2090 - val_accuracy: 0.5765\n",
      "Epoch 212/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1937 - accuracy: 0.5645 - val_loss: 0.2033 - val_accuracy: 0.5714\n",
      "Epoch 213/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1943 - accuracy: 0.5699 - val_loss: 0.2039 - val_accuracy: 0.5663\n",
      "Epoch 214/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1990 - accuracy: 0.5533 - val_loss: 0.2183 - val_accuracy: 0.5638\n",
      "Epoch 215/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1964 - accuracy: 0.5625 - val_loss: 0.2042 - val_accuracy: 0.5791\n",
      "Epoch 216/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1951 - accuracy: 0.5686 - val_loss: 0.2005 - val_accuracy: 0.5702\n",
      "Epoch 217/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1913 - accuracy: 0.5724 - val_loss: 0.2052 - val_accuracy: 0.5702\n",
      "Epoch 218/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1915 - accuracy: 0.5629 - val_loss: 0.2077 - val_accuracy: 0.5651\n",
      "Epoch 219/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1990 - accuracy: 0.5533 - val_loss: 0.2027 - val_accuracy: 0.5727\n",
      "Epoch 220/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1971 - accuracy: 0.5593 - val_loss: 0.2099 - val_accuracy: 0.5714\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2000 - accuracy: 0.5645 - val_loss: 0.2031 - val_accuracy: 0.5880\n",
      "Epoch 222/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1908 - accuracy: 0.5676 - val_loss: 0.2058 - val_accuracy: 0.5791\n",
      "Epoch 223/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1903 - accuracy: 0.5660 - val_loss: 0.2023 - val_accuracy: 0.5829\n",
      "Epoch 224/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1954 - accuracy: 0.5590 - val_loss: 0.2078 - val_accuracy: 0.5816\n",
      "Epoch 225/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1908 - accuracy: 0.5683 - val_loss: 0.2118 - val_accuracy: 0.5574\n",
      "Epoch 226/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1950 - accuracy: 0.5651 - val_loss: 0.2018 - val_accuracy: 0.5982\n",
      "Epoch 227/1000\n",
      "3134/3134 [==============================] - 0s 16us/step - loss: 0.1919 - accuracy: 0.5737 - val_loss: 0.1998 - val_accuracy: 0.5880\n",
      "Epoch 228/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1967 - accuracy: 0.5501 - val_loss: 0.2072 - val_accuracy: 0.5753\n",
      "Epoch 229/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1904 - accuracy: 0.5676 - val_loss: 0.2030 - val_accuracy: 0.5651\n",
      "Epoch 230/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1955 - accuracy: 0.5523 - val_loss: 0.2116 - val_accuracy: 0.5829\n",
      "Epoch 231/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1940 - accuracy: 0.5648 - val_loss: 0.2236 - val_accuracy: 0.5676\n",
      "Epoch 232/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1964 - accuracy: 0.5625 - val_loss: 0.2128 - val_accuracy: 0.5727\n",
      "Epoch 233/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1965 - accuracy: 0.5667 - val_loss: 0.2116 - val_accuracy: 0.5816\n",
      "Epoch 234/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2010 - accuracy: 0.5482 - val_loss: 0.1985 - val_accuracy: 0.5867\n",
      "Epoch 235/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1978 - accuracy: 0.5501 - val_loss: 0.2199 - val_accuracy: 0.5421\n",
      "Epoch 236/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1973 - accuracy: 0.5673 - val_loss: 0.2037 - val_accuracy: 0.5561\n",
      "Epoch 237/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1971 - accuracy: 0.5673 - val_loss: 0.2127 - val_accuracy: 0.5753\n",
      "Epoch 238/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1933 - accuracy: 0.5645 - val_loss: 0.1996 - val_accuracy: 0.5829\n",
      "Epoch 239/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1900 - accuracy: 0.5699 - val_loss: 0.2075 - val_accuracy: 0.5791\n",
      "Epoch 240/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1919 - accuracy: 0.5648 - val_loss: 0.2136 - val_accuracy: 0.5778\n",
      "Epoch 241/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1909 - accuracy: 0.5747 - val_loss: 0.2067 - val_accuracy: 0.5434\n",
      "Epoch 242/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2002 - accuracy: 0.5606 - val_loss: 0.2014 - val_accuracy: 0.5714\n",
      "Epoch 243/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1972 - accuracy: 0.5574 - val_loss: 0.2068 - val_accuracy: 0.5714\n",
      "Epoch 244/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1951 - accuracy: 0.5629 - val_loss: 0.1997 - val_accuracy: 0.5689\n",
      "Epoch 245/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1930 - accuracy: 0.5673 - val_loss: 0.1978 - val_accuracy: 0.5931\n",
      "Epoch 246/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1921 - accuracy: 0.5635 - val_loss: 0.1999 - val_accuracy: 0.5906\n",
      "Epoch 247/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1936 - accuracy: 0.5533 - val_loss: 0.2143 - val_accuracy: 0.5663\n",
      "Epoch 248/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1912 - accuracy: 0.5740 - val_loss: 0.2078 - val_accuracy: 0.5740\n",
      "Epoch 249/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1971 - accuracy: 0.5641 - val_loss: 0.2055 - val_accuracy: 0.5689\n",
      "Epoch 250/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1968 - accuracy: 0.5609 - val_loss: 0.2158 - val_accuracy: 0.5714\n",
      "Epoch 251/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1950 - accuracy: 0.5555 - val_loss: 0.2070 - val_accuracy: 0.5804\n",
      "Epoch 252/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1916 - accuracy: 0.5616 - val_loss: 0.2088 - val_accuracy: 0.5689\n",
      "Epoch 253/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1918 - accuracy: 0.5606 - val_loss: 0.2054 - val_accuracy: 0.5804\n",
      "Epoch 254/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1904 - accuracy: 0.5692 - val_loss: 0.2070 - val_accuracy: 0.5663\n",
      "Epoch 255/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1895 - accuracy: 0.5791 - val_loss: 0.2148 - val_accuracy: 0.5536\n",
      "Epoch 256/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2066 - accuracy: 0.5504 - val_loss: 0.2239 - val_accuracy: 0.5727\n",
      "Epoch 257/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1942 - accuracy: 0.5632 - val_loss: 0.2005 - val_accuracy: 0.5791\n",
      "Epoch 258/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1875 - accuracy: 0.5791 - val_loss: 0.2160 - val_accuracy: 0.5702\n",
      "Epoch 259/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1910 - accuracy: 0.5702 - val_loss: 0.1997 - val_accuracy: 0.5893\n",
      "Epoch 260/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1899 - accuracy: 0.5724 - val_loss: 0.2001 - val_accuracy: 0.5842\n",
      "Epoch 261/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1921 - accuracy: 0.5743 - val_loss: 0.2010 - val_accuracy: 0.5778\n",
      "Epoch 262/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1869 - accuracy: 0.5737 - val_loss: 0.2013 - val_accuracy: 0.5829\n",
      "Epoch 263/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1884 - accuracy: 0.5667 - val_loss: 0.2055 - val_accuracy: 0.5816\n",
      "Epoch 264/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1882 - accuracy: 0.5660 - val_loss: 0.2030 - val_accuracy: 0.5651\n",
      "Epoch 265/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1907 - accuracy: 0.5667 - val_loss: 0.2089 - val_accuracy: 0.5676\n",
      "Epoch 266/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1915 - accuracy: 0.5578 - val_loss: 0.2004 - val_accuracy: 0.5842\n",
      "Epoch 267/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1926 - accuracy: 0.5571 - val_loss: 0.2249 - val_accuracy: 0.5446\n",
      "Epoch 268/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1956 - accuracy: 0.5603 - val_loss: 0.2013 - val_accuracy: 0.5753\n",
      "Epoch 269/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1936 - accuracy: 0.5645 - val_loss: 0.1993 - val_accuracy: 0.5765\n",
      "Epoch 270/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1905 - accuracy: 0.5613 - val_loss: 0.2008 - val_accuracy: 0.5638\n",
      "Epoch 271/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1906 - accuracy: 0.5609 - val_loss: 0.2187 - val_accuracy: 0.5676\n",
      "Epoch 272/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1938 - accuracy: 0.5645 - val_loss: 0.2051 - val_accuracy: 0.5485\n",
      "Epoch 273/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1950 - accuracy: 0.5539 - val_loss: 0.2054 - val_accuracy: 0.5855\n",
      "Epoch 274/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1886 - accuracy: 0.5830 - val_loss: 0.1997 - val_accuracy: 0.5842\n",
      "Epoch 275/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1917 - accuracy: 0.5715 - val_loss: 0.2028 - val_accuracy: 0.5702\n",
      "Epoch 276/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1889 - accuracy: 0.5747 - val_loss: 0.2012 - val_accuracy: 0.5765\n",
      "Epoch 277/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1937 - accuracy: 0.5699 - val_loss: 0.2044 - val_accuracy: 0.5957\n",
      "Epoch 278/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1926 - accuracy: 0.5613 - val_loss: 0.2097 - val_accuracy: 0.5676\n",
      "Epoch 279/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1901 - accuracy: 0.5648 - val_loss: 0.2015 - val_accuracy: 0.5778\n",
      "Epoch 280/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1896 - accuracy: 0.5731 - val_loss: 0.2030 - val_accuracy: 0.5842\n",
      "Epoch 281/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1847 - accuracy: 0.5753 - val_loss: 0.2052 - val_accuracy: 0.5765\n",
      "Epoch 282/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1886 - accuracy: 0.5676 - val_loss: 0.1988 - val_accuracy: 0.5765\n",
      "Epoch 283/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1888 - accuracy: 0.5718 - val_loss: 0.2001 - val_accuracy: 0.5727\n",
      "Epoch 284/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1895 - accuracy: 0.5667 - val_loss: 0.1997 - val_accuracy: 0.5740\n",
      "Epoch 285/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1935 - accuracy: 0.5635 - val_loss: 0.2181 - val_accuracy: 0.5561\n",
      "Epoch 286/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1892 - accuracy: 0.5600 - val_loss: 0.1983 - val_accuracy: 0.5867\n",
      "Epoch 287/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1876 - accuracy: 0.5705 - val_loss: 0.2029 - val_accuracy: 0.5880\n",
      "Epoch 288/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1851 - accuracy: 0.5779 - val_loss: 0.2098 - val_accuracy: 0.5599\n",
      "Epoch 289/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1915 - accuracy: 0.5676 - val_loss: 0.2076 - val_accuracy: 0.5816\n",
      "Epoch 290/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1895 - accuracy: 0.5676 - val_loss: 0.1999 - val_accuracy: 0.5778\n",
      "Epoch 291/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1893 - accuracy: 0.5779 - val_loss: 0.1986 - val_accuracy: 0.5944\n",
      "Epoch 292/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1888 - accuracy: 0.5702 - val_loss: 0.2067 - val_accuracy: 0.5651\n",
      "Epoch 293/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1879 - accuracy: 0.5715 - val_loss: 0.2020 - val_accuracy: 0.5740\n",
      "Epoch 294/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1905 - accuracy: 0.5613 - val_loss: 0.2168 - val_accuracy: 0.5714\n",
      "Epoch 295/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1900 - accuracy: 0.5692 - val_loss: 0.1996 - val_accuracy: 0.5689\n",
      "Epoch 296/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1856 - accuracy: 0.5664 - val_loss: 0.2129 - val_accuracy: 0.5689\n",
      "Epoch 297/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1900 - accuracy: 0.5689 - val_loss: 0.2046 - val_accuracy: 0.5612\n",
      "Epoch 298/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1944 - accuracy: 0.5667 - val_loss: 0.2210 - val_accuracy: 0.5625\n",
      "Epoch 299/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1950 - accuracy: 0.5645 - val_loss: 0.1998 - val_accuracy: 0.5855\n",
      "Epoch 300/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1868 - accuracy: 0.5772 - val_loss: 0.2160 - val_accuracy: 0.5638\n",
      "Epoch 301/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1908 - accuracy: 0.5673 - val_loss: 0.2223 - val_accuracy: 0.5689\n",
      "Epoch 302/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1886 - accuracy: 0.5696 - val_loss: 0.2075 - val_accuracy: 0.5689\n",
      "Epoch 303/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1826 - accuracy: 0.5852 - val_loss: 0.2019 - val_accuracy: 0.5791\n",
      "Epoch 304/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1833 - accuracy: 0.5833 - val_loss: 0.2015 - val_accuracy: 0.5816\n",
      "Epoch 305/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1878 - accuracy: 0.5622 - val_loss: 0.2034 - val_accuracy: 0.5778\n",
      "Epoch 306/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1878 - accuracy: 0.5740 - val_loss: 0.2169 - val_accuracy: 0.5740\n",
      "Epoch 307/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1918 - accuracy: 0.5667 - val_loss: 0.2025 - val_accuracy: 0.5791\n",
      "Epoch 308/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1860 - accuracy: 0.5817 - val_loss: 0.1996 - val_accuracy: 0.5867\n",
      "Epoch 309/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1882 - accuracy: 0.5791 - val_loss: 0.2008 - val_accuracy: 0.5778\n",
      "Epoch 310/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1880 - accuracy: 0.5712 - val_loss: 0.2003 - val_accuracy: 0.5753\n",
      "Epoch 311/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1863 - accuracy: 0.5705 - val_loss: 0.2239 - val_accuracy: 0.5638\n",
      "Epoch 312/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1855 - accuracy: 0.5820 - val_loss: 0.2059 - val_accuracy: 0.5778\n",
      "Epoch 313/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1874 - accuracy: 0.5801 - val_loss: 0.2143 - val_accuracy: 0.5765\n",
      "Epoch 314/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1852 - accuracy: 0.5775 - val_loss: 0.2095 - val_accuracy: 0.5663\n",
      "Epoch 315/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1835 - accuracy: 0.5951 - val_loss: 0.2002 - val_accuracy: 0.5791\n",
      "Epoch 316/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1910 - accuracy: 0.5676 - val_loss: 0.2236 - val_accuracy: 0.5599\n",
      "Epoch 317/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1859 - accuracy: 0.5721 - val_loss: 0.1975 - val_accuracy: 0.5982\n",
      "Epoch 318/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1833 - accuracy: 0.5804 - val_loss: 0.2024 - val_accuracy: 0.5753\n",
      "Epoch 319/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1859 - accuracy: 0.5737 - val_loss: 0.2086 - val_accuracy: 0.5651\n",
      "Epoch 320/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1826 - accuracy: 0.5699 - val_loss: 0.2033 - val_accuracy: 0.5727\n",
      "Epoch 321/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1851 - accuracy: 0.5791 - val_loss: 0.2076 - val_accuracy: 0.5714\n",
      "Epoch 322/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1850 - accuracy: 0.5862 - val_loss: 0.2086 - val_accuracy: 0.5523\n",
      "Epoch 323/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1924 - accuracy: 0.5641 - val_loss: 0.2159 - val_accuracy: 0.5663\n",
      "Epoch 324/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1843 - accuracy: 0.5616 - val_loss: 0.2032 - val_accuracy: 0.5714\n",
      "Epoch 325/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1873 - accuracy: 0.5740 - val_loss: 0.2104 - val_accuracy: 0.5982\n",
      "Epoch 326/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1885 - accuracy: 0.5763 - val_loss: 0.1972 - val_accuracy: 0.5829\n",
      "Epoch 327/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1854 - accuracy: 0.5779 - val_loss: 0.1975 - val_accuracy: 0.5918\n",
      "Epoch 328/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1845 - accuracy: 0.5750 - val_loss: 0.2001 - val_accuracy: 0.5829\n",
      "Epoch 329/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1848 - accuracy: 0.5830 - val_loss: 0.2152 - val_accuracy: 0.5753\n",
      "Epoch 330/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1864 - accuracy: 0.5846 - val_loss: 0.2046 - val_accuracy: 0.5689\n",
      "Epoch 331/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1837 - accuracy: 0.5874 - val_loss: 0.2086 - val_accuracy: 0.5651\n",
      "Epoch 332/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1853 - accuracy: 0.5772 - val_loss: 0.2047 - val_accuracy: 0.5867\n",
      "Epoch 333/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1850 - accuracy: 0.5814 - val_loss: 0.2027 - val_accuracy: 0.5855\n",
      "Epoch 334/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1875 - accuracy: 0.5750 - val_loss: 0.2056 - val_accuracy: 0.5842\n",
      "Epoch 335/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1827 - accuracy: 0.5750 - val_loss: 0.2031 - val_accuracy: 0.5855\n",
      "Epoch 336/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1837 - accuracy: 0.5743 - val_loss: 0.2001 - val_accuracy: 0.5867\n",
      "Epoch 337/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1857 - accuracy: 0.5686 - val_loss: 0.2094 - val_accuracy: 0.5918\n",
      "Epoch 338/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1838 - accuracy: 0.5855 - val_loss: 0.2033 - val_accuracy: 0.5702\n",
      "Epoch 339/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1893 - accuracy: 0.5807 - val_loss: 0.2301 - val_accuracy: 0.5497\n",
      "Epoch 340/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1890 - accuracy: 0.5708 - val_loss: 0.2083 - val_accuracy: 0.5523\n",
      "Epoch 341/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1905 - accuracy: 0.5724 - val_loss: 0.2091 - val_accuracy: 0.5791\n",
      "Epoch 342/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1848 - accuracy: 0.5708 - val_loss: 0.2009 - val_accuracy: 0.5651\n",
      "Epoch 343/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1835 - accuracy: 0.5830 - val_loss: 0.1987 - val_accuracy: 0.5829\n",
      "Epoch 344/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1829 - accuracy: 0.5826 - val_loss: 0.2011 - val_accuracy: 0.6033\n",
      "Epoch 345/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1798 - accuracy: 0.5855 - val_loss: 0.1988 - val_accuracy: 0.5651\n",
      "Epoch 346/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1849 - accuracy: 0.5772 - val_loss: 0.2100 - val_accuracy: 0.5702\n",
      "Epoch 347/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1830 - accuracy: 0.5849 - val_loss: 0.2176 - val_accuracy: 0.5651\n",
      "Epoch 348/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1884 - accuracy: 0.5705 - val_loss: 0.2022 - val_accuracy: 0.5753\n",
      "Epoch 349/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1817 - accuracy: 0.5807 - val_loss: 0.2044 - val_accuracy: 0.5778\n",
      "Epoch 350/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1795 - accuracy: 0.5817 - val_loss: 0.2002 - val_accuracy: 0.5676\n",
      "Epoch 351/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1827 - accuracy: 0.5836 - val_loss: 0.1998 - val_accuracy: 0.5918\n",
      "Epoch 352/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1841 - accuracy: 0.5833 - val_loss: 0.2263 - val_accuracy: 0.5663\n",
      "Epoch 353/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1846 - accuracy: 0.5842 - val_loss: 0.1996 - val_accuracy: 0.5855\n",
      "Epoch 354/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1790 - accuracy: 0.5932 - val_loss: 0.2010 - val_accuracy: 0.5765\n",
      "Epoch 355/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1809 - accuracy: 0.5801 - val_loss: 0.2143 - val_accuracy: 0.5778\n",
      "Epoch 356/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1834 - accuracy: 0.5830 - val_loss: 0.1955 - val_accuracy: 0.5893\n",
      "Epoch 357/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1840 - accuracy: 0.5807 - val_loss: 0.2033 - val_accuracy: 0.5867\n",
      "Epoch 358/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1820 - accuracy: 0.5833 - val_loss: 0.1989 - val_accuracy: 0.5829\n",
      "Epoch 359/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1802 - accuracy: 0.5865 - val_loss: 0.1957 - val_accuracy: 0.5855\n",
      "Epoch 360/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1834 - accuracy: 0.5909 - val_loss: 0.2012 - val_accuracy: 0.5829\n",
      "Epoch 361/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1833 - accuracy: 0.5785 - val_loss: 0.2013 - val_accuracy: 0.5867\n",
      "Epoch 362/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1790 - accuracy: 0.5874 - val_loss: 0.2306 - val_accuracy: 0.5510\n",
      "Epoch 363/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1901 - accuracy: 0.5734 - val_loss: 0.2093 - val_accuracy: 0.5536\n",
      "Epoch 364/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.2010 - accuracy: 0.5613 - val_loss: 0.2445 - val_accuracy: 0.5434\n",
      "Epoch 365/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1940 - accuracy: 0.5619 - val_loss: 0.2018 - val_accuracy: 0.5651\n",
      "Epoch 366/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1809 - accuracy: 0.5826 - val_loss: 0.2030 - val_accuracy: 0.5689\n",
      "Epoch 367/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1780 - accuracy: 0.5855 - val_loss: 0.2001 - val_accuracy: 0.5880\n",
      "Epoch 368/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1819 - accuracy: 0.5807 - val_loss: 0.1957 - val_accuracy: 0.5816\n",
      "Epoch 369/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1842 - accuracy: 0.5842 - val_loss: 0.2033 - val_accuracy: 0.5689\n",
      "Epoch 370/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1811 - accuracy: 0.5817 - val_loss: 0.1971 - val_accuracy: 0.5893\n",
      "Epoch 371/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1816 - accuracy: 0.5855 - val_loss: 0.2084 - val_accuracy: 0.5676\n",
      "Epoch 372/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1801 - accuracy: 0.5922 - val_loss: 0.2023 - val_accuracy: 0.5702\n",
      "Epoch 373/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1769 - accuracy: 0.5858 - val_loss: 0.2013 - val_accuracy: 0.5689\n",
      "Epoch 374/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1859 - accuracy: 0.5721 - val_loss: 0.2004 - val_accuracy: 0.5702\n",
      "Epoch 375/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1802 - accuracy: 0.5830 - val_loss: 0.1956 - val_accuracy: 0.5931\n",
      "Epoch 376/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1780 - accuracy: 0.5833 - val_loss: 0.2028 - val_accuracy: 0.5714\n",
      "Epoch 377/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1896 - accuracy: 0.5705 - val_loss: 0.2077 - val_accuracy: 0.5689\n",
      "Epoch 378/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1818 - accuracy: 0.5728 - val_loss: 0.2048 - val_accuracy: 0.5855\n",
      "Epoch 379/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1846 - accuracy: 0.5769 - val_loss: 0.2010 - val_accuracy: 0.5663\n",
      "Epoch 380/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1834 - accuracy: 0.5705 - val_loss: 0.1999 - val_accuracy: 0.5765\n",
      "Epoch 381/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1781 - accuracy: 0.5989 - val_loss: 0.2085 - val_accuracy: 0.5791\n",
      "Epoch 382/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1829 - accuracy: 0.5887 - val_loss: 0.2021 - val_accuracy: 0.5855\n",
      "Epoch 383/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1773 - accuracy: 0.5944 - val_loss: 0.1993 - val_accuracy: 0.5893\n",
      "Epoch 384/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1804 - accuracy: 0.5833 - val_loss: 0.2185 - val_accuracy: 0.5587\n",
      "Epoch 385/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1856 - accuracy: 0.5795 - val_loss: 0.1982 - val_accuracy: 0.5829\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1804 - accuracy: 0.5925 - val_loss: 0.1987 - val_accuracy: 0.5791\n",
      "Epoch 387/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1797 - accuracy: 0.5906 - val_loss: 0.2070 - val_accuracy: 0.5893\n",
      "Epoch 388/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1801 - accuracy: 0.5753 - val_loss: 0.1989 - val_accuracy: 0.5753\n",
      "Epoch 389/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1806 - accuracy: 0.5782 - val_loss: 0.2060 - val_accuracy: 0.5702\n",
      "Epoch 390/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1841 - accuracy: 0.5769 - val_loss: 0.2001 - val_accuracy: 0.5740\n",
      "Epoch 391/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1840 - accuracy: 0.5820 - val_loss: 0.1971 - val_accuracy: 0.5816\n",
      "Epoch 392/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1811 - accuracy: 0.5900 - val_loss: 0.2167 - val_accuracy: 0.5740\n",
      "Epoch 393/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1884 - accuracy: 0.5708 - val_loss: 0.2022 - val_accuracy: 0.5880\n",
      "Epoch 394/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1809 - accuracy: 0.5929 - val_loss: 0.2082 - val_accuracy: 0.5689\n",
      "Epoch 395/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1797 - accuracy: 0.5852 - val_loss: 0.1966 - val_accuracy: 0.5778\n",
      "Epoch 396/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1786 - accuracy: 0.5852 - val_loss: 0.1963 - val_accuracy: 0.5842\n",
      "Epoch 397/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1799 - accuracy: 0.5906 - val_loss: 0.2159 - val_accuracy: 0.5842\n",
      "Epoch 398/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1877 - accuracy: 0.5769 - val_loss: 0.2003 - val_accuracy: 0.5893\n",
      "Epoch 399/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1829 - accuracy: 0.5807 - val_loss: 0.2003 - val_accuracy: 0.5944\n",
      "Epoch 400/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1789 - accuracy: 0.5881 - val_loss: 0.1984 - val_accuracy: 0.5753\n",
      "Epoch 401/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1813 - accuracy: 0.5852 - val_loss: 0.2154 - val_accuracy: 0.5714\n",
      "Epoch 402/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1790 - accuracy: 0.5795 - val_loss: 0.2061 - val_accuracy: 0.5804\n",
      "Epoch 403/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1773 - accuracy: 0.5842 - val_loss: 0.2109 - val_accuracy: 0.5702\n",
      "Epoch 404/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1801 - accuracy: 0.5772 - val_loss: 0.2009 - val_accuracy: 0.5842\n",
      "Epoch 405/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1813 - accuracy: 0.5868 - val_loss: 0.2001 - val_accuracy: 0.5740\n",
      "Epoch 406/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1780 - accuracy: 0.5807 - val_loss: 0.2008 - val_accuracy: 0.5842\n",
      "Epoch 407/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1773 - accuracy: 0.5839 - val_loss: 0.2064 - val_accuracy: 0.5855\n",
      "Epoch 408/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1795 - accuracy: 0.5846 - val_loss: 0.1991 - val_accuracy: 0.5867\n",
      "Epoch 409/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1741 - accuracy: 0.5989 - val_loss: 0.2023 - val_accuracy: 0.5804\n",
      "Epoch 410/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1780 - accuracy: 0.5836 - val_loss: 0.1981 - val_accuracy: 0.5816\n",
      "Epoch 411/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1785 - accuracy: 0.5897 - val_loss: 0.2005 - val_accuracy: 0.5765\n",
      "Epoch 412/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1814 - accuracy: 0.5753 - val_loss: 0.2257 - val_accuracy: 0.5548\n",
      "Epoch 413/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1803 - accuracy: 0.5913 - val_loss: 0.1975 - val_accuracy: 0.5842\n",
      "Epoch 414/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1793 - accuracy: 0.5925 - val_loss: 0.2048 - val_accuracy: 0.5995\n",
      "Epoch 415/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1786 - accuracy: 0.5935 - val_loss: 0.2016 - val_accuracy: 0.5829\n",
      "Epoch 416/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1840 - accuracy: 0.5801 - val_loss: 0.2042 - val_accuracy: 0.5676\n",
      "Epoch 417/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1803 - accuracy: 0.5852 - val_loss: 0.1989 - val_accuracy: 0.5804\n",
      "Epoch 418/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1801 - accuracy: 0.5935 - val_loss: 0.2007 - val_accuracy: 0.5765\n",
      "Epoch 419/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1754 - accuracy: 0.5948 - val_loss: 0.1933 - val_accuracy: 0.6008\n",
      "Epoch 420/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1775 - accuracy: 0.5906 - val_loss: 0.1979 - val_accuracy: 0.5969\n",
      "Epoch 421/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1745 - accuracy: 0.5925 - val_loss: 0.2137 - val_accuracy: 0.5804\n",
      "Epoch 422/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1781 - accuracy: 0.5960 - val_loss: 0.2117 - val_accuracy: 0.5676\n",
      "Epoch 423/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1756 - accuracy: 0.5887 - val_loss: 0.2088 - val_accuracy: 0.5689\n",
      "Epoch 424/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1827 - accuracy: 0.5839 - val_loss: 0.1968 - val_accuracy: 0.5918\n",
      "Epoch 425/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1795 - accuracy: 0.5913 - val_loss: 0.2007 - val_accuracy: 0.5880\n",
      "Epoch 426/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1776 - accuracy: 0.5986 - val_loss: 0.1976 - val_accuracy: 0.5791\n",
      "Epoch 427/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1789 - accuracy: 0.5887 - val_loss: 0.2210 - val_accuracy: 0.5663\n",
      "Epoch 428/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1934 - accuracy: 0.5673 - val_loss: 0.2047 - val_accuracy: 0.5663\n",
      "Epoch 429/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1800 - accuracy: 0.5826 - val_loss: 0.2001 - val_accuracy: 0.5791\n",
      "Epoch 430/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1845 - accuracy: 0.5817 - val_loss: 0.2095 - val_accuracy: 0.5906\n",
      "Epoch 431/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1769 - accuracy: 0.5960 - val_loss: 0.2049 - val_accuracy: 0.5778\n",
      "Epoch 432/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1790 - accuracy: 0.5858 - val_loss: 0.1975 - val_accuracy: 0.5816\n",
      "Epoch 433/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1776 - accuracy: 0.5929 - val_loss: 0.1981 - val_accuracy: 0.5880\n",
      "Epoch 434/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1778 - accuracy: 0.5871 - val_loss: 0.1966 - val_accuracy: 0.5918\n",
      "Epoch 435/1000\n",
      "3134/3134 [==============================] - 0s 16us/step - loss: 0.1763 - accuracy: 0.5944 - val_loss: 0.2028 - val_accuracy: 0.5893\n",
      "Epoch 436/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1798 - accuracy: 0.5823 - val_loss: 0.2000 - val_accuracy: 0.5867\n",
      "Epoch 437/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1808 - accuracy: 0.5795 - val_loss: 0.2223 - val_accuracy: 0.5587\n",
      "Epoch 438/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1854 - accuracy: 0.5772 - val_loss: 0.2057 - val_accuracy: 0.5689\n",
      "Epoch 439/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1900 - accuracy: 0.5651 - val_loss: 0.2120 - val_accuracy: 0.5651\n",
      "Epoch 440/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1798 - accuracy: 0.5839 - val_loss: 0.1966 - val_accuracy: 0.5918\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1773 - accuracy: 0.5951 - val_loss: 0.1974 - val_accuracy: 0.5906\n",
      "Epoch 442/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1787 - accuracy: 0.5954 - val_loss: 0.2216 - val_accuracy: 0.5536\n",
      "Epoch 443/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1833 - accuracy: 0.5795 - val_loss: 0.1944 - val_accuracy: 0.5982\n",
      "Epoch 444/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1830 - accuracy: 0.5852 - val_loss: 0.1980 - val_accuracy: 0.5957\n",
      "Epoch 445/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1819 - accuracy: 0.5830 - val_loss: 0.2018 - val_accuracy: 0.5714\n",
      "Epoch 446/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1809 - accuracy: 0.5788 - val_loss: 0.1972 - val_accuracy: 0.5969\n",
      "Epoch 447/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1796 - accuracy: 0.5868 - val_loss: 0.2036 - val_accuracy: 0.5995\n",
      "Epoch 448/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1781 - accuracy: 0.5893 - val_loss: 0.2018 - val_accuracy: 0.5778\n",
      "Epoch 449/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1799 - accuracy: 0.5967 - val_loss: 0.2155 - val_accuracy: 0.5804\n",
      "Epoch 450/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1854 - accuracy: 0.5897 - val_loss: 0.2041 - val_accuracy: 0.5612\n",
      "Epoch 451/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1872 - accuracy: 0.5839 - val_loss: 0.2163 - val_accuracy: 0.5676\n",
      "Epoch 452/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1804 - accuracy: 0.5887 - val_loss: 0.2042 - val_accuracy: 0.5612\n",
      "Epoch 453/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1782 - accuracy: 0.5944 - val_loss: 0.2040 - val_accuracy: 0.5855\n",
      "Epoch 454/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1767 - accuracy: 0.5913 - val_loss: 0.2046 - val_accuracy: 0.5778\n",
      "Epoch 455/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1746 - accuracy: 0.5948 - val_loss: 0.1979 - val_accuracy: 0.5867\n",
      "Epoch 456/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1715 - accuracy: 0.5887 - val_loss: 0.2036 - val_accuracy: 0.5931\n",
      "Epoch 457/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1779 - accuracy: 0.5893 - val_loss: 0.1990 - val_accuracy: 0.5880\n",
      "Epoch 458/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1729 - accuracy: 0.6037 - val_loss: 0.2028 - val_accuracy: 0.5855\n",
      "Epoch 459/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1774 - accuracy: 0.5922 - val_loss: 0.2003 - val_accuracy: 0.5816\n",
      "Epoch 460/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1755 - accuracy: 0.5932 - val_loss: 0.2164 - val_accuracy: 0.5702\n",
      "Epoch 461/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1828 - accuracy: 0.5954 - val_loss: 0.2014 - val_accuracy: 0.5855\n",
      "Epoch 462/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1749 - accuracy: 0.5976 - val_loss: 0.1955 - val_accuracy: 0.5957\n",
      "Epoch 463/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1782 - accuracy: 0.5842 - val_loss: 0.1975 - val_accuracy: 0.5982\n",
      "Epoch 464/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1712 - accuracy: 0.5976 - val_loss: 0.2071 - val_accuracy: 0.5880\n",
      "Epoch 465/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1781 - accuracy: 0.5919 - val_loss: 0.2014 - val_accuracy: 0.5791\n",
      "Epoch 466/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1774 - accuracy: 0.6018 - val_loss: 0.1967 - val_accuracy: 0.5969\n",
      "Epoch 467/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1746 - accuracy: 0.5893 - val_loss: 0.2004 - val_accuracy: 0.5893\n",
      "Epoch 468/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1776 - accuracy: 0.5909 - val_loss: 0.2109 - val_accuracy: 0.5676\n",
      "Epoch 469/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1750 - accuracy: 0.5999 - val_loss: 0.2016 - val_accuracy: 0.5816\n",
      "Epoch 470/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1699 - accuracy: 0.6040 - val_loss: 0.2031 - val_accuracy: 0.5931\n",
      "Epoch 471/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1721 - accuracy: 0.5954 - val_loss: 0.2008 - val_accuracy: 0.5816\n",
      "Epoch 472/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1728 - accuracy: 0.5957 - val_loss: 0.1992 - val_accuracy: 0.5880\n",
      "Epoch 473/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1765 - accuracy: 0.6015 - val_loss: 0.2092 - val_accuracy: 0.5727\n",
      "Epoch 474/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1802 - accuracy: 0.5916 - val_loss: 0.2268 - val_accuracy: 0.5587\n",
      "Epoch 475/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1791 - accuracy: 0.5839 - val_loss: 0.2034 - val_accuracy: 0.5612\n",
      "Epoch 476/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1802 - accuracy: 0.5887 - val_loss: 0.2039 - val_accuracy: 0.5791\n",
      "Epoch 477/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1752 - accuracy: 0.5992 - val_loss: 0.2070 - val_accuracy: 0.5625\n",
      "Epoch 478/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1799 - accuracy: 0.5849 - val_loss: 0.2266 - val_accuracy: 0.5561\n",
      "Epoch 479/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1797 - accuracy: 0.5881 - val_loss: 0.2079 - val_accuracy: 0.5702\n",
      "Epoch 480/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1746 - accuracy: 0.5989 - val_loss: 0.1985 - val_accuracy: 0.5931\n",
      "Epoch 481/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1698 - accuracy: 0.6130 - val_loss: 0.1996 - val_accuracy: 0.5816\n",
      "Epoch 482/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1763 - accuracy: 0.5913 - val_loss: 0.2332 - val_accuracy: 0.5574\n",
      "Epoch 483/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1791 - accuracy: 0.5922 - val_loss: 0.2100 - val_accuracy: 0.5753\n",
      "Epoch 484/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1795 - accuracy: 0.5881 - val_loss: 0.2219 - val_accuracy: 0.5689\n",
      "Epoch 485/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1813 - accuracy: 0.5810 - val_loss: 0.1999 - val_accuracy: 0.5778\n",
      "Epoch 486/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1793 - accuracy: 0.5884 - val_loss: 0.2048 - val_accuracy: 0.5702\n",
      "Epoch 487/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1796 - accuracy: 0.5964 - val_loss: 0.2099 - val_accuracy: 0.5714\n",
      "Epoch 488/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1728 - accuracy: 0.5976 - val_loss: 0.2225 - val_accuracy: 0.5574\n",
      "Epoch 489/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1798 - accuracy: 0.5913 - val_loss: 0.1967 - val_accuracy: 0.5880\n",
      "Epoch 490/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1739 - accuracy: 0.6008 - val_loss: 0.2054 - val_accuracy: 0.5702\n",
      "Epoch 491/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1733 - accuracy: 0.6018 - val_loss: 0.1981 - val_accuracy: 0.5867\n",
      "Epoch 492/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1711 - accuracy: 0.6069 - val_loss: 0.2016 - val_accuracy: 0.5893\n",
      "Epoch 493/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1733 - accuracy: 0.5900 - val_loss: 0.1981 - val_accuracy: 0.5906\n",
      "Epoch 494/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1765 - accuracy: 0.6011 - val_loss: 0.2066 - val_accuracy: 0.5842\n",
      "Epoch 495/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1724 - accuracy: 0.5996 - val_loss: 0.1980 - val_accuracy: 0.5804\n",
      "Epoch 496/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1769 - accuracy: 0.5935 - val_loss: 0.2021 - val_accuracy: 0.5880\n",
      "Epoch 497/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1724 - accuracy: 0.5989 - val_loss: 0.1976 - val_accuracy: 0.5778\n",
      "Epoch 498/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1730 - accuracy: 0.6043 - val_loss: 0.2053 - val_accuracy: 0.5829\n",
      "Epoch 499/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1732 - accuracy: 0.6066 - val_loss: 0.2060 - val_accuracy: 0.5714\n",
      "Epoch 500/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1738 - accuracy: 0.6002 - val_loss: 0.1991 - val_accuracy: 0.5625\n",
      "Epoch 501/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1763 - accuracy: 0.6037 - val_loss: 0.2051 - val_accuracy: 0.5663\n",
      "Epoch 502/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1721 - accuracy: 0.6015 - val_loss: 0.1982 - val_accuracy: 0.5702\n",
      "Epoch 503/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1722 - accuracy: 0.5929 - val_loss: 0.2077 - val_accuracy: 0.5778\n",
      "Epoch 504/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1730 - accuracy: 0.6034 - val_loss: 0.1980 - val_accuracy: 0.5855\n",
      "Epoch 505/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1745 - accuracy: 0.5996 - val_loss: 0.2020 - val_accuracy: 0.5957\n",
      "Epoch 506/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1742 - accuracy: 0.5999 - val_loss: 0.2056 - val_accuracy: 0.5574\n",
      "Epoch 507/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1740 - accuracy: 0.5967 - val_loss: 0.2119 - val_accuracy: 0.5804\n",
      "Epoch 508/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1767 - accuracy: 0.6005 - val_loss: 0.2078 - val_accuracy: 0.5880\n",
      "Epoch 509/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1776 - accuracy: 0.5919 - val_loss: 0.2090 - val_accuracy: 0.5663\n",
      "Epoch 510/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1701 - accuracy: 0.6050 - val_loss: 0.2018 - val_accuracy: 0.5855\n",
      "Epoch 511/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1721 - accuracy: 0.6053 - val_loss: 0.1980 - val_accuracy: 0.5816\n",
      "Epoch 512/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1736 - accuracy: 0.5948 - val_loss: 0.1981 - val_accuracy: 0.5957\n",
      "Epoch 513/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1748 - accuracy: 0.6005 - val_loss: 0.1987 - val_accuracy: 0.5778\n",
      "Epoch 514/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1738 - accuracy: 0.5897 - val_loss: 0.2016 - val_accuracy: 0.5753\n",
      "Epoch 515/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1748 - accuracy: 0.5944 - val_loss: 0.2008 - val_accuracy: 0.5944\n",
      "Epoch 516/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1719 - accuracy: 0.5999 - val_loss: 0.2007 - val_accuracy: 0.5829\n",
      "Epoch 517/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1760 - accuracy: 0.5922 - val_loss: 0.1968 - val_accuracy: 0.5969\n",
      "Epoch 518/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1708 - accuracy: 0.6050 - val_loss: 0.2006 - val_accuracy: 0.5791\n",
      "Epoch 519/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1745 - accuracy: 0.6011 - val_loss: 0.2126 - val_accuracy: 0.5638\n",
      "Epoch 520/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1670 - accuracy: 0.6142 - val_loss: 0.1990 - val_accuracy: 0.5880\n",
      "Epoch 521/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1670 - accuracy: 0.6088 - val_loss: 0.2011 - val_accuracy: 0.5765\n",
      "Epoch 522/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1753 - accuracy: 0.6091 - val_loss: 0.2101 - val_accuracy: 0.5804\n",
      "Epoch 523/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1712 - accuracy: 0.6018 - val_loss: 0.2011 - val_accuracy: 0.5867\n",
      "Epoch 524/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1770 - accuracy: 0.6011 - val_loss: 0.2208 - val_accuracy: 0.5689\n",
      "Epoch 525/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1828 - accuracy: 0.5996 - val_loss: 0.2067 - val_accuracy: 0.5625\n",
      "Epoch 526/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1862 - accuracy: 0.5855 - val_loss: 0.2386 - val_accuracy: 0.5523\n",
      "Epoch 527/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1841 - accuracy: 0.5836 - val_loss: 0.2028 - val_accuracy: 0.5714\n",
      "Epoch 528/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1726 - accuracy: 0.6002 - val_loss: 0.2012 - val_accuracy: 0.5855\n",
      "Epoch 529/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1735 - accuracy: 0.5954 - val_loss: 0.1989 - val_accuracy: 0.5714\n",
      "Epoch 530/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1743 - accuracy: 0.5989 - val_loss: 0.2030 - val_accuracy: 0.5842\n",
      "Epoch 531/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1733 - accuracy: 0.6043 - val_loss: 0.2025 - val_accuracy: 0.5944\n",
      "Epoch 532/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1674 - accuracy: 0.6190 - val_loss: 0.2108 - val_accuracy: 0.5791\n",
      "Epoch 533/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1703 - accuracy: 0.6018 - val_loss: 0.1994 - val_accuracy: 0.5944\n",
      "Epoch 534/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1685 - accuracy: 0.6078 - val_loss: 0.2045 - val_accuracy: 0.5944\n",
      "Epoch 535/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1736 - accuracy: 0.5906 - val_loss: 0.1972 - val_accuracy: 0.5816\n",
      "Epoch 536/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1725 - accuracy: 0.5932 - val_loss: 0.2045 - val_accuracy: 0.5867\n",
      "Epoch 537/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1698 - accuracy: 0.6126 - val_loss: 0.2062 - val_accuracy: 0.5791\n",
      "Epoch 538/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1680 - accuracy: 0.6158 - val_loss: 0.2087 - val_accuracy: 0.5957\n",
      "Epoch 539/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1741 - accuracy: 0.5996 - val_loss: 0.2049 - val_accuracy: 0.5638\n",
      "Epoch 540/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1713 - accuracy: 0.6047 - val_loss: 0.1982 - val_accuracy: 0.5842\n",
      "Epoch 541/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1676 - accuracy: 0.6047 - val_loss: 0.1988 - val_accuracy: 0.5969\n",
      "Epoch 542/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1713 - accuracy: 0.6040 - val_loss: 0.2046 - val_accuracy: 0.5804\n",
      "Epoch 543/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1788 - accuracy: 0.5980 - val_loss: 0.1997 - val_accuracy: 0.5765\n",
      "Epoch 544/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1718 - accuracy: 0.6174 - val_loss: 0.1981 - val_accuracy: 0.5829\n",
      "Epoch 545/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1732 - accuracy: 0.6040 - val_loss: 0.1971 - val_accuracy: 0.5778\n",
      "Epoch 546/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1734 - accuracy: 0.5964 - val_loss: 0.2160 - val_accuracy: 0.5727\n",
      "Epoch 547/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1723 - accuracy: 0.6002 - val_loss: 0.1973 - val_accuracy: 0.5982\n",
      "Epoch 548/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1660 - accuracy: 0.6238 - val_loss: 0.1993 - val_accuracy: 0.5855\n",
      "Epoch 549/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1684 - accuracy: 0.6101 - val_loss: 0.1965 - val_accuracy: 0.6046\n",
      "Epoch 550/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1662 - accuracy: 0.6130 - val_loss: 0.1982 - val_accuracy: 0.6020\n",
      "Epoch 551/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1657 - accuracy: 0.6133 - val_loss: 0.1976 - val_accuracy: 0.5957\n",
      "Epoch 552/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1684 - accuracy: 0.6098 - val_loss: 0.2024 - val_accuracy: 0.5931\n",
      "Epoch 553/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1706 - accuracy: 0.6015 - val_loss: 0.2018 - val_accuracy: 0.5740\n",
      "Epoch 554/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1731 - accuracy: 0.6066 - val_loss: 0.1998 - val_accuracy: 0.5893\n",
      "Epoch 555/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1713 - accuracy: 0.6005 - val_loss: 0.2069 - val_accuracy: 0.5599\n",
      "Epoch 556/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1733 - accuracy: 0.5976 - val_loss: 0.2051 - val_accuracy: 0.5740\n",
      "Epoch 557/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1735 - accuracy: 0.6126 - val_loss: 0.2151 - val_accuracy: 0.5740\n",
      "Epoch 558/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1723 - accuracy: 0.6047 - val_loss: 0.1992 - val_accuracy: 0.6046\n",
      "Epoch 559/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1663 - accuracy: 0.6078 - val_loss: 0.1991 - val_accuracy: 0.5918\n",
      "Epoch 560/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1712 - accuracy: 0.5983 - val_loss: 0.2112 - val_accuracy: 0.5727\n",
      "Epoch 561/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1726 - accuracy: 0.5980 - val_loss: 0.1972 - val_accuracy: 0.5957\n",
      "Epoch 562/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1694 - accuracy: 0.6031 - val_loss: 0.2067 - val_accuracy: 0.5893\n",
      "Epoch 563/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1721 - accuracy: 0.5976 - val_loss: 0.2006 - val_accuracy: 0.5689\n",
      "Epoch 564/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1743 - accuracy: 0.5842 - val_loss: 0.2108 - val_accuracy: 0.5753\n",
      "Epoch 565/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1696 - accuracy: 0.6027 - val_loss: 0.1965 - val_accuracy: 0.5969\n",
      "Epoch 566/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1691 - accuracy: 0.6085 - val_loss: 0.2016 - val_accuracy: 0.5918\n",
      "Epoch 567/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1687 - accuracy: 0.6123 - val_loss: 0.1954 - val_accuracy: 0.5893\n",
      "Epoch 568/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1692 - accuracy: 0.6126 - val_loss: 0.2098 - val_accuracy: 0.5804\n",
      "Epoch 569/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1686 - accuracy: 0.6005 - val_loss: 0.2050 - val_accuracy: 0.5778\n",
      "Epoch 570/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1709 - accuracy: 0.6024 - val_loss: 0.2028 - val_accuracy: 0.5918\n",
      "Epoch 571/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1735 - accuracy: 0.5903 - val_loss: 0.2142 - val_accuracy: 0.5727\n",
      "Epoch 572/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1743 - accuracy: 0.5922 - val_loss: 0.2026 - val_accuracy: 0.5778\n",
      "Epoch 573/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1694 - accuracy: 0.6047 - val_loss: 0.2000 - val_accuracy: 0.5957\n",
      "Epoch 574/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1714 - accuracy: 0.6018 - val_loss: 0.2083 - val_accuracy: 0.5765\n",
      "Epoch 575/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1716 - accuracy: 0.6110 - val_loss: 0.1988 - val_accuracy: 0.5969\n",
      "Epoch 576/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1707 - accuracy: 0.6027 - val_loss: 0.1976 - val_accuracy: 0.6071\n",
      "Epoch 577/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1642 - accuracy: 0.6091 - val_loss: 0.1965 - val_accuracy: 0.5791\n",
      "Epoch 578/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1689 - accuracy: 0.6094 - val_loss: 0.1940 - val_accuracy: 0.5944\n",
      "Epoch 579/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1634 - accuracy: 0.6187 - val_loss: 0.2061 - val_accuracy: 0.5829\n",
      "Epoch 580/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1721 - accuracy: 0.6011 - val_loss: 0.2035 - val_accuracy: 0.5804\n",
      "Epoch 581/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1643 - accuracy: 0.6117 - val_loss: 0.1995 - val_accuracy: 0.5982\n",
      "Epoch 582/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1688 - accuracy: 0.6139 - val_loss: 0.2044 - val_accuracy: 0.5625\n",
      "Epoch 583/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1705 - accuracy: 0.5992 - val_loss: 0.1991 - val_accuracy: 0.5727\n",
      "Epoch 584/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1675 - accuracy: 0.6069 - val_loss: 0.2114 - val_accuracy: 0.5765\n",
      "Epoch 585/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1695 - accuracy: 0.6075 - val_loss: 0.1981 - val_accuracy: 0.5880\n",
      "Epoch 586/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1667 - accuracy: 0.6027 - val_loss: 0.1936 - val_accuracy: 0.5995\n",
      "Epoch 587/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1646 - accuracy: 0.6168 - val_loss: 0.2088 - val_accuracy: 0.5791\n",
      "Epoch 588/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1684 - accuracy: 0.6165 - val_loss: 0.1948 - val_accuracy: 0.5893\n",
      "Epoch 589/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1752 - accuracy: 0.6037 - val_loss: 0.1946 - val_accuracy: 0.5753\n",
      "Epoch 590/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1689 - accuracy: 0.6056 - val_loss: 0.2017 - val_accuracy: 0.5663\n",
      "Epoch 591/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1699 - accuracy: 0.6088 - val_loss: 0.2110 - val_accuracy: 0.5791\n",
      "Epoch 592/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1663 - accuracy: 0.6107 - val_loss: 0.2065 - val_accuracy: 0.5804\n",
      "Epoch 593/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1707 - accuracy: 0.5980 - val_loss: 0.2006 - val_accuracy: 0.5612\n",
      "Epoch 594/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1715 - accuracy: 0.5989 - val_loss: 0.2036 - val_accuracy: 0.5816\n",
      "Epoch 595/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1690 - accuracy: 0.6142 - val_loss: 0.1999 - val_accuracy: 0.5791\n",
      "Epoch 596/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1663 - accuracy: 0.6184 - val_loss: 0.2082 - val_accuracy: 0.5816\n",
      "Epoch 597/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1697 - accuracy: 0.6120 - val_loss: 0.2010 - val_accuracy: 0.5765\n",
      "Epoch 598/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1668 - accuracy: 0.6158 - val_loss: 0.2070 - val_accuracy: 0.5727\n",
      "Epoch 599/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1661 - accuracy: 0.6085 - val_loss: 0.2079 - val_accuracy: 0.5638\n",
      "Epoch 600/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1733 - accuracy: 0.5944 - val_loss: 0.2025 - val_accuracy: 0.5625\n",
      "Epoch 601/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1704 - accuracy: 0.6008 - val_loss: 0.2186 - val_accuracy: 0.5548\n",
      "Epoch 602/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1728 - accuracy: 0.5957 - val_loss: 0.2070 - val_accuracy: 0.5765\n",
      "Epoch 603/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1691 - accuracy: 0.6110 - val_loss: 0.2011 - val_accuracy: 0.5880\n",
      "Epoch 604/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1684 - accuracy: 0.6040 - val_loss: 0.1990 - val_accuracy: 0.5765\n",
      "Epoch 605/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1625 - accuracy: 0.6088 - val_loss: 0.1987 - val_accuracy: 0.5867\n",
      "Epoch 606/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1619 - accuracy: 0.6142 - val_loss: 0.2106 - val_accuracy: 0.5651\n",
      "Epoch 607/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1708 - accuracy: 0.6043 - val_loss: 0.1995 - val_accuracy: 0.5931\n",
      "Epoch 608/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1682 - accuracy: 0.6107 - val_loss: 0.2042 - val_accuracy: 0.5880\n",
      "Epoch 609/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1719 - accuracy: 0.5973 - val_loss: 0.2033 - val_accuracy: 0.6020\n",
      "Epoch 610/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1617 - accuracy: 0.6171 - val_loss: 0.2036 - val_accuracy: 0.5727\n",
      "Epoch 611/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1662 - accuracy: 0.6219 - val_loss: 0.2008 - val_accuracy: 0.5918\n",
      "Epoch 612/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1656 - accuracy: 0.6104 - val_loss: 0.1976 - val_accuracy: 0.5829\n",
      "Epoch 613/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1663 - accuracy: 0.6043 - val_loss: 0.2000 - val_accuracy: 0.5893\n",
      "Epoch 614/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1675 - accuracy: 0.6059 - val_loss: 0.1997 - val_accuracy: 0.5842\n",
      "Epoch 615/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1634 - accuracy: 0.6216 - val_loss: 0.1980 - val_accuracy: 0.5842\n",
      "Epoch 616/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1629 - accuracy: 0.6219 - val_loss: 0.2110 - val_accuracy: 0.5740\n",
      "Epoch 617/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1701 - accuracy: 0.6011 - val_loss: 0.2030 - val_accuracy: 0.5765\n",
      "Epoch 618/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1709 - accuracy: 0.6171 - val_loss: 0.2085 - val_accuracy: 0.5816\n",
      "Epoch 619/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1688 - accuracy: 0.6063 - val_loss: 0.2071 - val_accuracy: 0.5740\n",
      "Epoch 620/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1656 - accuracy: 0.6043 - val_loss: 0.2026 - val_accuracy: 0.5855\n",
      "Epoch 621/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1630 - accuracy: 0.6149 - val_loss: 0.1998 - val_accuracy: 0.5957\n",
      "Epoch 622/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1663 - accuracy: 0.6120 - val_loss: 0.2119 - val_accuracy: 0.5867\n",
      "Epoch 623/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1679 - accuracy: 0.6018 - val_loss: 0.2016 - val_accuracy: 0.5625\n",
      "Epoch 624/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1740 - accuracy: 0.5951 - val_loss: 0.1946 - val_accuracy: 0.5855\n",
      "Epoch 625/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1648 - accuracy: 0.6232 - val_loss: 0.1962 - val_accuracy: 0.5816\n",
      "Epoch 626/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1656 - accuracy: 0.6187 - val_loss: 0.2034 - val_accuracy: 0.5880\n",
      "Epoch 627/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1676 - accuracy: 0.6117 - val_loss: 0.2003 - val_accuracy: 0.5804\n",
      "Epoch 628/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1661 - accuracy: 0.6158 - val_loss: 0.2012 - val_accuracy: 0.5944\n",
      "Epoch 629/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1639 - accuracy: 0.6197 - val_loss: 0.1969 - val_accuracy: 0.5804\n",
      "Epoch 630/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1648 - accuracy: 0.6133 - val_loss: 0.2056 - val_accuracy: 0.5753\n",
      "Epoch 631/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1645 - accuracy: 0.6120 - val_loss: 0.2124 - val_accuracy: 0.5459\n",
      "Epoch 632/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1764 - accuracy: 0.6027 - val_loss: 0.1994 - val_accuracy: 0.5829\n",
      "Epoch 633/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1660 - accuracy: 0.6075 - val_loss: 0.2058 - val_accuracy: 0.5867\n",
      "Epoch 634/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1692 - accuracy: 0.6059 - val_loss: 0.1982 - val_accuracy: 0.5804\n",
      "Epoch 635/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1679 - accuracy: 0.6130 - val_loss: 0.2024 - val_accuracy: 0.5893\n",
      "Epoch 636/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1570 - accuracy: 0.6244 - val_loss: 0.2021 - val_accuracy: 0.5918\n",
      "Epoch 637/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1638 - accuracy: 0.6203 - val_loss: 0.2061 - val_accuracy: 0.5829\n",
      "Epoch 638/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1634 - accuracy: 0.6203 - val_loss: 0.1971 - val_accuracy: 0.5740\n",
      "Epoch 639/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1687 - accuracy: 0.6136 - val_loss: 0.2050 - val_accuracy: 0.5740\n",
      "Epoch 640/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1633 - accuracy: 0.6184 - val_loss: 0.2060 - val_accuracy: 0.5651\n",
      "Epoch 641/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1659 - accuracy: 0.6136 - val_loss: 0.2078 - val_accuracy: 0.5816\n",
      "Epoch 642/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1671 - accuracy: 0.6123 - val_loss: 0.2006 - val_accuracy: 0.5918\n",
      "Epoch 643/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1665 - accuracy: 0.6146 - val_loss: 0.2017 - val_accuracy: 0.5906\n",
      "Epoch 644/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1682 - accuracy: 0.6171 - val_loss: 0.1982 - val_accuracy: 0.6020\n",
      "Epoch 645/1000\n",
      "3134/3134 [==============================] - 0s 15us/step - loss: 0.1618 - accuracy: 0.6197 - val_loss: 0.2291 - val_accuracy: 0.5599\n",
      "Epoch 646/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1685 - accuracy: 0.6158 - val_loss: 0.2002 - val_accuracy: 0.5931\n",
      "Epoch 647/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1664 - accuracy: 0.6126 - val_loss: 0.2094 - val_accuracy: 0.5893\n",
      "Epoch 648/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1609 - accuracy: 0.6130 - val_loss: 0.2089 - val_accuracy: 0.5714\n",
      "Epoch 649/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1656 - accuracy: 0.6187 - val_loss: 0.2060 - val_accuracy: 0.5791\n",
      "Epoch 650/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1648 - accuracy: 0.6139 - val_loss: 0.2014 - val_accuracy: 0.5957\n",
      "Epoch 651/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1692 - accuracy: 0.6059 - val_loss: 0.2137 - val_accuracy: 0.5727\n",
      "Epoch 652/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1692 - accuracy: 0.5996 - val_loss: 0.2001 - val_accuracy: 0.5969\n",
      "Epoch 653/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1696 - accuracy: 0.6053 - val_loss: 0.2028 - val_accuracy: 0.6008\n",
      "Epoch 654/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1639 - accuracy: 0.6264 - val_loss: 0.1985 - val_accuracy: 0.5855\n",
      "Epoch 655/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1679 - accuracy: 0.5986 - val_loss: 0.2059 - val_accuracy: 0.5778\n",
      "Epoch 656/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1629 - accuracy: 0.6206 - val_loss: 0.1960 - val_accuracy: 0.5982\n",
      "Epoch 657/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1599 - accuracy: 0.6213 - val_loss: 0.2022 - val_accuracy: 0.5791\n",
      "Epoch 658/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1615 - accuracy: 0.6238 - val_loss: 0.1987 - val_accuracy: 0.5969\n",
      "Epoch 659/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1633 - accuracy: 0.6152 - val_loss: 0.1994 - val_accuracy: 0.5855\n",
      "Epoch 660/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1565 - accuracy: 0.6267 - val_loss: 0.2051 - val_accuracy: 0.5893\n",
      "Epoch 661/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1639 - accuracy: 0.6190 - val_loss: 0.2049 - val_accuracy: 0.5765\n",
      "Epoch 662/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1641 - accuracy: 0.6149 - val_loss: 0.2100 - val_accuracy: 0.5740\n",
      "Epoch 663/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1658 - accuracy: 0.6158 - val_loss: 0.1975 - val_accuracy: 0.5906\n",
      "Epoch 664/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1599 - accuracy: 0.6251 - val_loss: 0.2025 - val_accuracy: 0.5829\n",
      "Epoch 665/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1638 - accuracy: 0.6056 - val_loss: 0.2078 - val_accuracy: 0.5765\n",
      "Epoch 666/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1657 - accuracy: 0.6130 - val_loss: 0.2072 - val_accuracy: 0.5676\n",
      "Epoch 667/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1625 - accuracy: 0.6181 - val_loss: 0.1971 - val_accuracy: 0.5842\n",
      "Epoch 668/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1635 - accuracy: 0.6197 - val_loss: 0.1996 - val_accuracy: 0.5765\n",
      "Epoch 669/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1649 - accuracy: 0.6101 - val_loss: 0.2096 - val_accuracy: 0.5867\n",
      "Epoch 670/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1663 - accuracy: 0.6085 - val_loss: 0.2135 - val_accuracy: 0.5638\n",
      "Epoch 671/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1703 - accuracy: 0.6114 - val_loss: 0.2038 - val_accuracy: 0.5599\n",
      "Epoch 672/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1637 - accuracy: 0.6203 - val_loss: 0.2001 - val_accuracy: 0.5842\n",
      "Epoch 673/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1602 - accuracy: 0.6193 - val_loss: 0.2321 - val_accuracy: 0.5599\n",
      "Epoch 674/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1692 - accuracy: 0.6130 - val_loss: 0.2015 - val_accuracy: 0.5791\n",
      "Epoch 675/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1623 - accuracy: 0.6142 - val_loss: 0.2217 - val_accuracy: 0.5753\n",
      "Epoch 676/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1699 - accuracy: 0.6031 - val_loss: 0.2165 - val_accuracy: 0.5446\n",
      "Epoch 677/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1732 - accuracy: 0.5957 - val_loss: 0.2053 - val_accuracy: 0.5778\n",
      "Epoch 678/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1679 - accuracy: 0.6078 - val_loss: 0.2018 - val_accuracy: 0.5816\n",
      "Epoch 679/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1665 - accuracy: 0.6120 - val_loss: 0.2115 - val_accuracy: 0.5867\n",
      "Epoch 680/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1644 - accuracy: 0.6155 - val_loss: 0.2023 - val_accuracy: 0.5778\n",
      "Epoch 681/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1685 - accuracy: 0.6161 - val_loss: 0.2267 - val_accuracy: 0.5638\n",
      "Epoch 682/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1683 - accuracy: 0.6193 - val_loss: 0.1998 - val_accuracy: 0.6020\n",
      "Epoch 683/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1649 - accuracy: 0.6136 - val_loss: 0.2008 - val_accuracy: 0.5982\n",
      "Epoch 684/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1604 - accuracy: 0.6280 - val_loss: 0.2019 - val_accuracy: 0.5867\n",
      "Epoch 685/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1639 - accuracy: 0.6190 - val_loss: 0.2059 - val_accuracy: 0.5918\n",
      "Epoch 686/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1671 - accuracy: 0.6146 - val_loss: 0.1997 - val_accuracy: 0.5816\n",
      "Epoch 687/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1622 - accuracy: 0.6232 - val_loss: 0.2025 - val_accuracy: 0.5918\n",
      "Epoch 688/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1668 - accuracy: 0.6177 - val_loss: 0.2032 - val_accuracy: 0.5855\n",
      "Epoch 689/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1644 - accuracy: 0.6040 - val_loss: 0.2231 - val_accuracy: 0.5727\n",
      "Epoch 690/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1667 - accuracy: 0.6047 - val_loss: 0.2032 - val_accuracy: 0.5727\n",
      "Epoch 691/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1648 - accuracy: 0.6107 - val_loss: 0.2462 - val_accuracy: 0.5332\n",
      "Epoch 692/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1801 - accuracy: 0.5820 - val_loss: 0.2062 - val_accuracy: 0.5804\n",
      "Epoch 693/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1653 - accuracy: 0.6241 - val_loss: 0.1968 - val_accuracy: 0.5918\n",
      "Epoch 694/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1624 - accuracy: 0.6181 - val_loss: 0.2048 - val_accuracy: 0.5842\n",
      "Epoch 695/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1661 - accuracy: 0.6130 - val_loss: 0.2077 - val_accuracy: 0.5906\n",
      "Epoch 696/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1604 - accuracy: 0.6174 - val_loss: 0.2028 - val_accuracy: 0.5829\n",
      "Epoch 697/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1581 - accuracy: 0.6289 - val_loss: 0.2099 - val_accuracy: 0.5816\n",
      "Epoch 698/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1661 - accuracy: 0.6114 - val_loss: 0.2000 - val_accuracy: 0.5791\n",
      "Epoch 699/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1583 - accuracy: 0.6235 - val_loss: 0.2078 - val_accuracy: 0.5702\n",
      "Epoch 700/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1639 - accuracy: 0.6133 - val_loss: 0.1991 - val_accuracy: 0.6046\n",
      "Epoch 701/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1628 - accuracy: 0.6136 - val_loss: 0.1987 - val_accuracy: 0.5842\n",
      "Epoch 702/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1560 - accuracy: 0.6318 - val_loss: 0.2080 - val_accuracy: 0.5893\n",
      "Epoch 703/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1616 - accuracy: 0.6133 - val_loss: 0.2052 - val_accuracy: 0.5714\n",
      "Epoch 704/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1683 - accuracy: 0.6174 - val_loss: 0.2115 - val_accuracy: 0.5957\n",
      "Epoch 705/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1637 - accuracy: 0.6193 - val_loss: 0.1989 - val_accuracy: 0.5855\n",
      "Epoch 706/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1653 - accuracy: 0.6107 - val_loss: 0.2073 - val_accuracy: 0.5918\n",
      "Epoch 707/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1617 - accuracy: 0.6267 - val_loss: 0.2024 - val_accuracy: 0.5740\n",
      "Epoch 708/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1653 - accuracy: 0.6123 - val_loss: 0.2101 - val_accuracy: 0.5829\n",
      "Epoch 709/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1632 - accuracy: 0.6244 - val_loss: 0.1984 - val_accuracy: 0.5765\n",
      "Epoch 710/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1588 - accuracy: 0.6254 - val_loss: 0.2045 - val_accuracy: 0.5880\n",
      "Epoch 711/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1595 - accuracy: 0.6318 - val_loss: 0.2044 - val_accuracy: 0.5842\n",
      "Epoch 712/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1606 - accuracy: 0.6171 - val_loss: 0.2056 - val_accuracy: 0.5804\n",
      "Epoch 713/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1564 - accuracy: 0.6318 - val_loss: 0.2143 - val_accuracy: 0.5778\n",
      "Epoch 714/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1663 - accuracy: 0.6190 - val_loss: 0.2018 - val_accuracy: 0.5893\n",
      "Epoch 715/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1592 - accuracy: 0.6168 - val_loss: 0.2018 - val_accuracy: 0.5893\n",
      "Epoch 716/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1564 - accuracy: 0.6305 - val_loss: 0.1959 - val_accuracy: 0.5931\n",
      "Epoch 717/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1576 - accuracy: 0.6295 - val_loss: 0.2002 - val_accuracy: 0.5906\n",
      "Epoch 718/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1561 - accuracy: 0.6385 - val_loss: 0.2033 - val_accuracy: 0.5753\n",
      "Epoch 719/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1553 - accuracy: 0.6219 - val_loss: 0.1977 - val_accuracy: 0.5969\n",
      "Epoch 720/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1576 - accuracy: 0.6289 - val_loss: 0.1991 - val_accuracy: 0.5855\n",
      "Epoch 721/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1621 - accuracy: 0.6206 - val_loss: 0.1960 - val_accuracy: 0.5893\n",
      "Epoch 722/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1571 - accuracy: 0.6327 - val_loss: 0.2002 - val_accuracy: 0.5702\n",
      "Epoch 723/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1577 - accuracy: 0.6369 - val_loss: 0.2001 - val_accuracy: 0.5791\n",
      "Epoch 724/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1574 - accuracy: 0.6251 - val_loss: 0.1964 - val_accuracy: 0.6020\n",
      "Epoch 725/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1615 - accuracy: 0.6130 - val_loss: 0.2049 - val_accuracy: 0.5765\n",
      "Epoch 726/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1598 - accuracy: 0.6318 - val_loss: 0.2007 - val_accuracy: 0.5740\n",
      "Epoch 727/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1571 - accuracy: 0.6257 - val_loss: 0.2166 - val_accuracy: 0.5676\n",
      "Epoch 728/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1624 - accuracy: 0.6187 - val_loss: 0.1982 - val_accuracy: 0.5893\n",
      "Epoch 729/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1649 - accuracy: 0.6280 - val_loss: 0.2126 - val_accuracy: 0.5829\n",
      "Epoch 730/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1654 - accuracy: 0.6216 - val_loss: 0.2003 - val_accuracy: 0.5816\n",
      "Epoch 731/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1579 - accuracy: 0.6216 - val_loss: 0.1976 - val_accuracy: 0.5893\n",
      "Epoch 732/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1613 - accuracy: 0.6216 - val_loss: 0.2034 - val_accuracy: 0.5918\n",
      "Epoch 733/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1617 - accuracy: 0.6213 - val_loss: 0.2003 - val_accuracy: 0.5842\n",
      "Epoch 734/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1618 - accuracy: 0.6078 - val_loss: 0.2166 - val_accuracy: 0.5740\n",
      "Epoch 735/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1641 - accuracy: 0.6228 - val_loss: 0.1982 - val_accuracy: 0.5982\n",
      "Epoch 736/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1608 - accuracy: 0.6270 - val_loss: 0.1971 - val_accuracy: 0.5778\n",
      "Epoch 737/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1586 - accuracy: 0.6216 - val_loss: 0.2050 - val_accuracy: 0.5778\n",
      "Epoch 738/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1565 - accuracy: 0.6324 - val_loss: 0.2265 - val_accuracy: 0.5740\n",
      "Epoch 739/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1646 - accuracy: 0.6235 - val_loss: 0.1960 - val_accuracy: 0.6148\n",
      "Epoch 740/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1581 - accuracy: 0.6347 - val_loss: 0.1997 - val_accuracy: 0.5804\n",
      "Epoch 741/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1540 - accuracy: 0.6299 - val_loss: 0.2072 - val_accuracy: 0.5804\n",
      "Epoch 742/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1585 - accuracy: 0.6219 - val_loss: 0.2103 - val_accuracy: 0.5969\n",
      "Epoch 743/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1616 - accuracy: 0.6110 - val_loss: 0.2044 - val_accuracy: 0.5804\n",
      "Epoch 744/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1584 - accuracy: 0.6321 - val_loss: 0.2153 - val_accuracy: 0.5791\n",
      "Epoch 745/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1604 - accuracy: 0.6244 - val_loss: 0.2012 - val_accuracy: 0.5918\n",
      "Epoch 746/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1576 - accuracy: 0.6324 - val_loss: 0.2044 - val_accuracy: 0.5842\n",
      "Epoch 747/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1654 - accuracy: 0.6171 - val_loss: 0.2087 - val_accuracy: 0.5714\n",
      "Epoch 748/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1579 - accuracy: 0.6235 - val_loss: 0.2016 - val_accuracy: 0.5778\n",
      "Epoch 749/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1602 - accuracy: 0.6190 - val_loss: 0.2288 - val_accuracy: 0.5612\n",
      "Epoch 750/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1643 - accuracy: 0.6200 - val_loss: 0.1991 - val_accuracy: 0.5855\n",
      "Epoch 751/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1661 - accuracy: 0.6104 - val_loss: 0.2078 - val_accuracy: 0.5753\n",
      "Epoch 752/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1577 - accuracy: 0.6235 - val_loss: 0.2096 - val_accuracy: 0.5867\n",
      "Epoch 753/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1574 - accuracy: 0.6334 - val_loss: 0.2016 - val_accuracy: 0.5855\n",
      "Epoch 754/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1618 - accuracy: 0.6251 - val_loss: 0.2302 - val_accuracy: 0.5612\n",
      "Epoch 755/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1678 - accuracy: 0.6174 - val_loss: 0.2035 - val_accuracy: 0.5816\n",
      "Epoch 756/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1598 - accuracy: 0.6203 - val_loss: 0.2035 - val_accuracy: 0.5842\n",
      "Epoch 757/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1561 - accuracy: 0.6362 - val_loss: 0.2078 - val_accuracy: 0.5753\n",
      "Epoch 758/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1583 - accuracy: 0.6283 - val_loss: 0.2177 - val_accuracy: 0.5765\n",
      "Epoch 759/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1597 - accuracy: 0.6273 - val_loss: 0.2017 - val_accuracy: 0.5880\n",
      "Epoch 760/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1578 - accuracy: 0.6347 - val_loss: 0.2031 - val_accuracy: 0.5829\n",
      "Epoch 761/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1599 - accuracy: 0.6264 - val_loss: 0.2117 - val_accuracy: 0.5855\n",
      "Epoch 762/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1693 - accuracy: 0.6031 - val_loss: 0.2003 - val_accuracy: 0.5867\n",
      "Epoch 763/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1579 - accuracy: 0.6257 - val_loss: 0.2030 - val_accuracy: 0.5765\n",
      "Epoch 764/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1610 - accuracy: 0.6244 - val_loss: 0.2238 - val_accuracy: 0.5702\n",
      "Epoch 765/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1655 - accuracy: 0.6069 - val_loss: 0.1996 - val_accuracy: 0.5842\n",
      "Epoch 766/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1616 - accuracy: 0.6382 - val_loss: 0.2060 - val_accuracy: 0.5778\n",
      "Epoch 767/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1576 - accuracy: 0.6283 - val_loss: 0.2305 - val_accuracy: 0.5625\n",
      "Epoch 768/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1629 - accuracy: 0.6184 - val_loss: 0.2055 - val_accuracy: 0.5599\n",
      "Epoch 769/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1604 - accuracy: 0.6155 - val_loss: 0.2039 - val_accuracy: 0.5663\n",
      "Epoch 770/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1566 - accuracy: 0.6235 - val_loss: 0.2018 - val_accuracy: 0.5816\n",
      "Epoch 771/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1593 - accuracy: 0.6238 - val_loss: 0.2053 - val_accuracy: 0.5765\n",
      "Epoch 772/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1593 - accuracy: 0.6209 - val_loss: 0.2039 - val_accuracy: 0.5906\n",
      "Epoch 773/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1580 - accuracy: 0.6244 - val_loss: 0.2034 - val_accuracy: 0.5880\n",
      "Epoch 774/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1537 - accuracy: 0.6385 - val_loss: 0.2036 - val_accuracy: 0.5804\n",
      "Epoch 775/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1550 - accuracy: 0.6302 - val_loss: 0.1997 - val_accuracy: 0.5957\n",
      "Epoch 776/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1583 - accuracy: 0.6254 - val_loss: 0.2170 - val_accuracy: 0.5702\n",
      "Epoch 777/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1637 - accuracy: 0.6270 - val_loss: 0.2054 - val_accuracy: 0.5727\n",
      "Epoch 778/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1633 - accuracy: 0.6222 - val_loss: 0.2266 - val_accuracy: 0.5740\n",
      "Epoch 779/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1647 - accuracy: 0.6184 - val_loss: 0.2003 - val_accuracy: 0.5804\n",
      "Epoch 780/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1631 - accuracy: 0.6228 - val_loss: 0.2023 - val_accuracy: 0.5765\n",
      "Epoch 781/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1539 - accuracy: 0.6308 - val_loss: 0.2005 - val_accuracy: 0.5995\n",
      "Epoch 782/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1574 - accuracy: 0.6286 - val_loss: 0.2048 - val_accuracy: 0.5727\n",
      "Epoch 783/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1562 - accuracy: 0.6276 - val_loss: 0.2147 - val_accuracy: 0.5727\n",
      "Epoch 784/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1653 - accuracy: 0.6292 - val_loss: 0.2079 - val_accuracy: 0.5893\n",
      "Epoch 785/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1586 - accuracy: 0.6327 - val_loss: 0.2093 - val_accuracy: 0.5944\n",
      "Epoch 786/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1561 - accuracy: 0.6286 - val_loss: 0.2110 - val_accuracy: 0.5663\n",
      "Epoch 787/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1603 - accuracy: 0.6248 - val_loss: 0.2085 - val_accuracy: 0.5855\n",
      "Epoch 788/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1596 - accuracy: 0.6254 - val_loss: 0.2028 - val_accuracy: 0.5829\n",
      "Epoch 789/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1579 - accuracy: 0.6343 - val_loss: 0.1996 - val_accuracy: 0.5893\n",
      "Epoch 790/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1572 - accuracy: 0.6273 - val_loss: 0.2123 - val_accuracy: 0.5740\n",
      "Epoch 791/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1668 - accuracy: 0.6053 - val_loss: 0.2027 - val_accuracy: 0.5842\n",
      "Epoch 792/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1595 - accuracy: 0.6238 - val_loss: 0.2023 - val_accuracy: 0.5676\n",
      "Epoch 793/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1568 - accuracy: 0.6267 - val_loss: 0.2045 - val_accuracy: 0.6020\n",
      "Epoch 794/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1522 - accuracy: 0.6375 - val_loss: 0.2084 - val_accuracy: 0.5880\n",
      "Epoch 795/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1539 - accuracy: 0.6372 - val_loss: 0.2003 - val_accuracy: 0.5880\n",
      "Epoch 796/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1595 - accuracy: 0.6359 - val_loss: 0.2156 - val_accuracy: 0.5842\n",
      "Epoch 797/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1635 - accuracy: 0.6216 - val_loss: 0.2087 - val_accuracy: 0.5612\n",
      "Epoch 798/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1586 - accuracy: 0.6254 - val_loss: 0.2096 - val_accuracy: 0.5829\n",
      "Epoch 799/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1573 - accuracy: 0.6280 - val_loss: 0.2007 - val_accuracy: 0.6033\n",
      "Epoch 800/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1549 - accuracy: 0.6356 - val_loss: 0.2062 - val_accuracy: 0.5816\n",
      "Epoch 801/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1588 - accuracy: 0.6260 - val_loss: 0.2082 - val_accuracy: 0.5765\n",
      "Epoch 802/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1584 - accuracy: 0.6241 - val_loss: 0.1976 - val_accuracy: 0.5842\n",
      "Epoch 803/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1532 - accuracy: 0.6337 - val_loss: 0.2025 - val_accuracy: 0.5918\n",
      "Epoch 804/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1551 - accuracy: 0.6327 - val_loss: 0.2069 - val_accuracy: 0.5727\n",
      "Epoch 805/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1608 - accuracy: 0.6235 - val_loss: 0.1988 - val_accuracy: 0.5893\n",
      "Epoch 806/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1568 - accuracy: 0.6289 - val_loss: 0.2015 - val_accuracy: 0.5918\n",
      "Epoch 807/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1551 - accuracy: 0.6302 - val_loss: 0.2015 - val_accuracy: 0.5778\n",
      "Epoch 808/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1593 - accuracy: 0.6149 - val_loss: 0.1999 - val_accuracy: 0.5880\n",
      "Epoch 809/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1586 - accuracy: 0.6337 - val_loss: 0.1995 - val_accuracy: 0.5842\n",
      "Epoch 810/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1505 - accuracy: 0.6401 - val_loss: 0.2053 - val_accuracy: 0.5842\n",
      "Epoch 811/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1553 - accuracy: 0.6308 - val_loss: 0.2119 - val_accuracy: 0.5778\n",
      "Epoch 812/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1534 - accuracy: 0.6442 - val_loss: 0.1993 - val_accuracy: 0.5906\n",
      "Epoch 813/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1591 - accuracy: 0.6321 - val_loss: 0.2136 - val_accuracy: 0.5829\n",
      "Epoch 814/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1587 - accuracy: 0.6216 - val_loss: 0.2057 - val_accuracy: 0.5842\n",
      "Epoch 815/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1582 - accuracy: 0.6429 - val_loss: 0.2131 - val_accuracy: 0.5778\n",
      "Epoch 816/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1591 - accuracy: 0.6315 - val_loss: 0.2080 - val_accuracy: 0.5842\n",
      "Epoch 817/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1619 - accuracy: 0.6232 - val_loss: 0.2110 - val_accuracy: 0.5804\n",
      "Epoch 818/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1564 - accuracy: 0.6283 - val_loss: 0.2072 - val_accuracy: 0.5931\n",
      "Epoch 819/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1573 - accuracy: 0.6299 - val_loss: 0.2025 - val_accuracy: 0.5804\n",
      "Epoch 820/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1578 - accuracy: 0.6359 - val_loss: 0.2093 - val_accuracy: 0.5829\n",
      "Epoch 821/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1570 - accuracy: 0.6340 - val_loss: 0.2087 - val_accuracy: 0.5638\n",
      "Epoch 822/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1606 - accuracy: 0.6251 - val_loss: 0.2062 - val_accuracy: 0.5778\n",
      "Epoch 823/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1496 - accuracy: 0.6375 - val_loss: 0.2049 - val_accuracy: 0.5867\n",
      "Epoch 824/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1560 - accuracy: 0.6308 - val_loss: 0.2080 - val_accuracy: 0.5829\n",
      "Epoch 825/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1537 - accuracy: 0.6305 - val_loss: 0.2017 - val_accuracy: 0.5893\n",
      "Epoch 826/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1551 - accuracy: 0.6321 - val_loss: 0.2204 - val_accuracy: 0.5816\n",
      "Epoch 827/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1540 - accuracy: 0.6295 - val_loss: 0.2055 - val_accuracy: 0.5702\n",
      "Epoch 828/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1586 - accuracy: 0.6248 - val_loss: 0.2049 - val_accuracy: 0.5893\n",
      "Epoch 829/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1535 - accuracy: 0.6340 - val_loss: 0.2008 - val_accuracy: 0.5931\n",
      "Epoch 830/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1539 - accuracy: 0.6264 - val_loss: 0.2093 - val_accuracy: 0.5740\n",
      "Epoch 831/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1594 - accuracy: 0.6254 - val_loss: 0.2022 - val_accuracy: 0.5918\n",
      "Epoch 832/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1556 - accuracy: 0.6394 - val_loss: 0.1981 - val_accuracy: 0.5918\n",
      "Epoch 833/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1561 - accuracy: 0.6299 - val_loss: 0.2049 - val_accuracy: 0.5842\n",
      "Epoch 834/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1512 - accuracy: 0.6362 - val_loss: 0.2059 - val_accuracy: 0.5778\n",
      "Epoch 835/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1532 - accuracy: 0.6465 - val_loss: 0.2321 - val_accuracy: 0.5778\n",
      "Epoch 836/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1658 - accuracy: 0.6206 - val_loss: 0.2035 - val_accuracy: 0.5778\n",
      "Epoch 837/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1560 - accuracy: 0.6276 - val_loss: 0.2029 - val_accuracy: 0.5816\n",
      "Epoch 838/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1569 - accuracy: 0.6267 - val_loss: 0.2112 - val_accuracy: 0.5816\n",
      "Epoch 839/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1551 - accuracy: 0.6436 - val_loss: 0.1997 - val_accuracy: 0.5995\n",
      "Epoch 840/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1499 - accuracy: 0.6439 - val_loss: 0.2064 - val_accuracy: 0.5880\n",
      "Epoch 841/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1498 - accuracy: 0.6426 - val_loss: 0.2022 - val_accuracy: 0.5944\n",
      "Epoch 842/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1548 - accuracy: 0.6289 - val_loss: 0.1997 - val_accuracy: 0.5880\n",
      "Epoch 843/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1554 - accuracy: 0.6404 - val_loss: 0.2128 - val_accuracy: 0.5778\n",
      "Epoch 844/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1496 - accuracy: 0.6356 - val_loss: 0.2015 - val_accuracy: 0.5867\n",
      "Epoch 845/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1504 - accuracy: 0.6487 - val_loss: 0.1975 - val_accuracy: 0.6059\n",
      "Epoch 846/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1525 - accuracy: 0.6343 - val_loss: 0.2074 - val_accuracy: 0.5804\n",
      "Epoch 847/1000\n",
      "3134/3134 [==============================] - 0s 16us/step - loss: 0.1521 - accuracy: 0.6366 - val_loss: 0.2174 - val_accuracy: 0.5740\n",
      "Epoch 848/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1539 - accuracy: 0.6264 - val_loss: 0.2055 - val_accuracy: 0.5867\n",
      "Epoch 849/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1548 - accuracy: 0.6401 - val_loss: 0.2067 - val_accuracy: 0.5804\n",
      "Epoch 850/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1577 - accuracy: 0.6299 - val_loss: 0.2055 - val_accuracy: 0.5842\n",
      "Epoch 851/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1515 - accuracy: 0.6308 - val_loss: 0.2100 - val_accuracy: 0.5676\n",
      "Epoch 852/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1490 - accuracy: 0.6401 - val_loss: 0.2130 - val_accuracy: 0.5816\n",
      "Epoch 853/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1493 - accuracy: 0.6500 - val_loss: 0.2089 - val_accuracy: 0.5855\n",
      "Epoch 854/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1533 - accuracy: 0.6321 - val_loss: 0.1996 - val_accuracy: 0.5893\n",
      "Epoch 855/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1558 - accuracy: 0.6248 - val_loss: 0.2060 - val_accuracy: 0.5842\n",
      "Epoch 856/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1518 - accuracy: 0.6433 - val_loss: 0.2027 - val_accuracy: 0.5982\n",
      "Epoch 857/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1546 - accuracy: 0.6276 - val_loss: 0.1976 - val_accuracy: 0.5906\n",
      "Epoch 858/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1566 - accuracy: 0.6257 - val_loss: 0.1986 - val_accuracy: 0.5957\n",
      "Epoch 859/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1508 - accuracy: 0.6394 - val_loss: 0.2033 - val_accuracy: 0.5855\n",
      "Epoch 860/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1555 - accuracy: 0.6337 - val_loss: 0.2025 - val_accuracy: 0.5931\n",
      "Epoch 861/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1545 - accuracy: 0.6394 - val_loss: 0.2019 - val_accuracy: 0.5804\n",
      "Epoch 862/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1626 - accuracy: 0.6187 - val_loss: 0.2099 - val_accuracy: 0.5816\n",
      "Epoch 863/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1604 - accuracy: 0.6292 - val_loss: 0.2027 - val_accuracy: 0.5918\n",
      "Epoch 864/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1549 - accuracy: 0.6315 - val_loss: 0.1972 - val_accuracy: 0.5829\n",
      "Epoch 865/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1480 - accuracy: 0.6391 - val_loss: 0.2017 - val_accuracy: 0.5982\n",
      "Epoch 866/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1522 - accuracy: 0.6321 - val_loss: 0.2106 - val_accuracy: 0.5816\n",
      "Epoch 867/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1556 - accuracy: 0.6334 - val_loss: 0.2087 - val_accuracy: 0.5727\n",
      "Epoch 868/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1527 - accuracy: 0.6353 - val_loss: 0.1987 - val_accuracy: 0.5906\n",
      "Epoch 869/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1541 - accuracy: 0.6378 - val_loss: 0.2178 - val_accuracy: 0.5740\n",
      "Epoch 870/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1570 - accuracy: 0.6353 - val_loss: 0.2069 - val_accuracy: 0.5906\n",
      "Epoch 871/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1611 - accuracy: 0.6228 - val_loss: 0.2114 - val_accuracy: 0.5689\n",
      "Epoch 872/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1566 - accuracy: 0.6289 - val_loss: 0.2054 - val_accuracy: 0.5740\n",
      "Epoch 873/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1578 - accuracy: 0.6334 - val_loss: 0.2168 - val_accuracy: 0.5804\n",
      "Epoch 874/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1607 - accuracy: 0.6228 - val_loss: 0.2068 - val_accuracy: 0.5727\n",
      "Epoch 875/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1526 - accuracy: 0.6452 - val_loss: 0.2115 - val_accuracy: 0.5753\n",
      "Epoch 876/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1500 - accuracy: 0.6366 - val_loss: 0.2074 - val_accuracy: 0.5740\n",
      "Epoch 877/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1538 - accuracy: 0.6350 - val_loss: 0.2089 - val_accuracy: 0.5702\n",
      "Epoch 878/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1507 - accuracy: 0.6382 - val_loss: 0.2030 - val_accuracy: 0.5880\n",
      "Epoch 879/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1500 - accuracy: 0.6382 - val_loss: 0.2017 - val_accuracy: 0.5880\n",
      "Epoch 880/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1480 - accuracy: 0.6414 - val_loss: 0.1979 - val_accuracy: 0.5829\n",
      "Epoch 881/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1593 - accuracy: 0.6228 - val_loss: 0.2083 - val_accuracy: 0.5740\n",
      "Epoch 882/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1574 - accuracy: 0.6251 - val_loss: 0.1999 - val_accuracy: 0.5804\n",
      "Epoch 883/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1537 - accuracy: 0.6305 - val_loss: 0.2023 - val_accuracy: 0.5765\n",
      "Epoch 884/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1581 - accuracy: 0.6315 - val_loss: 0.2017 - val_accuracy: 0.5765\n",
      "Epoch 885/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1519 - accuracy: 0.6391 - val_loss: 0.2029 - val_accuracy: 0.5753\n",
      "Epoch 886/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1551 - accuracy: 0.6331 - val_loss: 0.1978 - val_accuracy: 0.5918\n",
      "Epoch 887/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1587 - accuracy: 0.6324 - val_loss: 0.2139 - val_accuracy: 0.5702\n",
      "Epoch 888/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1609 - accuracy: 0.6213 - val_loss: 0.2061 - val_accuracy: 0.5740\n",
      "Epoch 889/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1569 - accuracy: 0.6356 - val_loss: 0.2034 - val_accuracy: 0.5804\n",
      "Epoch 890/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1532 - accuracy: 0.6519 - val_loss: 0.2008 - val_accuracy: 0.5893\n",
      "Epoch 891/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1549 - accuracy: 0.6133 - val_loss: 0.2094 - val_accuracy: 0.5765\n",
      "Epoch 892/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1532 - accuracy: 0.6311 - val_loss: 0.1969 - val_accuracy: 0.5893\n",
      "Epoch 893/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1504 - accuracy: 0.6394 - val_loss: 0.2114 - val_accuracy: 0.5663\n",
      "Epoch 894/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1495 - accuracy: 0.6410 - val_loss: 0.2024 - val_accuracy: 0.5880\n",
      "Epoch 895/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1538 - accuracy: 0.6347 - val_loss: 0.2112 - val_accuracy: 0.5740\n",
      "Epoch 896/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1499 - accuracy: 0.6366 - val_loss: 0.2049 - val_accuracy: 0.5791\n",
      "Epoch 897/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1549 - accuracy: 0.6225 - val_loss: 0.2051 - val_accuracy: 0.5944\n",
      "Epoch 898/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1459 - accuracy: 0.6487 - val_loss: 0.2008 - val_accuracy: 0.5918\n",
      "Epoch 899/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1499 - accuracy: 0.6503 - val_loss: 0.2012 - val_accuracy: 0.5880\n",
      "Epoch 900/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1537 - accuracy: 0.6436 - val_loss: 0.1979 - val_accuracy: 0.6033\n",
      "Epoch 901/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1516 - accuracy: 0.6359 - val_loss: 0.2047 - val_accuracy: 0.6059\n",
      "Epoch 902/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1466 - accuracy: 0.6528 - val_loss: 0.2072 - val_accuracy: 0.5829\n",
      "Epoch 903/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1503 - accuracy: 0.6429 - val_loss: 0.1991 - val_accuracy: 0.5906\n",
      "Epoch 904/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1470 - accuracy: 0.6506 - val_loss: 0.2085 - val_accuracy: 0.5906\n",
      "Epoch 905/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1471 - accuracy: 0.6570 - val_loss: 0.2128 - val_accuracy: 0.5906\n",
      "Epoch 906/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1575 - accuracy: 0.6362 - val_loss: 0.2082 - val_accuracy: 0.5689\n",
      "Epoch 907/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1648 - accuracy: 0.6165 - val_loss: 0.2131 - val_accuracy: 0.5880\n",
      "Epoch 908/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1543 - accuracy: 0.6359 - val_loss: 0.2085 - val_accuracy: 0.5791\n",
      "Epoch 909/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1530 - accuracy: 0.6337 - val_loss: 0.2025 - val_accuracy: 0.5867\n",
      "Epoch 910/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1531 - accuracy: 0.6404 - val_loss: 0.2040 - val_accuracy: 0.5893\n",
      "Epoch 911/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1481 - accuracy: 0.6481 - val_loss: 0.2126 - val_accuracy: 0.5727\n",
      "Epoch 912/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1514 - accuracy: 0.6455 - val_loss: 0.2027 - val_accuracy: 0.5906\n",
      "Epoch 913/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1528 - accuracy: 0.6414 - val_loss: 0.1989 - val_accuracy: 0.6046\n",
      "Epoch 914/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1531 - accuracy: 0.6433 - val_loss: 0.2121 - val_accuracy: 0.5778\n",
      "Epoch 915/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1450 - accuracy: 0.6503 - val_loss: 0.1977 - val_accuracy: 0.5969\n",
      "Epoch 916/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1544 - accuracy: 0.6420 - val_loss: 0.2137 - val_accuracy: 0.5804\n",
      "Epoch 917/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1479 - accuracy: 0.6429 - val_loss: 0.1979 - val_accuracy: 0.5867\n",
      "Epoch 918/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1493 - accuracy: 0.6378 - val_loss: 0.1975 - val_accuracy: 0.5995\n",
      "Epoch 919/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1510 - accuracy: 0.6449 - val_loss: 0.2072 - val_accuracy: 0.5740\n",
      "Epoch 920/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1516 - accuracy: 0.6388 - val_loss: 0.2066 - val_accuracy: 0.5753\n",
      "Epoch 921/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1495 - accuracy: 0.6544 - val_loss: 0.2198 - val_accuracy: 0.5599\n",
      "Epoch 922/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1555 - accuracy: 0.6187 - val_loss: 0.1996 - val_accuracy: 0.5855\n",
      "Epoch 923/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1491 - accuracy: 0.6372 - val_loss: 0.2017 - val_accuracy: 0.5867\n",
      "Epoch 924/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1541 - accuracy: 0.6382 - val_loss: 0.1960 - val_accuracy: 0.5995\n",
      "Epoch 925/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1518 - accuracy: 0.6452 - val_loss: 0.1987 - val_accuracy: 0.5957\n",
      "Epoch 926/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1467 - accuracy: 0.6570 - val_loss: 0.2013 - val_accuracy: 0.5867\n",
      "Epoch 927/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1529 - accuracy: 0.6420 - val_loss: 0.2003 - val_accuracy: 0.5969\n",
      "Epoch 928/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1500 - accuracy: 0.6452 - val_loss: 0.1988 - val_accuracy: 0.5816\n",
      "Epoch 929/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1497 - accuracy: 0.6404 - val_loss: 0.1981 - val_accuracy: 0.5918\n",
      "Epoch 930/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1502 - accuracy: 0.6481 - val_loss: 0.2244 - val_accuracy: 0.5651\n",
      "Epoch 931/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1568 - accuracy: 0.6276 - val_loss: 0.2045 - val_accuracy: 0.5906\n",
      "Epoch 932/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1525 - accuracy: 0.6423 - val_loss: 0.2145 - val_accuracy: 0.5804\n",
      "Epoch 933/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1540 - accuracy: 0.6455 - val_loss: 0.2091 - val_accuracy: 0.5829\n",
      "Epoch 934/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1557 - accuracy: 0.6337 - val_loss: 0.2110 - val_accuracy: 0.5855\n",
      "Epoch 935/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1527 - accuracy: 0.6362 - val_loss: 0.2100 - val_accuracy: 0.5625\n",
      "Epoch 936/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1566 - accuracy: 0.6343 - val_loss: 0.2109 - val_accuracy: 0.5829\n",
      "Epoch 937/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1503 - accuracy: 0.6439 - val_loss: 0.2034 - val_accuracy: 0.5804\n",
      "Epoch 938/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1481 - accuracy: 0.6465 - val_loss: 0.2007 - val_accuracy: 0.5893\n",
      "Epoch 939/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1506 - accuracy: 0.6458 - val_loss: 0.1992 - val_accuracy: 0.5778\n",
      "Epoch 940/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1531 - accuracy: 0.6388 - val_loss: 0.1984 - val_accuracy: 0.5829\n",
      "Epoch 941/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1518 - accuracy: 0.6388 - val_loss: 0.2014 - val_accuracy: 0.5918\n",
      "Epoch 942/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1494 - accuracy: 0.6567 - val_loss: 0.2175 - val_accuracy: 0.5676\n",
      "Epoch 943/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1575 - accuracy: 0.6315 - val_loss: 0.2013 - val_accuracy: 0.5727\n",
      "Epoch 944/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1529 - accuracy: 0.6474 - val_loss: 0.2050 - val_accuracy: 0.5740\n",
      "Epoch 945/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1499 - accuracy: 0.6394 - val_loss: 0.2458 - val_accuracy: 0.5485\n",
      "Epoch 946/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1613 - accuracy: 0.6197 - val_loss: 0.2060 - val_accuracy: 0.5702\n",
      "Epoch 947/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1475 - accuracy: 0.6522 - val_loss: 0.2054 - val_accuracy: 0.5778\n",
      "Epoch 948/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1511 - accuracy: 0.6398 - val_loss: 0.2095 - val_accuracy: 0.5689\n",
      "Epoch 949/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1561 - accuracy: 0.6324 - val_loss: 0.2084 - val_accuracy: 0.5740\n",
      "Epoch 950/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1496 - accuracy: 0.6535 - val_loss: 0.2006 - val_accuracy: 0.5944\n",
      "Epoch 951/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1488 - accuracy: 0.6455 - val_loss: 0.2074 - val_accuracy: 0.5778\n",
      "Epoch 952/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1467 - accuracy: 0.6541 - val_loss: 0.2028 - val_accuracy: 0.5880\n",
      "Epoch 953/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1467 - accuracy: 0.6544 - val_loss: 0.2039 - val_accuracy: 0.5957\n",
      "Epoch 954/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1522 - accuracy: 0.6385 - val_loss: 0.2320 - val_accuracy: 0.5510\n",
      "Epoch 955/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1612 - accuracy: 0.6244 - val_loss: 0.2055 - val_accuracy: 0.5727\n",
      "Epoch 956/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1533 - accuracy: 0.6496 - val_loss: 0.2017 - val_accuracy: 0.5944\n",
      "Epoch 957/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1453 - accuracy: 0.6522 - val_loss: 0.2095 - val_accuracy: 0.5995\n",
      "Epoch 958/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1521 - accuracy: 0.6347 - val_loss: 0.1979 - val_accuracy: 0.6084\n",
      "Epoch 959/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1459 - accuracy: 0.6548 - val_loss: 0.2019 - val_accuracy: 0.5906\n",
      "Epoch 960/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1501 - accuracy: 0.6551 - val_loss: 0.2039 - val_accuracy: 0.5842\n",
      "Epoch 961/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1533 - accuracy: 0.6442 - val_loss: 0.1999 - val_accuracy: 0.6033\n",
      "Epoch 962/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1486 - accuracy: 0.6433 - val_loss: 0.2073 - val_accuracy: 0.5778\n",
      "Epoch 963/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1533 - accuracy: 0.6366 - val_loss: 0.2165 - val_accuracy: 0.5765\n",
      "Epoch 964/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1532 - accuracy: 0.6350 - val_loss: 0.2062 - val_accuracy: 0.5944\n",
      "Epoch 965/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1530 - accuracy: 0.6398 - val_loss: 0.2032 - val_accuracy: 0.5842\n",
      "Epoch 966/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1477 - accuracy: 0.6471 - val_loss: 0.2087 - val_accuracy: 0.5867\n",
      "Epoch 967/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1536 - accuracy: 0.6353 - val_loss: 0.2195 - val_accuracy: 0.5918\n",
      "Epoch 968/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1510 - accuracy: 0.6481 - val_loss: 0.2088 - val_accuracy: 0.5625\n",
      "Epoch 969/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1540 - accuracy: 0.6331 - val_loss: 0.2041 - val_accuracy: 0.5906\n",
      "Epoch 970/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1466 - accuracy: 0.6465 - val_loss: 0.2025 - val_accuracy: 0.5982\n",
      "Epoch 971/1000\n",
      "3134/3134 [==============================] - 0s 12us/step - loss: 0.1514 - accuracy: 0.6461 - val_loss: 0.2025 - val_accuracy: 0.5931\n",
      "Epoch 972/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1466 - accuracy: 0.6493 - val_loss: 0.2047 - val_accuracy: 0.5753\n",
      "Epoch 973/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1446 - accuracy: 0.6528 - val_loss: 0.1998 - val_accuracy: 0.5778\n",
      "Epoch 974/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1490 - accuracy: 0.6490 - val_loss: 0.2007 - val_accuracy: 0.5906\n",
      "Epoch 975/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1434 - accuracy: 0.6532 - val_loss: 0.1963 - val_accuracy: 0.5931\n",
      "Epoch 976/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1473 - accuracy: 0.6560 - val_loss: 0.2197 - val_accuracy: 0.5778\n",
      "Epoch 977/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1519 - accuracy: 0.6426 - val_loss: 0.2025 - val_accuracy: 0.5753\n",
      "Epoch 978/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1509 - accuracy: 0.6477 - val_loss: 0.1983 - val_accuracy: 0.5944\n",
      "Epoch 979/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1463 - accuracy: 0.6500 - val_loss: 0.2097 - val_accuracy: 0.5753\n",
      "Epoch 980/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1515 - accuracy: 0.6439 - val_loss: 0.1980 - val_accuracy: 0.5893\n",
      "Epoch 981/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1465 - accuracy: 0.6493 - val_loss: 0.2047 - val_accuracy: 0.5969\n",
      "Epoch 982/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1466 - accuracy: 0.6509 - val_loss: 0.2069 - val_accuracy: 0.5778\n",
      "Epoch 983/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1469 - accuracy: 0.6516 - val_loss: 0.2057 - val_accuracy: 0.5982\n",
      "Epoch 984/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1517 - accuracy: 0.6311 - val_loss: 0.2192 - val_accuracy: 0.5842\n",
      "Epoch 985/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1585 - accuracy: 0.6394 - val_loss: 0.1989 - val_accuracy: 0.6020\n",
      "Epoch 986/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1466 - accuracy: 0.6528 - val_loss: 0.1919 - val_accuracy: 0.6033\n",
      "Epoch 987/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1511 - accuracy: 0.6375 - val_loss: 0.2270 - val_accuracy: 0.5612\n",
      "Epoch 988/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1563 - accuracy: 0.6260 - val_loss: 0.1995 - val_accuracy: 0.5969\n",
      "Epoch 989/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1488 - accuracy: 0.6407 - val_loss: 0.2008 - val_accuracy: 0.5893\n",
      "Epoch 990/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1503 - accuracy: 0.6445 - val_loss: 0.1994 - val_accuracy: 0.6059\n",
      "Epoch 991/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1522 - accuracy: 0.6449 - val_loss: 0.1972 - val_accuracy: 0.6033\n",
      "Epoch 992/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1519 - accuracy: 0.6481 - val_loss: 0.1954 - val_accuracy: 0.5804\n",
      "Epoch 993/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1492 - accuracy: 0.6385 - val_loss: 0.1956 - val_accuracy: 0.6020\n",
      "Epoch 994/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1496 - accuracy: 0.6465 - val_loss: 0.2012 - val_accuracy: 0.5931\n",
      "Epoch 995/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1503 - accuracy: 0.6433 - val_loss: 0.2070 - val_accuracy: 0.5906\n",
      "Epoch 996/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1451 - accuracy: 0.6615 - val_loss: 0.2017 - val_accuracy: 0.5969\n",
      "Epoch 997/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1460 - accuracy: 0.6506 - val_loss: 0.2048 - val_accuracy: 0.5842\n",
      "Epoch 998/1000\n",
      "3134/3134 [==============================] - 0s 14us/step - loss: 0.1489 - accuracy: 0.6458 - val_loss: 0.2029 - val_accuracy: 0.5765\n",
      "Epoch 999/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1447 - accuracy: 0.6560 - val_loss: 0.2035 - val_accuracy: 0.5855\n",
      "Epoch 1000/1000\n",
      "3134/3134 [==============================] - 0s 13us/step - loss: 0.1429 - accuracy: 0.6519 - val_loss: 0.1983 - val_accuracy: 0.5957\n",
      "980/980 [==============================] - 0s 4us/step\n",
      "\n",
      "Test Loss: [0.18185145149425586, 0.6153061389923096]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x_train, y_train, x_test, y_test = generate_data(white_wine, 0.8)\n",
    "\n",
    "class DNN_Regressior(models.Model):\n",
    "    def __init__(self, n_in, n_h, n_h2, n_h3, n_h4, n_h5, n_out):\n",
    "        hidden = layers.Dense(n_h)\n",
    "        hidden2 = layers.Dense(n_h2)\n",
    "        hidden3 = layers.Dense(n_h3)\n",
    "        hidden4 = layers.Dense(n_h4)\n",
    "        hidden5 = layers.Dense(n_h5)\n",
    "        output = layers.Dense(n_out)\n",
    "        relu = layers.Activation('relu')\n",
    "        sigmoid = layers.Activation('sigmoid')\n",
    "        dropout_4 = layers.Dropout(0.48)\n",
    "        dropout_2 = layers.Dropout(0.2)\n",
    "\n",
    "        x = layers.Input(shape=(n_in,))\n",
    "        h = relu(hidden(x))\n",
    "        h = dropout_4(h)\n",
    "        h = relu(hidden2(h))\n",
    "        h = relu(hidden3(h)) \n",
    "        h = dropout_2(h)\n",
    "        h = relu(hidden4(h))\n",
    "        h = dropout_4(h)\n",
    "        h = hidden5(h)\n",
    "        y = output(h)\n",
    "\n",
    "        adam = optimizers.Adam(lr=0.003, beta_1=0.8)\n",
    "\n",
    "        super().__init__(x, y)\n",
    "\n",
    "        self.compile(loss='logcosh', \n",
    "                    optimizer=adam,\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "n_in = 11\n",
    "n_h = 212\n",
    "n_h2 = 128\n",
    "n_h3 = 64\n",
    "n_h4 = 128\n",
    "n_h5 = 256\n",
    "n_out = 1\n",
    "\n",
    "model = DNN_Regressior(n_in, n_h, n_h2, n_h3, n_h4, n_h5, n_out)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1000, batch_size=500, validation_split=0.2, verbose=1)\n",
    "\n",
    "performance_test = model.evaluate(x_test, y_test, batch_size=500)\n",
    "\n",
    "print(f'\\nTest Loss: {performance_test}')\n",
    "\n",
    "plot_loss(history)\n",
    "plt.show()\n",
    "plot_acc(history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJ_KUtH2obWf"
   },
   "source": [
    "### 3. 화이트 와인과 레드 와인을 하나의 모델만 사용하여 분류\n",
    "* 화이트 와인과 레드 와인 데이터를 합쳐 wine 데이터 셋 생성\n",
    "* 입력이 화이트 와인인지 레드 와인인지에 관계없이 와인 품질을 분류하는 모델 생성\n",
    "* 모델의 성능을 향상시킬 수 있는 방법을 찾아 적용할 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWzy7FV8obWg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4157 samples, validate on 1040 samples\n",
      "Epoch 1/1500\n",
      "4157/4157 [==============================] - 1s 129us/step - loss: 1.6775 - accuracy: 0.3548 - val_loss: 1.2318 - val_accuracy: 0.4010\n",
      "Epoch 2/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.3766 - accuracy: 0.3924 - val_loss: 1.2284 - val_accuracy: 0.4010\n",
      "Epoch 3/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.3384 - accuracy: 0.4236 - val_loss: 1.2026 - val_accuracy: 0.4231\n",
      "Epoch 4/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3356 - accuracy: 0.4152 - val_loss: 1.2330 - val_accuracy: 0.4010\n",
      "Epoch 5/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.3218 - accuracy: 0.4260 - val_loss: 1.2587 - val_accuracy: 0.4010\n",
      "Epoch 6/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3150 - accuracy: 0.4296 - val_loss: 1.2083 - val_accuracy: 0.4010\n",
      "Epoch 7/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3118 - accuracy: 0.4287 - val_loss: 1.2383 - val_accuracy: 0.4010\n",
      "Epoch 8/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3101 - accuracy: 0.4409 - val_loss: 1.2069 - val_accuracy: 0.4010\n",
      "Epoch 9/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3058 - accuracy: 0.4292 - val_loss: 1.2362 - val_accuracy: 0.4010\n",
      "Epoch 10/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3034 - accuracy: 0.4443 - val_loss: 1.2196 - val_accuracy: 0.4231\n",
      "Epoch 11/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3020 - accuracy: 0.4287 - val_loss: 1.2598 - val_accuracy: 0.4010\n",
      "Epoch 12/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3010 - accuracy: 0.4453 - val_loss: 1.2134 - val_accuracy: 0.4010\n",
      "Epoch 13/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2998 - accuracy: 0.4438 - val_loss: 1.2385 - val_accuracy: 0.4010\n",
      "Epoch 14/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3025 - accuracy: 0.4402 - val_loss: 1.2204 - val_accuracy: 0.4010\n",
      "Epoch 15/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3009 - accuracy: 0.4407 - val_loss: 1.2212 - val_accuracy: 0.4010\n",
      "Epoch 16/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.3011 - accuracy: 0.4304 - val_loss: 1.2132 - val_accuracy: 0.4010\n",
      "Epoch 17/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2962 - accuracy: 0.4441 - val_loss: 1.2668 - val_accuracy: 0.4010\n",
      "Epoch 18/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2966 - accuracy: 0.4455 - val_loss: 1.2461 - val_accuracy: 0.4010\n",
      "Epoch 19/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.3048 - accuracy: 0.4224 - val_loss: 1.3184 - val_accuracy: 0.4010\n",
      "Epoch 20/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2988 - accuracy: 0.4474 - val_loss: 1.2459 - val_accuracy: 0.4010\n",
      "Epoch 21/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2984 - accuracy: 0.4378 - val_loss: 1.2382 - val_accuracy: 0.4010\n",
      "Epoch 22/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2987 - accuracy: 0.4409 - val_loss: 1.2421 - val_accuracy: 0.4010\n",
      "Epoch 23/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2966 - accuracy: 0.4455 - val_loss: 1.2278 - val_accuracy: 0.4010\n",
      "Epoch 24/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2931 - accuracy: 0.4470 - val_loss: 1.2301 - val_accuracy: 0.4010\n",
      "Epoch 25/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2949 - accuracy: 0.4438 - val_loss: 1.2585 - val_accuracy: 0.4010\n",
      "Epoch 26/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2970 - accuracy: 0.4433 - val_loss: 1.2351 - val_accuracy: 0.4010\n",
      "Epoch 27/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2903 - accuracy: 0.4453 - val_loss: 1.2213 - val_accuracy: 0.4010\n",
      "Epoch 28/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2982 - accuracy: 0.4352 - val_loss: 1.2279 - val_accuracy: 0.4010\n",
      "Epoch 29/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.2965 - accuracy: 0.4446 - val_loss: 1.2212 - val_accuracy: 0.4010\n",
      "Epoch 30/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2929 - accuracy: 0.4455 - val_loss: 1.2261 - val_accuracy: 0.4010\n",
      "Epoch 31/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2915 - accuracy: 0.4448 - val_loss: 1.2184 - val_accuracy: 0.4010\n",
      "Epoch 32/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2941 - accuracy: 0.4433 - val_loss: 1.2533 - val_accuracy: 0.4010\n",
      "Epoch 33/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2940 - accuracy: 0.4453 - val_loss: 1.2180 - val_accuracy: 0.4010\n",
      "Epoch 34/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2978 - accuracy: 0.4344 - val_loss: 1.2265 - val_accuracy: 0.4010\n",
      "Epoch 35/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2995 - accuracy: 0.4318 - val_loss: 1.2349 - val_accuracy: 0.4010\n",
      "Epoch 36/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2931 - accuracy: 0.4465 - val_loss: 1.2289 - val_accuracy: 0.4010\n",
      "Epoch 37/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2941 - accuracy: 0.4462 - val_loss: 1.2207 - val_accuracy: 0.4010\n",
      "Epoch 38/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2890 - accuracy: 0.4441 - val_loss: 1.2505 - val_accuracy: 0.4010\n",
      "Epoch 39/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2980 - accuracy: 0.4414 - val_loss: 1.2347 - val_accuracy: 0.4010\n",
      "Epoch 40/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2933 - accuracy: 0.4412 - val_loss: 1.2311 - val_accuracy: 0.4010\n",
      "Epoch 41/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2905 - accuracy: 0.4462 - val_loss: 1.2302 - val_accuracy: 0.4010\n",
      "Epoch 42/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2921 - accuracy: 0.4465 - val_loss: 1.2304 - val_accuracy: 0.4010\n",
      "Epoch 43/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2937 - accuracy: 0.4414 - val_loss: 1.2286 - val_accuracy: 0.4010\n",
      "Epoch 44/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2918 - accuracy: 0.4470 - val_loss: 1.2218 - val_accuracy: 0.4010\n",
      "Epoch 45/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2905 - accuracy: 0.4470 - val_loss: 1.2307 - val_accuracy: 0.4010\n",
      "Epoch 46/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2904 - accuracy: 0.4470 - val_loss: 1.2178 - val_accuracy: 0.4010\n",
      "Epoch 47/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2919 - accuracy: 0.4465 - val_loss: 1.2343 - val_accuracy: 0.4010\n",
      "Epoch 48/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2942 - accuracy: 0.4470 - val_loss: 1.2342 - val_accuracy: 0.4010\n",
      "Epoch 49/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.2911 - accuracy: 0.4467 - val_loss: 1.2510 - val_accuracy: 0.4010\n",
      "Epoch 50/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2927 - accuracy: 0.4460 - val_loss: 1.2362 - val_accuracy: 0.4010\n",
      "Epoch 51/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2909 - accuracy: 0.4460 - val_loss: 1.2209 - val_accuracy: 0.4010\n",
      "Epoch 52/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2862 - accuracy: 0.4498 - val_loss: 1.1936 - val_accuracy: 0.4029\n",
      "Epoch 53/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2667 - accuracy: 0.4587 - val_loss: 1.1409 - val_accuracy: 0.5038\n",
      "Epoch 54/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2435 - accuracy: 0.4513 - val_loss: 1.1249 - val_accuracy: 0.5067\n",
      "Epoch 55/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.2168 - accuracy: 0.4708 - val_loss: 1.1456 - val_accuracy: 0.5135\n",
      "Epoch 56/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.2119 - accuracy: 0.4650 - val_loss: 1.1345 - val_accuracy: 0.5548\n",
      "Epoch 57/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.2016 - accuracy: 0.4652 - val_loss: 1.1188 - val_accuracy: 0.5452\n",
      "Epoch 58/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1983 - accuracy: 0.4645 - val_loss: 1.1341 - val_accuracy: 0.4894\n",
      "Epoch 59/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1892 - accuracy: 0.4722 - val_loss: 1.1129 - val_accuracy: 0.4894\n",
      "Epoch 60/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1860 - accuracy: 0.4761 - val_loss: 1.1075 - val_accuracy: 0.5500\n",
      "Epoch 61/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1828 - accuracy: 0.4753 - val_loss: 1.1078 - val_accuracy: 0.5462\n",
      "Epoch 62/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1750 - accuracy: 0.4674 - val_loss: 1.0995 - val_accuracy: 0.5433\n",
      "Epoch 63/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1744 - accuracy: 0.4910 - val_loss: 1.1259 - val_accuracy: 0.5548\n",
      "Epoch 64/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.1705 - accuracy: 0.4823 - val_loss: 1.1153 - val_accuracy: 0.5567\n",
      "Epoch 65/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1723 - accuracy: 0.4775 - val_loss: 1.1254 - val_accuracy: 0.5010\n",
      "Epoch 66/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1697 - accuracy: 0.4797 - val_loss: 1.0867 - val_accuracy: 0.5260\n",
      "Epoch 67/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1711 - accuracy: 0.4729 - val_loss: 1.0988 - val_accuracy: 0.5048\n",
      "Epoch 68/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1651 - accuracy: 0.4924 - val_loss: 1.0910 - val_accuracy: 0.5606\n",
      "Epoch 69/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1684 - accuracy: 0.4838 - val_loss: 1.0934 - val_accuracy: 0.5394\n",
      "Epoch 70/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.1615 - accuracy: 0.4900 - val_loss: 1.0966 - val_accuracy: 0.5221\n",
      "Epoch 71/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1619 - accuracy: 0.4833 - val_loss: 1.0895 - val_accuracy: 0.5250\n",
      "Epoch 72/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1649 - accuracy: 0.4840 - val_loss: 1.0764 - val_accuracy: 0.5538\n",
      "Epoch 73/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.1641 - accuracy: 0.4903 - val_loss: 1.0899 - val_accuracy: 0.5240\n",
      "Epoch 74/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1599 - accuracy: 0.4992 - val_loss: 1.0782 - val_accuracy: 0.5490\n",
      "Epoch 75/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1571 - accuracy: 0.4980 - val_loss: 1.0885 - val_accuracy: 0.5096\n",
      "Epoch 76/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1540 - accuracy: 0.4891 - val_loss: 1.0763 - val_accuracy: 0.5298\n",
      "Epoch 77/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1641 - accuracy: 0.4919 - val_loss: 1.0800 - val_accuracy: 0.5317\n",
      "Epoch 78/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1526 - accuracy: 0.4943 - val_loss: 1.0838 - val_accuracy: 0.5635\n",
      "Epoch 79/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1523 - accuracy: 0.5020 - val_loss: 1.0775 - val_accuracy: 0.5500\n",
      "Epoch 80/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1557 - accuracy: 0.4924 - val_loss: 1.0700 - val_accuracy: 0.5548\n",
      "Epoch 81/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1507 - accuracy: 0.5011 - val_loss: 1.0651 - val_accuracy: 0.5596\n",
      "Epoch 82/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1455 - accuracy: 0.4931 - val_loss: 1.0518 - val_accuracy: 0.5596\n",
      "Epoch 83/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1483 - accuracy: 0.5042 - val_loss: 1.0597 - val_accuracy: 0.5692\n",
      "Epoch 84/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.1476 - accuracy: 0.5032 - val_loss: 1.0616 - val_accuracy: 0.5548\n",
      "Epoch 85/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1514 - accuracy: 0.4996 - val_loss: 1.0635 - val_accuracy: 0.5606\n",
      "Epoch 86/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.1526 - accuracy: 0.4953 - val_loss: 1.0747 - val_accuracy: 0.5548\n",
      "Epoch 87/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1545 - accuracy: 0.4984 - val_loss: 1.0580 - val_accuracy: 0.5442\n",
      "Epoch 88/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1502 - accuracy: 0.4996 - val_loss: 1.0605 - val_accuracy: 0.5538\n",
      "Epoch 89/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1562 - accuracy: 0.4958 - val_loss: 1.0677 - val_accuracy: 0.5529\n",
      "Epoch 90/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1421 - accuracy: 0.5054 - val_loss: 1.0546 - val_accuracy: 0.5587\n",
      "Epoch 91/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1407 - accuracy: 0.5076 - val_loss: 1.0507 - val_accuracy: 0.5490\n",
      "Epoch 92/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1430 - accuracy: 0.5032 - val_loss: 1.0615 - val_accuracy: 0.5510\n",
      "Epoch 93/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1478 - accuracy: 0.5064 - val_loss: 1.0683 - val_accuracy: 0.5490\n",
      "Epoch 94/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1440 - accuracy: 0.5030 - val_loss: 1.0610 - val_accuracy: 0.5577\n",
      "Epoch 95/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1459 - accuracy: 0.5025 - val_loss: 1.0699 - val_accuracy: 0.5558\n",
      "Epoch 96/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1470 - accuracy: 0.5030 - val_loss: 1.0692 - val_accuracy: 0.5327\n",
      "Epoch 97/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1444 - accuracy: 0.5061 - val_loss: 1.0665 - val_accuracy: 0.5471\n",
      "Epoch 98/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1447 - accuracy: 0.5112 - val_loss: 1.0595 - val_accuracy: 0.5471\n",
      "Epoch 99/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1447 - accuracy: 0.5013 - val_loss: 1.0632 - val_accuracy: 0.5587\n",
      "Epoch 100/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1444 - accuracy: 0.5093 - val_loss: 1.0545 - val_accuracy: 0.5500\n",
      "Epoch 101/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1460 - accuracy: 0.5030 - val_loss: 1.0733 - val_accuracy: 0.5481\n",
      "Epoch 102/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1451 - accuracy: 0.4994 - val_loss: 1.0704 - val_accuracy: 0.5558\n",
      "Epoch 103/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1456 - accuracy: 0.5066 - val_loss: 1.0742 - val_accuracy: 0.5337\n",
      "Epoch 104/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1348 - accuracy: 0.4970 - val_loss: 1.0662 - val_accuracy: 0.5529\n",
      "Epoch 105/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1478 - accuracy: 0.5061 - val_loss: 1.0540 - val_accuracy: 0.5558\n",
      "Epoch 106/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1380 - accuracy: 0.5153 - val_loss: 1.0575 - val_accuracy: 0.5519\n",
      "Epoch 107/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1444 - accuracy: 0.5008 - val_loss: 1.0645 - val_accuracy: 0.5317\n",
      "Epoch 108/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1361 - accuracy: 0.5030 - val_loss: 1.0542 - val_accuracy: 0.5423\n",
      "Epoch 109/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1381 - accuracy: 0.5150 - val_loss: 1.0707 - val_accuracy: 0.5423\n",
      "Epoch 110/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1395 - accuracy: 0.5148 - val_loss: 1.0537 - val_accuracy: 0.5471\n",
      "Epoch 111/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1443 - accuracy: 0.5016 - val_loss: 1.0513 - val_accuracy: 0.5567\n",
      "Epoch 112/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1365 - accuracy: 0.5102 - val_loss: 1.0558 - val_accuracy: 0.5606\n",
      "Epoch 113/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1377 - accuracy: 0.5066 - val_loss: 1.0515 - val_accuracy: 0.5510\n",
      "Epoch 114/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1416 - accuracy: 0.4999 - val_loss: 1.0514 - val_accuracy: 0.5490\n",
      "Epoch 115/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1360 - accuracy: 0.5006 - val_loss: 1.0545 - val_accuracy: 0.5500\n",
      "Epoch 116/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1416 - accuracy: 0.5119 - val_loss: 1.0682 - val_accuracy: 0.5317\n",
      "Epoch 117/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1392 - accuracy: 0.5037 - val_loss: 1.0553 - val_accuracy: 0.5471\n",
      "Epoch 118/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1363 - accuracy: 0.5105 - val_loss: 1.0623 - val_accuracy: 0.5490\n",
      "Epoch 119/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1402 - accuracy: 0.5105 - val_loss: 1.0607 - val_accuracy: 0.5490\n",
      "Epoch 120/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1366 - accuracy: 0.5032 - val_loss: 1.0486 - val_accuracy: 0.5471\n",
      "Epoch 121/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1364 - accuracy: 0.5131 - val_loss: 1.0501 - val_accuracy: 0.5500\n",
      "Epoch 122/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1349 - accuracy: 0.5076 - val_loss: 1.0546 - val_accuracy: 0.5490\n",
      "Epoch 123/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1314 - accuracy: 0.5124 - val_loss: 1.0591 - val_accuracy: 0.5510\n",
      "Epoch 124/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1340 - accuracy: 0.5160 - val_loss: 1.0499 - val_accuracy: 0.5519\n",
      "Epoch 125/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1362 - accuracy: 0.5054 - val_loss: 1.0415 - val_accuracy: 0.5519\n",
      "Epoch 126/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1369 - accuracy: 0.5016 - val_loss: 1.0514 - val_accuracy: 0.5481\n",
      "Epoch 127/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1381 - accuracy: 0.5150 - val_loss: 1.0509 - val_accuracy: 0.5510\n",
      "Epoch 128/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1328 - accuracy: 0.5150 - val_loss: 1.0516 - val_accuracy: 0.5510\n",
      "Epoch 129/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1349 - accuracy: 0.5172 - val_loss: 1.0442 - val_accuracy: 0.5510\n",
      "Epoch 130/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1387 - accuracy: 0.5114 - val_loss: 1.0441 - val_accuracy: 0.5510\n",
      "Epoch 131/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.1352 - accuracy: 0.5174 - val_loss: 1.0397 - val_accuracy: 0.5462\n",
      "Epoch 132/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1351 - accuracy: 0.5134 - val_loss: 1.0450 - val_accuracy: 0.5538\n",
      "Epoch 133/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1303 - accuracy: 0.5186 - val_loss: 1.0441 - val_accuracy: 0.5529\n",
      "Epoch 134/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1371 - accuracy: 0.5112 - val_loss: 1.0395 - val_accuracy: 0.5538\n",
      "Epoch 135/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1356 - accuracy: 0.5064 - val_loss: 1.0500 - val_accuracy: 0.5538\n",
      "Epoch 136/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1351 - accuracy: 0.5085 - val_loss: 1.0402 - val_accuracy: 0.5490\n",
      "Epoch 137/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1336 - accuracy: 0.5069 - val_loss: 1.0512 - val_accuracy: 0.5548\n",
      "Epoch 138/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1379 - accuracy: 0.5073 - val_loss: 1.0485 - val_accuracy: 0.5481\n",
      "Epoch 139/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1368 - accuracy: 0.5138 - val_loss: 1.0419 - val_accuracy: 0.5481\n",
      "Epoch 140/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1345 - accuracy: 0.5117 - val_loss: 1.0619 - val_accuracy: 0.5423\n",
      "Epoch 141/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1358 - accuracy: 0.5136 - val_loss: 1.0480 - val_accuracy: 0.5481\n",
      "Epoch 142/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.1298 - accuracy: 0.5215 - val_loss: 1.0467 - val_accuracy: 0.5558\n",
      "Epoch 143/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1291 - accuracy: 0.5208 - val_loss: 1.0402 - val_accuracy: 0.5529\n",
      "Epoch 144/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1321 - accuracy: 0.5088 - val_loss: 1.0420 - val_accuracy: 0.5481\n",
      "Epoch 145/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1286 - accuracy: 0.5124 - val_loss: 1.0435 - val_accuracy: 0.5548\n",
      "Epoch 146/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1338 - accuracy: 0.5138 - val_loss: 1.0443 - val_accuracy: 0.5462\n",
      "Epoch 147/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1350 - accuracy: 0.5025 - val_loss: 1.0377 - val_accuracy: 0.5462\n",
      "Epoch 148/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1323 - accuracy: 0.5105 - val_loss: 1.0416 - val_accuracy: 0.5500\n",
      "Epoch 149/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1276 - accuracy: 0.5165 - val_loss: 1.0385 - val_accuracy: 0.5577\n",
      "Epoch 150/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1305 - accuracy: 0.5117 - val_loss: 1.0418 - val_accuracy: 0.5433\n",
      "Epoch 151/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1333 - accuracy: 0.5134 - val_loss: 1.0413 - val_accuracy: 0.5442\n",
      "Epoch 152/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1315 - accuracy: 0.5196 - val_loss: 1.0395 - val_accuracy: 0.5500\n",
      "Epoch 153/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1356 - accuracy: 0.5093 - val_loss: 1.0428 - val_accuracy: 0.5519\n",
      "Epoch 154/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1348 - accuracy: 0.5134 - val_loss: 1.0510 - val_accuracy: 0.5625\n",
      "Epoch 155/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1247 - accuracy: 0.5141 - val_loss: 1.0337 - val_accuracy: 0.5548\n",
      "Epoch 156/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1345 - accuracy: 0.5114 - val_loss: 1.0387 - val_accuracy: 0.5500\n",
      "Epoch 157/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1276 - accuracy: 0.5112 - val_loss: 1.0359 - val_accuracy: 0.5462\n",
      "Epoch 158/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1319 - accuracy: 0.5129 - val_loss: 1.0330 - val_accuracy: 0.5490\n",
      "Epoch 159/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1221 - accuracy: 0.5244 - val_loss: 1.0402 - val_accuracy: 0.5529\n",
      "Epoch 160/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1309 - accuracy: 0.5109 - val_loss: 1.0367 - val_accuracy: 0.5538\n",
      "Epoch 161/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1323 - accuracy: 0.5218 - val_loss: 1.0331 - val_accuracy: 0.5433\n",
      "Epoch 162/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1287 - accuracy: 0.5117 - val_loss: 1.0366 - val_accuracy: 0.5548\n",
      "Epoch 163/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1298 - accuracy: 0.5162 - val_loss: 1.0416 - val_accuracy: 0.5442\n",
      "Epoch 164/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1302 - accuracy: 0.5194 - val_loss: 1.0400 - val_accuracy: 0.5548\n",
      "Epoch 165/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1270 - accuracy: 0.5117 - val_loss: 1.0360 - val_accuracy: 0.5490\n",
      "Epoch 166/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1288 - accuracy: 0.5121 - val_loss: 1.0321 - val_accuracy: 0.5519\n",
      "Epoch 167/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1302 - accuracy: 0.5167 - val_loss: 1.0425 - val_accuracy: 0.5510\n",
      "Epoch 168/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1311 - accuracy: 0.5109 - val_loss: 1.0361 - val_accuracy: 0.5433\n",
      "Epoch 169/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1311 - accuracy: 0.5124 - val_loss: 1.0377 - val_accuracy: 0.5481\n",
      "Epoch 170/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1253 - accuracy: 0.5196 - val_loss: 1.0338 - val_accuracy: 0.5423\n",
      "Epoch 171/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1288 - accuracy: 0.5134 - val_loss: 1.0323 - val_accuracy: 0.5423\n",
      "Epoch 172/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1274 - accuracy: 0.5085 - val_loss: 1.0257 - val_accuracy: 0.5462\n",
      "Epoch 173/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1263 - accuracy: 0.5172 - val_loss: 1.0255 - val_accuracy: 0.5404\n",
      "Epoch 174/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1326 - accuracy: 0.5191 - val_loss: 1.0318 - val_accuracy: 0.5529\n",
      "Epoch 175/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1220 - accuracy: 0.5170 - val_loss: 1.0301 - val_accuracy: 0.5423\n",
      "Epoch 176/1500\n",
      "4157/4157 [==============================] - 0s 34us/step - loss: 1.1266 - accuracy: 0.5201 - val_loss: 1.0403 - val_accuracy: 0.5462\n",
      "Epoch 177/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1279 - accuracy: 0.5160 - val_loss: 1.0459 - val_accuracy: 0.5413\n",
      "Epoch 178/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1333 - accuracy: 0.5112 - val_loss: 1.0272 - val_accuracy: 0.5567\n",
      "Epoch 179/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1268 - accuracy: 0.5223 - val_loss: 1.0330 - val_accuracy: 0.5490\n",
      "Epoch 180/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1234 - accuracy: 0.5191 - val_loss: 1.0284 - val_accuracy: 0.5538\n",
      "Epoch 181/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1219 - accuracy: 0.5150 - val_loss: 1.0343 - val_accuracy: 0.5471\n",
      "Epoch 182/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1247 - accuracy: 0.5179 - val_loss: 1.0416 - val_accuracy: 0.5510\n",
      "Epoch 183/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1251 - accuracy: 0.5124 - val_loss: 1.0264 - val_accuracy: 0.5510\n",
      "Epoch 184/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1249 - accuracy: 0.5213 - val_loss: 1.0327 - val_accuracy: 0.5538\n",
      "Epoch 185/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1256 - accuracy: 0.5186 - val_loss: 1.0334 - val_accuracy: 0.5548\n",
      "Epoch 186/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1290 - accuracy: 0.5215 - val_loss: 1.0266 - val_accuracy: 0.5433\n",
      "Epoch 187/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1283 - accuracy: 0.5158 - val_loss: 1.0272 - val_accuracy: 0.5548\n",
      "Epoch 188/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1199 - accuracy: 0.5148 - val_loss: 1.0412 - val_accuracy: 0.5490\n",
      "Epoch 189/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1199 - accuracy: 0.5191 - val_loss: 1.0249 - val_accuracy: 0.5519\n",
      "Epoch 190/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1276 - accuracy: 0.5160 - val_loss: 1.0319 - val_accuracy: 0.5538\n",
      "Epoch 191/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1259 - accuracy: 0.5210 - val_loss: 1.0335 - val_accuracy: 0.5452\n",
      "Epoch 192/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1224 - accuracy: 0.5223 - val_loss: 1.0309 - val_accuracy: 0.5462\n",
      "Epoch 193/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1203 - accuracy: 0.5138 - val_loss: 1.0189 - val_accuracy: 0.5519\n",
      "Epoch 194/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1202 - accuracy: 0.5225 - val_loss: 1.0233 - val_accuracy: 0.5490\n",
      "Epoch 195/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1247 - accuracy: 0.5210 - val_loss: 1.0279 - val_accuracy: 0.5490\n",
      "Epoch 196/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1216 - accuracy: 0.5117 - val_loss: 1.0240 - val_accuracy: 0.5462\n",
      "Epoch 197/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1214 - accuracy: 0.5189 - val_loss: 1.0245 - val_accuracy: 0.5510\n",
      "Epoch 198/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1215 - accuracy: 0.5160 - val_loss: 1.0270 - val_accuracy: 0.5529\n",
      "Epoch 199/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1261 - accuracy: 0.5146 - val_loss: 1.0228 - val_accuracy: 0.5519\n",
      "Epoch 200/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1205 - accuracy: 0.5184 - val_loss: 1.0274 - val_accuracy: 0.5433\n",
      "Epoch 201/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1119 - accuracy: 0.5210 - val_loss: 1.0314 - val_accuracy: 0.5471\n",
      "Epoch 202/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1174 - accuracy: 0.5155 - val_loss: 1.0252 - val_accuracy: 0.5567\n",
      "Epoch 203/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1273 - accuracy: 0.5189 - val_loss: 1.0312 - val_accuracy: 0.5558\n",
      "Epoch 204/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1226 - accuracy: 0.5186 - val_loss: 1.0252 - val_accuracy: 0.5471\n",
      "Epoch 205/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1188 - accuracy: 0.5184 - val_loss: 1.0369 - val_accuracy: 0.5587\n",
      "Epoch 206/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1239 - accuracy: 0.5213 - val_loss: 1.0200 - val_accuracy: 0.5490\n",
      "Epoch 207/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1161 - accuracy: 0.5223 - val_loss: 1.0269 - val_accuracy: 0.5500\n",
      "Epoch 208/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1208 - accuracy: 0.5206 - val_loss: 1.0212 - val_accuracy: 0.5510\n",
      "Epoch 209/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1222 - accuracy: 0.5174 - val_loss: 1.0271 - val_accuracy: 0.5452\n",
      "Epoch 210/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1187 - accuracy: 0.5136 - val_loss: 1.0268 - val_accuracy: 0.5529\n",
      "Epoch 211/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1160 - accuracy: 0.5235 - val_loss: 1.0210 - val_accuracy: 0.5471\n",
      "Epoch 212/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1166 - accuracy: 0.5242 - val_loss: 1.0316 - val_accuracy: 0.5462\n",
      "Epoch 213/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1244 - accuracy: 0.5218 - val_loss: 1.0256 - val_accuracy: 0.5500\n",
      "Epoch 214/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1201 - accuracy: 0.5196 - val_loss: 1.0263 - val_accuracy: 0.5481\n",
      "Epoch 215/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1164 - accuracy: 0.5186 - val_loss: 1.0268 - val_accuracy: 0.5452\n",
      "Epoch 216/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1182 - accuracy: 0.5235 - val_loss: 1.0299 - val_accuracy: 0.5433\n",
      "Epoch 217/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1178 - accuracy: 0.5196 - val_loss: 1.0262 - val_accuracy: 0.5481\n",
      "Epoch 218/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1206 - accuracy: 0.5244 - val_loss: 1.0243 - val_accuracy: 0.5452\n",
      "Epoch 219/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1125 - accuracy: 0.5198 - val_loss: 1.0253 - val_accuracy: 0.5481\n",
      "Epoch 220/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1158 - accuracy: 0.5247 - val_loss: 1.0243 - val_accuracy: 0.5462\n",
      "Epoch 221/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1149 - accuracy: 0.5186 - val_loss: 1.0346 - val_accuracy: 0.5433\n",
      "Epoch 222/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1151 - accuracy: 0.5225 - val_loss: 1.0283 - val_accuracy: 0.5500\n",
      "Epoch 223/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1138 - accuracy: 0.5242 - val_loss: 1.0272 - val_accuracy: 0.5471\n",
      "Epoch 224/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1155 - accuracy: 0.5223 - val_loss: 1.0273 - val_accuracy: 0.5462\n",
      "Epoch 225/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1135 - accuracy: 0.5232 - val_loss: 1.0310 - val_accuracy: 0.5452\n",
      "Epoch 226/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1179 - accuracy: 0.5213 - val_loss: 1.0314 - val_accuracy: 0.5404\n",
      "Epoch 227/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1164 - accuracy: 0.5167 - val_loss: 1.0289 - val_accuracy: 0.5385\n",
      "Epoch 228/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1139 - accuracy: 0.5275 - val_loss: 1.0269 - val_accuracy: 0.5433\n",
      "Epoch 229/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1130 - accuracy: 0.5158 - val_loss: 1.0258 - val_accuracy: 0.5500\n",
      "Epoch 230/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1116 - accuracy: 0.5254 - val_loss: 1.0366 - val_accuracy: 0.5490\n",
      "Epoch 231/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1097 - accuracy: 0.5215 - val_loss: 1.0312 - val_accuracy: 0.5404\n",
      "Epoch 232/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1171 - accuracy: 0.5162 - val_loss: 1.0291 - val_accuracy: 0.5346\n",
      "Epoch 233/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1157 - accuracy: 0.5218 - val_loss: 1.0305 - val_accuracy: 0.5519\n",
      "Epoch 234/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1094 - accuracy: 0.5215 - val_loss: 1.0322 - val_accuracy: 0.5423\n",
      "Epoch 235/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1128 - accuracy: 0.5201 - val_loss: 1.0340 - val_accuracy: 0.5423\n",
      "Epoch 236/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1124 - accuracy: 0.5251 - val_loss: 1.0298 - val_accuracy: 0.5385\n",
      "Epoch 237/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1119 - accuracy: 0.5201 - val_loss: 1.0347 - val_accuracy: 0.5308\n",
      "Epoch 238/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1100 - accuracy: 0.5186 - val_loss: 1.0294 - val_accuracy: 0.5413\n",
      "Epoch 239/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1176 - accuracy: 0.5239 - val_loss: 1.0321 - val_accuracy: 0.5346\n",
      "Epoch 240/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1105 - accuracy: 0.5227 - val_loss: 1.0297 - val_accuracy: 0.5471\n",
      "Epoch 241/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1127 - accuracy: 0.5355 - val_loss: 1.0376 - val_accuracy: 0.5365\n",
      "Epoch 242/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1083 - accuracy: 0.5266 - val_loss: 1.0354 - val_accuracy: 0.5385\n",
      "Epoch 243/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1117 - accuracy: 0.5254 - val_loss: 1.0289 - val_accuracy: 0.5442\n",
      "Epoch 244/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1085 - accuracy: 0.5278 - val_loss: 1.0354 - val_accuracy: 0.5442\n",
      "Epoch 245/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1096 - accuracy: 0.5237 - val_loss: 1.0295 - val_accuracy: 0.5423\n",
      "Epoch 246/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1113 - accuracy: 0.5201 - val_loss: 1.0340 - val_accuracy: 0.5442\n",
      "Epoch 247/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1124 - accuracy: 0.5186 - val_loss: 1.0280 - val_accuracy: 0.5442\n",
      "Epoch 248/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1091 - accuracy: 0.5242 - val_loss: 1.0312 - val_accuracy: 0.5462\n",
      "Epoch 249/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1101 - accuracy: 0.5225 - val_loss: 1.0334 - val_accuracy: 0.5423\n",
      "Epoch 250/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1140 - accuracy: 0.5143 - val_loss: 1.0294 - val_accuracy: 0.5404\n",
      "Epoch 251/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1065 - accuracy: 0.5237 - val_loss: 1.0385 - val_accuracy: 0.5423\n",
      "Epoch 252/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1075 - accuracy: 0.5275 - val_loss: 1.0323 - val_accuracy: 0.5413\n",
      "Epoch 253/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1092 - accuracy: 0.5256 - val_loss: 1.0370 - val_accuracy: 0.5394\n",
      "Epoch 254/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1131 - accuracy: 0.5251 - val_loss: 1.0390 - val_accuracy: 0.5404\n",
      "Epoch 255/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1106 - accuracy: 0.5232 - val_loss: 1.0456 - val_accuracy: 0.5327\n",
      "Epoch 256/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1108 - accuracy: 0.5225 - val_loss: 1.0403 - val_accuracy: 0.5433\n",
      "Epoch 257/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1048 - accuracy: 0.5247 - val_loss: 1.0408 - val_accuracy: 0.5308\n",
      "Epoch 258/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1072 - accuracy: 0.5271 - val_loss: 1.0346 - val_accuracy: 0.5394\n",
      "Epoch 259/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1040 - accuracy: 0.5292 - val_loss: 1.0421 - val_accuracy: 0.5298\n",
      "Epoch 260/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1111 - accuracy: 0.5239 - val_loss: 1.0365 - val_accuracy: 0.5423\n",
      "Epoch 261/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1023 - accuracy: 0.5203 - val_loss: 1.0346 - val_accuracy: 0.5404\n",
      "Epoch 262/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1073 - accuracy: 0.5266 - val_loss: 1.0407 - val_accuracy: 0.5413\n",
      "Epoch 263/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1134 - accuracy: 0.5268 - val_loss: 1.0343 - val_accuracy: 0.5442\n",
      "Epoch 264/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1112 - accuracy: 0.5167 - val_loss: 1.0327 - val_accuracy: 0.5433\n",
      "Epoch 265/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1038 - accuracy: 0.5266 - val_loss: 1.0339 - val_accuracy: 0.5423\n",
      "Epoch 266/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1058 - accuracy: 0.5299 - val_loss: 1.0389 - val_accuracy: 0.5404\n",
      "Epoch 267/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1065 - accuracy: 0.5215 - val_loss: 1.0341 - val_accuracy: 0.5404\n",
      "Epoch 268/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1065 - accuracy: 0.5297 - val_loss: 1.0368 - val_accuracy: 0.5375\n",
      "Epoch 269/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1081 - accuracy: 0.5227 - val_loss: 1.0372 - val_accuracy: 0.5433\n",
      "Epoch 270/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1071 - accuracy: 0.5218 - val_loss: 1.0321 - val_accuracy: 0.5413\n",
      "Epoch 271/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1075 - accuracy: 0.5210 - val_loss: 1.0354 - val_accuracy: 0.5413\n",
      "Epoch 272/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1119 - accuracy: 0.5206 - val_loss: 1.0349 - val_accuracy: 0.5442\n",
      "Epoch 273/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1089 - accuracy: 0.5203 - val_loss: 1.0375 - val_accuracy: 0.5413\n",
      "Epoch 274/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1024 - accuracy: 0.5268 - val_loss: 1.0416 - val_accuracy: 0.5394\n",
      "Epoch 275/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1042 - accuracy: 0.5213 - val_loss: 1.0382 - val_accuracy: 0.5423\n",
      "Epoch 276/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1105 - accuracy: 0.5256 - val_loss: 1.0370 - val_accuracy: 0.5423\n",
      "Epoch 277/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1070 - accuracy: 0.5242 - val_loss: 1.0327 - val_accuracy: 0.5413\n",
      "Epoch 278/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1060 - accuracy: 0.5290 - val_loss: 1.0348 - val_accuracy: 0.5413\n",
      "Epoch 279/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1041 - accuracy: 0.5326 - val_loss: 1.0370 - val_accuracy: 0.5413\n",
      "Epoch 280/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1070 - accuracy: 0.5182 - val_loss: 1.0393 - val_accuracy: 0.5404\n",
      "Epoch 281/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1088 - accuracy: 0.5249 - val_loss: 1.0371 - val_accuracy: 0.5433\n",
      "Epoch 282/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1081 - accuracy: 0.5256 - val_loss: 1.0403 - val_accuracy: 0.5442\n",
      "Epoch 283/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1108 - accuracy: 0.5254 - val_loss: 1.0404 - val_accuracy: 0.5413\n",
      "Epoch 284/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1078 - accuracy: 0.5263 - val_loss: 1.0461 - val_accuracy: 0.5308\n",
      "Epoch 285/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.1097 - accuracy: 0.5292 - val_loss: 1.0407 - val_accuracy: 0.5423\n",
      "Epoch 286/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1054 - accuracy: 0.5285 - val_loss: 1.0392 - val_accuracy: 0.5462\n",
      "Epoch 287/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1065 - accuracy: 0.5287 - val_loss: 1.0413 - val_accuracy: 0.5433\n",
      "Epoch 288/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1058 - accuracy: 0.5307 - val_loss: 1.0456 - val_accuracy: 0.5385\n",
      "Epoch 289/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0972 - accuracy: 0.5338 - val_loss: 1.0406 - val_accuracy: 0.5423\n",
      "Epoch 290/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1098 - accuracy: 0.5268 - val_loss: 1.0361 - val_accuracy: 0.5433\n",
      "Epoch 291/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1058 - accuracy: 0.5210 - val_loss: 1.0403 - val_accuracy: 0.5423\n",
      "Epoch 292/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1064 - accuracy: 0.5275 - val_loss: 1.0418 - val_accuracy: 0.5413\n",
      "Epoch 293/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1034 - accuracy: 0.5263 - val_loss: 1.0321 - val_accuracy: 0.5452\n",
      "Epoch 294/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1053 - accuracy: 0.5309 - val_loss: 1.0469 - val_accuracy: 0.5462\n",
      "Epoch 295/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1006 - accuracy: 0.5295 - val_loss: 1.0411 - val_accuracy: 0.5356\n",
      "Epoch 296/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1017 - accuracy: 0.5302 - val_loss: 1.0387 - val_accuracy: 0.5413\n",
      "Epoch 297/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1039 - accuracy: 0.5237 - val_loss: 1.0403 - val_accuracy: 0.5413\n",
      "Epoch 298/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1036 - accuracy: 0.5280 - val_loss: 1.0410 - val_accuracy: 0.5413\n",
      "Epoch 299/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1049 - accuracy: 0.5319 - val_loss: 1.0421 - val_accuracy: 0.5413\n",
      "Epoch 300/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1058 - accuracy: 0.5316 - val_loss: 1.0428 - val_accuracy: 0.5423\n",
      "Epoch 301/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1045 - accuracy: 0.5213 - val_loss: 1.0448 - val_accuracy: 0.5442\n",
      "Epoch 302/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0997 - accuracy: 0.5287 - val_loss: 1.0434 - val_accuracy: 0.5365\n",
      "Epoch 303/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1035 - accuracy: 0.5235 - val_loss: 1.0421 - val_accuracy: 0.5442\n",
      "Epoch 304/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1088 - accuracy: 0.5268 - val_loss: 1.0366 - val_accuracy: 0.5375\n",
      "Epoch 305/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1022 - accuracy: 0.5309 - val_loss: 1.0356 - val_accuracy: 0.5413\n",
      "Epoch 306/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0997 - accuracy: 0.5302 - val_loss: 1.0395 - val_accuracy: 0.5413\n",
      "Epoch 307/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1055 - accuracy: 0.5292 - val_loss: 1.0417 - val_accuracy: 0.5452\n",
      "Epoch 308/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1025 - accuracy: 0.5292 - val_loss: 1.0406 - val_accuracy: 0.5404\n",
      "Epoch 309/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1005 - accuracy: 0.5355 - val_loss: 1.0452 - val_accuracy: 0.5433\n",
      "Epoch 310/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1035 - accuracy: 0.5275 - val_loss: 1.0442 - val_accuracy: 0.5385\n",
      "Epoch 311/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0973 - accuracy: 0.5307 - val_loss: 1.0429 - val_accuracy: 0.5375\n",
      "Epoch 312/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1009 - accuracy: 0.5302 - val_loss: 1.0430 - val_accuracy: 0.5346\n",
      "Epoch 313/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1063 - accuracy: 0.5309 - val_loss: 1.0407 - val_accuracy: 0.5385\n",
      "Epoch 314/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0993 - accuracy: 0.5372 - val_loss: 1.0440 - val_accuracy: 0.5394\n",
      "Epoch 315/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1075 - accuracy: 0.5261 - val_loss: 1.0406 - val_accuracy: 0.5433\n",
      "Epoch 316/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1047 - accuracy: 0.5191 - val_loss: 1.0389 - val_accuracy: 0.5365\n",
      "Epoch 317/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1018 - accuracy: 0.5263 - val_loss: 1.0393 - val_accuracy: 0.5394\n",
      "Epoch 318/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0984 - accuracy: 0.5307 - val_loss: 1.0434 - val_accuracy: 0.5337\n",
      "Epoch 319/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0987 - accuracy: 0.5312 - val_loss: 1.0403 - val_accuracy: 0.5394\n",
      "Epoch 320/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1030 - accuracy: 0.5285 - val_loss: 1.0450 - val_accuracy: 0.5365\n",
      "Epoch 321/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1049 - accuracy: 0.5328 - val_loss: 1.0421 - val_accuracy: 0.5404\n",
      "Epoch 322/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0991 - accuracy: 0.5259 - val_loss: 1.0370 - val_accuracy: 0.5356\n",
      "Epoch 323/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1034 - accuracy: 0.5273 - val_loss: 1.0412 - val_accuracy: 0.5404\n",
      "Epoch 324/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0992 - accuracy: 0.5268 - val_loss: 1.0411 - val_accuracy: 0.5404\n",
      "Epoch 325/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1039 - accuracy: 0.5328 - val_loss: 1.0417 - val_accuracy: 0.5404\n",
      "Epoch 326/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0944 - accuracy: 0.5324 - val_loss: 1.0430 - val_accuracy: 0.5413\n",
      "Epoch 327/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1028 - accuracy: 0.5275 - val_loss: 1.0478 - val_accuracy: 0.5356\n",
      "Epoch 328/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1015 - accuracy: 0.5343 - val_loss: 1.0433 - val_accuracy: 0.5375\n",
      "Epoch 329/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1018 - accuracy: 0.5271 - val_loss: 1.0430 - val_accuracy: 0.5404\n",
      "Epoch 330/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0992 - accuracy: 0.5292 - val_loss: 1.0422 - val_accuracy: 0.5394\n",
      "Epoch 331/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1056 - accuracy: 0.5273 - val_loss: 1.0415 - val_accuracy: 0.5394\n",
      "Epoch 332/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1051 - accuracy: 0.5259 - val_loss: 1.0415 - val_accuracy: 0.5346\n",
      "Epoch 333/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1009 - accuracy: 0.5302 - val_loss: 1.0372 - val_accuracy: 0.5413\n",
      "Epoch 334/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0999 - accuracy: 0.5295 - val_loss: 1.0395 - val_accuracy: 0.5385\n",
      "Epoch 335/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1010 - accuracy: 0.5328 - val_loss: 1.0402 - val_accuracy: 0.5385\n",
      "Epoch 336/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0991 - accuracy: 0.5360 - val_loss: 1.0365 - val_accuracy: 0.5471\n",
      "Epoch 337/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0973 - accuracy: 0.5324 - val_loss: 1.0380 - val_accuracy: 0.5423\n",
      "Epoch 338/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1011 - accuracy: 0.5208 - val_loss: 1.0335 - val_accuracy: 0.5452\n",
      "Epoch 339/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0993 - accuracy: 0.5391 - val_loss: 1.0364 - val_accuracy: 0.5413\n",
      "Epoch 340/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0991 - accuracy: 0.5314 - val_loss: 1.0352 - val_accuracy: 0.5404\n",
      "Epoch 341/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1011 - accuracy: 0.5338 - val_loss: 1.0342 - val_accuracy: 0.5404\n",
      "Epoch 342/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0977 - accuracy: 0.5350 - val_loss: 1.0411 - val_accuracy: 0.5442\n",
      "Epoch 343/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1060 - accuracy: 0.5285 - val_loss: 1.0404 - val_accuracy: 0.5337\n",
      "Epoch 344/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0985 - accuracy: 0.5299 - val_loss: 1.0403 - val_accuracy: 0.5394\n",
      "Epoch 345/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1028 - accuracy: 0.5227 - val_loss: 1.0419 - val_accuracy: 0.5404\n",
      "Epoch 346/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0995 - accuracy: 0.5283 - val_loss: 1.0354 - val_accuracy: 0.5404\n",
      "Epoch 347/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0943 - accuracy: 0.5328 - val_loss: 1.0378 - val_accuracy: 0.5356\n",
      "Epoch 348/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0965 - accuracy: 0.5292 - val_loss: 1.0399 - val_accuracy: 0.5452\n",
      "Epoch 349/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0974 - accuracy: 0.5295 - val_loss: 1.0387 - val_accuracy: 0.5327\n",
      "Epoch 350/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0963 - accuracy: 0.5345 - val_loss: 1.0396 - val_accuracy: 0.5404\n",
      "Epoch 351/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1021 - accuracy: 0.5309 - val_loss: 1.0465 - val_accuracy: 0.5385\n",
      "Epoch 352/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0954 - accuracy: 0.5449 - val_loss: 1.0386 - val_accuracy: 0.5404\n",
      "Epoch 353/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0976 - accuracy: 0.5324 - val_loss: 1.0436 - val_accuracy: 0.5337\n",
      "Epoch 354/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0942 - accuracy: 0.5302 - val_loss: 1.0415 - val_accuracy: 0.5404\n",
      "Epoch 355/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0999 - accuracy: 0.5328 - val_loss: 1.0398 - val_accuracy: 0.5337\n",
      "Epoch 356/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1014 - accuracy: 0.5278 - val_loss: 1.0452 - val_accuracy: 0.5356\n",
      "Epoch 357/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0944 - accuracy: 0.5295 - val_loss: 1.0440 - val_accuracy: 0.5375\n",
      "Epoch 358/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0987 - accuracy: 0.5247 - val_loss: 1.0456 - val_accuracy: 0.5413\n",
      "Epoch 359/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0961 - accuracy: 0.5273 - val_loss: 1.0389 - val_accuracy: 0.5433\n",
      "Epoch 360/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0959 - accuracy: 0.5275 - val_loss: 1.0350 - val_accuracy: 0.5423\n",
      "Epoch 361/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0991 - accuracy: 0.5343 - val_loss: 1.0368 - val_accuracy: 0.5404\n",
      "Epoch 362/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.1006 - accuracy: 0.5261 - val_loss: 1.0420 - val_accuracy: 0.5394\n",
      "Epoch 363/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0981 - accuracy: 0.5309 - val_loss: 1.0400 - val_accuracy: 0.5365\n",
      "Epoch 364/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0940 - accuracy: 0.5309 - val_loss: 1.0391 - val_accuracy: 0.5394\n",
      "Epoch 365/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0978 - accuracy: 0.5254 - val_loss: 1.0345 - val_accuracy: 0.5385\n",
      "Epoch 366/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0955 - accuracy: 0.5345 - val_loss: 1.0379 - val_accuracy: 0.5346\n",
      "Epoch 367/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0970 - accuracy: 0.5316 - val_loss: 1.0390 - val_accuracy: 0.5423\n",
      "Epoch 368/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0960 - accuracy: 0.5343 - val_loss: 1.0382 - val_accuracy: 0.5337\n",
      "Epoch 369/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0950 - accuracy: 0.5287 - val_loss: 1.0371 - val_accuracy: 0.5404\n",
      "Epoch 370/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0996 - accuracy: 0.5309 - val_loss: 1.0390 - val_accuracy: 0.5385\n",
      "Epoch 371/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1001 - accuracy: 0.5312 - val_loss: 1.0371 - val_accuracy: 0.5394\n",
      "Epoch 372/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0925 - accuracy: 0.5309 - val_loss: 1.0342 - val_accuracy: 0.5365\n",
      "Epoch 373/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0920 - accuracy: 0.5316 - val_loss: 1.0383 - val_accuracy: 0.5337\n",
      "Epoch 374/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1000 - accuracy: 0.5304 - val_loss: 1.0368 - val_accuracy: 0.5365\n",
      "Epoch 375/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0953 - accuracy: 0.5367 - val_loss: 1.0440 - val_accuracy: 0.5375\n",
      "Epoch 376/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0960 - accuracy: 0.5333 - val_loss: 1.0432 - val_accuracy: 0.5442\n",
      "Epoch 377/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0967 - accuracy: 0.5307 - val_loss: 1.0360 - val_accuracy: 0.5385\n",
      "Epoch 378/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1001 - accuracy: 0.5259 - val_loss: 1.0445 - val_accuracy: 0.5317\n",
      "Epoch 379/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0959 - accuracy: 0.5336 - val_loss: 1.0355 - val_accuracy: 0.5365\n",
      "Epoch 380/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0947 - accuracy: 0.5367 - val_loss: 1.0360 - val_accuracy: 0.5375\n",
      "Epoch 381/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0955 - accuracy: 0.5304 - val_loss: 1.0355 - val_accuracy: 0.5327\n",
      "Epoch 382/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0954 - accuracy: 0.5396 - val_loss: 1.0358 - val_accuracy: 0.5394\n",
      "Epoch 383/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0966 - accuracy: 0.5362 - val_loss: 1.0344 - val_accuracy: 0.5394\n",
      "Epoch 384/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1000 - accuracy: 0.5343 - val_loss: 1.0300 - val_accuracy: 0.5404\n",
      "Epoch 385/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0976 - accuracy: 0.5384 - val_loss: 1.0422 - val_accuracy: 0.5404\n",
      "Epoch 386/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0968 - accuracy: 0.5309 - val_loss: 1.0343 - val_accuracy: 0.5404\n",
      "Epoch 387/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0935 - accuracy: 0.5295 - val_loss: 1.0342 - val_accuracy: 0.5433\n",
      "Epoch 388/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0906 - accuracy: 0.5401 - val_loss: 1.0354 - val_accuracy: 0.5394\n",
      "Epoch 389/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0945 - accuracy: 0.5304 - val_loss: 1.0342 - val_accuracy: 0.5394\n",
      "Epoch 390/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.1001 - accuracy: 0.5384 - val_loss: 1.0349 - val_accuracy: 0.5423\n",
      "Epoch 391/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0965 - accuracy: 0.5408 - val_loss: 1.0384 - val_accuracy: 0.5356\n",
      "Epoch 392/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0965 - accuracy: 0.5367 - val_loss: 1.0381 - val_accuracy: 0.5346\n",
      "Epoch 393/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0978 - accuracy: 0.5251 - val_loss: 1.0377 - val_accuracy: 0.5462\n",
      "Epoch 394/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0978 - accuracy: 0.5328 - val_loss: 1.0340 - val_accuracy: 0.5404\n",
      "Epoch 395/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0912 - accuracy: 0.5316 - val_loss: 1.0352 - val_accuracy: 0.5375\n",
      "Epoch 396/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0943 - accuracy: 0.5297 - val_loss: 1.0312 - val_accuracy: 0.5471\n",
      "Epoch 397/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0922 - accuracy: 0.5338 - val_loss: 1.0375 - val_accuracy: 0.5385\n",
      "Epoch 398/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0943 - accuracy: 0.5312 - val_loss: 1.0372 - val_accuracy: 0.5442\n",
      "Epoch 399/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0918 - accuracy: 0.5350 - val_loss: 1.0404 - val_accuracy: 0.5423\n",
      "Epoch 400/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0895 - accuracy: 0.5389 - val_loss: 1.0361 - val_accuracy: 0.5346\n",
      "Epoch 401/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0943 - accuracy: 0.5302 - val_loss: 1.0356 - val_accuracy: 0.5413\n",
      "Epoch 402/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0911 - accuracy: 0.5292 - val_loss: 1.0359 - val_accuracy: 0.5423\n",
      "Epoch 403/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0911 - accuracy: 0.5374 - val_loss: 1.0369 - val_accuracy: 0.5452\n",
      "Epoch 404/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0927 - accuracy: 0.5432 - val_loss: 1.0432 - val_accuracy: 0.5394\n",
      "Epoch 405/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0913 - accuracy: 0.5352 - val_loss: 1.0410 - val_accuracy: 0.5394\n",
      "Epoch 406/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0915 - accuracy: 0.5340 - val_loss: 1.0376 - val_accuracy: 0.5519\n",
      "Epoch 407/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0968 - accuracy: 0.5328 - val_loss: 1.0323 - val_accuracy: 0.5471\n",
      "Epoch 408/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0956 - accuracy: 0.5244 - val_loss: 1.0356 - val_accuracy: 0.5327\n",
      "Epoch 409/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1021 - accuracy: 0.5314 - val_loss: 1.0388 - val_accuracy: 0.5452\n",
      "Epoch 410/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0961 - accuracy: 0.5372 - val_loss: 1.0410 - val_accuracy: 0.5375\n",
      "Epoch 411/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1016 - accuracy: 0.5285 - val_loss: 1.0373 - val_accuracy: 0.5433\n",
      "Epoch 412/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0916 - accuracy: 0.5321 - val_loss: 1.0360 - val_accuracy: 0.5413\n",
      "Epoch 413/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0940 - accuracy: 0.5352 - val_loss: 1.0331 - val_accuracy: 0.5423\n",
      "Epoch 414/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0915 - accuracy: 0.5364 - val_loss: 1.0319 - val_accuracy: 0.5365\n",
      "Epoch 415/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0890 - accuracy: 0.5328 - val_loss: 1.0325 - val_accuracy: 0.5442\n",
      "Epoch 416/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0896 - accuracy: 0.5360 - val_loss: 1.0411 - val_accuracy: 0.5433\n",
      "Epoch 417/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0904 - accuracy: 0.5319 - val_loss: 1.0374 - val_accuracy: 0.5413\n",
      "Epoch 418/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0909 - accuracy: 0.5321 - val_loss: 1.0385 - val_accuracy: 0.5346\n",
      "Epoch 419/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0933 - accuracy: 0.5314 - val_loss: 1.0347 - val_accuracy: 0.5346\n",
      "Epoch 420/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0907 - accuracy: 0.5254 - val_loss: 1.0326 - val_accuracy: 0.5471\n",
      "Epoch 421/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0912 - accuracy: 0.5292 - val_loss: 1.0353 - val_accuracy: 0.5394\n",
      "Epoch 422/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0938 - accuracy: 0.5352 - val_loss: 1.0336 - val_accuracy: 0.5423\n",
      "Epoch 423/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0917 - accuracy: 0.5355 - val_loss: 1.0343 - val_accuracy: 0.5462\n",
      "Epoch 424/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0917 - accuracy: 0.5283 - val_loss: 1.0346 - val_accuracy: 0.5394\n",
      "Epoch 425/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0908 - accuracy: 0.5287 - val_loss: 1.0346 - val_accuracy: 0.5433\n",
      "Epoch 426/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0902 - accuracy: 0.5321 - val_loss: 1.0357 - val_accuracy: 0.5452\n",
      "Epoch 427/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0907 - accuracy: 0.5336 - val_loss: 1.0396 - val_accuracy: 0.5490\n",
      "Epoch 428/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0939 - accuracy: 0.5328 - val_loss: 1.0416 - val_accuracy: 0.5452\n",
      "Epoch 429/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0928 - accuracy: 0.5290 - val_loss: 1.0367 - val_accuracy: 0.5452\n",
      "Epoch 430/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0881 - accuracy: 0.5324 - val_loss: 1.0360 - val_accuracy: 0.5452\n",
      "Epoch 431/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0877 - accuracy: 0.5304 - val_loss: 1.0373 - val_accuracy: 0.5462\n",
      "Epoch 432/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0860 - accuracy: 0.5381 - val_loss: 1.0401 - val_accuracy: 0.5442\n",
      "Epoch 433/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0907 - accuracy: 0.5302 - val_loss: 1.0330 - val_accuracy: 0.5510\n",
      "Epoch 434/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0897 - accuracy: 0.5393 - val_loss: 1.0373 - val_accuracy: 0.5433\n",
      "Epoch 435/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.1008 - accuracy: 0.5268 - val_loss: 1.0341 - val_accuracy: 0.5462\n",
      "Epoch 436/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0893 - accuracy: 0.5343 - val_loss: 1.0390 - val_accuracy: 0.5500\n",
      "Epoch 437/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0899 - accuracy: 0.5372 - val_loss: 1.0370 - val_accuracy: 0.5490\n",
      "Epoch 438/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0930 - accuracy: 0.5340 - val_loss: 1.0325 - val_accuracy: 0.5452\n",
      "Epoch 439/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0891 - accuracy: 0.5324 - val_loss: 1.0357 - val_accuracy: 0.5500\n",
      "Epoch 440/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0889 - accuracy: 0.5336 - val_loss: 1.0355 - val_accuracy: 0.5404\n",
      "Epoch 441/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0920 - accuracy: 0.5372 - val_loss: 1.0382 - val_accuracy: 0.5500\n",
      "Epoch 442/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0914 - accuracy: 0.5292 - val_loss: 1.0360 - val_accuracy: 0.5413\n",
      "Epoch 443/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0893 - accuracy: 0.5362 - val_loss: 1.0357 - val_accuracy: 0.5433\n",
      "Epoch 444/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0899 - accuracy: 0.5312 - val_loss: 1.0382 - val_accuracy: 0.5385\n",
      "Epoch 445/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0873 - accuracy: 0.5408 - val_loss: 1.0337 - val_accuracy: 0.5452\n",
      "Epoch 446/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0906 - accuracy: 0.5355 - val_loss: 1.0318 - val_accuracy: 0.5442\n",
      "Epoch 447/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0896 - accuracy: 0.5319 - val_loss: 1.0309 - val_accuracy: 0.5452\n",
      "Epoch 448/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0851 - accuracy: 0.5372 - val_loss: 1.0358 - val_accuracy: 0.5452\n",
      "Epoch 449/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0884 - accuracy: 0.5367 - val_loss: 1.0364 - val_accuracy: 0.5356\n",
      "Epoch 450/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0920 - accuracy: 0.5328 - val_loss: 1.0339 - val_accuracy: 0.5471\n",
      "Epoch 451/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0837 - accuracy: 0.5319 - val_loss: 1.0346 - val_accuracy: 0.5423\n",
      "Epoch 452/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0884 - accuracy: 0.5319 - val_loss: 1.0312 - val_accuracy: 0.5481\n",
      "Epoch 453/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0885 - accuracy: 0.5350 - val_loss: 1.0312 - val_accuracy: 0.5404\n",
      "Epoch 454/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0907 - accuracy: 0.5328 - val_loss: 1.0312 - val_accuracy: 0.5433\n",
      "Epoch 455/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0876 - accuracy: 0.5331 - val_loss: 1.0341 - val_accuracy: 0.5433\n",
      "Epoch 456/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0907 - accuracy: 0.5328 - val_loss: 1.0331 - val_accuracy: 0.5385\n",
      "Epoch 457/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0910 - accuracy: 0.5345 - val_loss: 1.0323 - val_accuracy: 0.5452\n",
      "Epoch 458/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0872 - accuracy: 0.5389 - val_loss: 1.0363 - val_accuracy: 0.5433\n",
      "Epoch 459/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0871 - accuracy: 0.5355 - val_loss: 1.0365 - val_accuracy: 0.5433\n",
      "Epoch 460/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0852 - accuracy: 0.5376 - val_loss: 1.0374 - val_accuracy: 0.5413\n",
      "Epoch 461/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0883 - accuracy: 0.5307 - val_loss: 1.0358 - val_accuracy: 0.5452\n",
      "Epoch 462/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0880 - accuracy: 0.5350 - val_loss: 1.0289 - val_accuracy: 0.5413\n",
      "Epoch 463/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0872 - accuracy: 0.5278 - val_loss: 1.0371 - val_accuracy: 0.5471\n",
      "Epoch 464/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0875 - accuracy: 0.5316 - val_loss: 1.0412 - val_accuracy: 0.5510\n",
      "Epoch 465/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0881 - accuracy: 0.5340 - val_loss: 1.0357 - val_accuracy: 0.5423\n",
      "Epoch 466/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0908 - accuracy: 0.5287 - val_loss: 1.0319 - val_accuracy: 0.5385\n",
      "Epoch 467/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0857 - accuracy: 0.5336 - val_loss: 1.0354 - val_accuracy: 0.5433\n",
      "Epoch 468/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0846 - accuracy: 0.5376 - val_loss: 1.0316 - val_accuracy: 0.5471\n",
      "Epoch 469/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0823 - accuracy: 0.5352 - val_loss: 1.0338 - val_accuracy: 0.5462\n",
      "Epoch 470/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0934 - accuracy: 0.5324 - val_loss: 1.0350 - val_accuracy: 0.5529\n",
      "Epoch 471/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0850 - accuracy: 0.5333 - val_loss: 1.0288 - val_accuracy: 0.5385\n",
      "Epoch 472/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0885 - accuracy: 0.5292 - val_loss: 1.0293 - val_accuracy: 0.5442\n",
      "Epoch 473/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0892 - accuracy: 0.5343 - val_loss: 1.0334 - val_accuracy: 0.5471\n",
      "Epoch 474/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0870 - accuracy: 0.5360 - val_loss: 1.0299 - val_accuracy: 0.5442\n",
      "Epoch 475/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0862 - accuracy: 0.5348 - val_loss: 1.0373 - val_accuracy: 0.5442\n",
      "Epoch 476/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0851 - accuracy: 0.5386 - val_loss: 1.0370 - val_accuracy: 0.5413\n",
      "Epoch 477/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0889 - accuracy: 0.5367 - val_loss: 1.0296 - val_accuracy: 0.5404\n",
      "Epoch 478/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0850 - accuracy: 0.5415 - val_loss: 1.0387 - val_accuracy: 0.5490\n",
      "Epoch 479/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0891 - accuracy: 0.5336 - val_loss: 1.0305 - val_accuracy: 0.5442\n",
      "Epoch 480/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0898 - accuracy: 0.5302 - val_loss: 1.0328 - val_accuracy: 0.5452\n",
      "Epoch 481/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0889 - accuracy: 0.5350 - val_loss: 1.0348 - val_accuracy: 0.5413\n",
      "Epoch 482/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0907 - accuracy: 0.5345 - val_loss: 1.0343 - val_accuracy: 0.5490\n",
      "Epoch 483/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0927 - accuracy: 0.5312 - val_loss: 1.0315 - val_accuracy: 0.5413\n",
      "Epoch 484/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0875 - accuracy: 0.5352 - val_loss: 1.0325 - val_accuracy: 0.5394\n",
      "Epoch 485/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0833 - accuracy: 0.5410 - val_loss: 1.0346 - val_accuracy: 0.5413\n",
      "Epoch 486/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0801 - accuracy: 0.5348 - val_loss: 1.0300 - val_accuracy: 0.5375\n",
      "Epoch 487/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0858 - accuracy: 0.5343 - val_loss: 1.0304 - val_accuracy: 0.5452\n",
      "Epoch 488/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0814 - accuracy: 0.5362 - val_loss: 1.0340 - val_accuracy: 0.5452\n",
      "Epoch 489/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0866 - accuracy: 0.5295 - val_loss: 1.0351 - val_accuracy: 0.5471\n",
      "Epoch 490/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0802 - accuracy: 0.5386 - val_loss: 1.0311 - val_accuracy: 0.5452\n",
      "Epoch 491/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0882 - accuracy: 0.5316 - val_loss: 1.0295 - val_accuracy: 0.5423\n",
      "Epoch 492/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0883 - accuracy: 0.5299 - val_loss: 1.0327 - val_accuracy: 0.5433\n",
      "Epoch 493/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0876 - accuracy: 0.5321 - val_loss: 1.0309 - val_accuracy: 0.5423\n",
      "Epoch 494/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0857 - accuracy: 0.5417 - val_loss: 1.0316 - val_accuracy: 0.5433\n",
      "Epoch 495/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0824 - accuracy: 0.5357 - val_loss: 1.0357 - val_accuracy: 0.5490\n",
      "Epoch 496/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0869 - accuracy: 0.5319 - val_loss: 1.0306 - val_accuracy: 0.5394\n",
      "Epoch 497/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0823 - accuracy: 0.5376 - val_loss: 1.0351 - val_accuracy: 0.5433\n",
      "Epoch 498/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0904 - accuracy: 0.5348 - val_loss: 1.0337 - val_accuracy: 0.5481\n",
      "Epoch 499/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0873 - accuracy: 0.5287 - val_loss: 1.0325 - val_accuracy: 0.5413\n",
      "Epoch 500/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0837 - accuracy: 0.5403 - val_loss: 1.0313 - val_accuracy: 0.5375\n",
      "Epoch 501/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0836 - accuracy: 0.5350 - val_loss: 1.0393 - val_accuracy: 0.5423\n",
      "Epoch 502/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0863 - accuracy: 0.5314 - val_loss: 1.0340 - val_accuracy: 0.5433\n",
      "Epoch 503/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0837 - accuracy: 0.5401 - val_loss: 1.0321 - val_accuracy: 0.5394\n",
      "Epoch 504/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0834 - accuracy: 0.5381 - val_loss: 1.0342 - val_accuracy: 0.5423\n",
      "Epoch 505/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0885 - accuracy: 0.5367 - val_loss: 1.0325 - val_accuracy: 0.5462\n",
      "Epoch 506/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0847 - accuracy: 0.5304 - val_loss: 1.0349 - val_accuracy: 0.5385\n",
      "Epoch 507/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0881 - accuracy: 0.5376 - val_loss: 1.0312 - val_accuracy: 0.5413\n",
      "Epoch 508/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0846 - accuracy: 0.5379 - val_loss: 1.0478 - val_accuracy: 0.5442\n",
      "Epoch 509/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0889 - accuracy: 0.5307 - val_loss: 1.0370 - val_accuracy: 0.5404\n",
      "Epoch 510/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0898 - accuracy: 0.5312 - val_loss: 1.0422 - val_accuracy: 0.5510\n",
      "Epoch 511/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0841 - accuracy: 0.5439 - val_loss: 1.0382 - val_accuracy: 0.5442\n",
      "Epoch 512/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0835 - accuracy: 0.5376 - val_loss: 1.0348 - val_accuracy: 0.5404\n",
      "Epoch 513/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0862 - accuracy: 0.5357 - val_loss: 1.0370 - val_accuracy: 0.5413\n",
      "Epoch 514/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0853 - accuracy: 0.5367 - val_loss: 1.0343 - val_accuracy: 0.5471\n",
      "Epoch 515/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0883 - accuracy: 0.5357 - val_loss: 1.0349 - val_accuracy: 0.5433\n",
      "Epoch 516/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0886 - accuracy: 0.5316 - val_loss: 1.0334 - val_accuracy: 0.5462\n",
      "Epoch 517/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0900 - accuracy: 0.5393 - val_loss: 1.0380 - val_accuracy: 0.5500\n",
      "Epoch 518/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0858 - accuracy: 0.5348 - val_loss: 1.0331 - val_accuracy: 0.5452\n",
      "Epoch 519/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0850 - accuracy: 0.5364 - val_loss: 1.0341 - val_accuracy: 0.5519\n",
      "Epoch 520/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0860 - accuracy: 0.5343 - val_loss: 1.0345 - val_accuracy: 0.5385\n",
      "Epoch 521/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0923 - accuracy: 0.5314 - val_loss: 1.0293 - val_accuracy: 0.5462\n",
      "Epoch 522/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0815 - accuracy: 0.5348 - val_loss: 1.0295 - val_accuracy: 0.5413\n",
      "Epoch 523/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0885 - accuracy: 0.5362 - val_loss: 1.0350 - val_accuracy: 0.5500\n",
      "Epoch 524/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0838 - accuracy: 0.5367 - val_loss: 1.0448 - val_accuracy: 0.5538\n",
      "Epoch 525/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0836 - accuracy: 0.5364 - val_loss: 1.0349 - val_accuracy: 0.5385\n",
      "Epoch 526/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0847 - accuracy: 0.5331 - val_loss: 1.0318 - val_accuracy: 0.5404\n",
      "Epoch 527/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0858 - accuracy: 0.5307 - val_loss: 1.0331 - val_accuracy: 0.5500\n",
      "Epoch 528/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0844 - accuracy: 0.5389 - val_loss: 1.0362 - val_accuracy: 0.5385\n",
      "Epoch 529/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0859 - accuracy: 0.5408 - val_loss: 1.0324 - val_accuracy: 0.5404\n",
      "Epoch 530/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0821 - accuracy: 0.5372 - val_loss: 1.0336 - val_accuracy: 0.5413\n",
      "Epoch 531/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0847 - accuracy: 0.5319 - val_loss: 1.0395 - val_accuracy: 0.5346\n",
      "Epoch 532/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0829 - accuracy: 0.5398 - val_loss: 1.0412 - val_accuracy: 0.5365\n",
      "Epoch 533/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0794 - accuracy: 0.5441 - val_loss: 1.0411 - val_accuracy: 0.5385\n",
      "Epoch 534/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0849 - accuracy: 0.5398 - val_loss: 1.0504 - val_accuracy: 0.5356\n",
      "Epoch 535/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0843 - accuracy: 0.5357 - val_loss: 1.0318 - val_accuracy: 0.5433\n",
      "Epoch 536/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0820 - accuracy: 0.5384 - val_loss: 1.0344 - val_accuracy: 0.5442\n",
      "Epoch 537/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0816 - accuracy: 0.5328 - val_loss: 1.0385 - val_accuracy: 0.5404\n",
      "Epoch 538/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0852 - accuracy: 0.5441 - val_loss: 1.0368 - val_accuracy: 0.5442\n",
      "Epoch 539/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0865 - accuracy: 0.5312 - val_loss: 1.0350 - val_accuracy: 0.5394\n",
      "Epoch 540/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0810 - accuracy: 0.5379 - val_loss: 1.0345 - val_accuracy: 0.5413\n",
      "Epoch 541/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0785 - accuracy: 0.5343 - val_loss: 1.0406 - val_accuracy: 0.5462\n",
      "Epoch 542/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0854 - accuracy: 0.5413 - val_loss: 1.0351 - val_accuracy: 0.5442\n",
      "Epoch 543/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0820 - accuracy: 0.5393 - val_loss: 1.0361 - val_accuracy: 0.5442\n",
      "Epoch 544/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0878 - accuracy: 0.5350 - val_loss: 1.0338 - val_accuracy: 0.5433\n",
      "Epoch 545/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0874 - accuracy: 0.5376 - val_loss: 1.0340 - val_accuracy: 0.5452\n",
      "Epoch 546/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0838 - accuracy: 0.5348 - val_loss: 1.0357 - val_accuracy: 0.5423\n",
      "Epoch 547/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0855 - accuracy: 0.5384 - val_loss: 1.0358 - val_accuracy: 0.5413\n",
      "Epoch 548/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0839 - accuracy: 0.5381 - val_loss: 1.0337 - val_accuracy: 0.5442\n",
      "Epoch 549/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0818 - accuracy: 0.5381 - val_loss: 1.0373 - val_accuracy: 0.5413\n",
      "Epoch 550/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0836 - accuracy: 0.5360 - val_loss: 1.0407 - val_accuracy: 0.5433\n",
      "Epoch 551/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0832 - accuracy: 0.5307 - val_loss: 1.0298 - val_accuracy: 0.5442\n",
      "Epoch 552/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0811 - accuracy: 0.5376 - val_loss: 1.0382 - val_accuracy: 0.5365\n",
      "Epoch 553/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0818 - accuracy: 0.5384 - val_loss: 1.0398 - val_accuracy: 0.5365\n",
      "Epoch 554/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0847 - accuracy: 0.5287 - val_loss: 1.0350 - val_accuracy: 0.5423\n",
      "Epoch 555/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0827 - accuracy: 0.5355 - val_loss: 1.0368 - val_accuracy: 0.5394\n",
      "Epoch 556/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0818 - accuracy: 0.5422 - val_loss: 1.0349 - val_accuracy: 0.5413\n",
      "Epoch 557/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0819 - accuracy: 0.5386 - val_loss: 1.0413 - val_accuracy: 0.5471\n",
      "Epoch 558/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0830 - accuracy: 0.5352 - val_loss: 1.0358 - val_accuracy: 0.5413\n",
      "Epoch 559/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0828 - accuracy: 0.5338 - val_loss: 1.0443 - val_accuracy: 0.5462\n",
      "Epoch 560/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0811 - accuracy: 0.5350 - val_loss: 1.0366 - val_accuracy: 0.5423\n",
      "Epoch 561/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0807 - accuracy: 0.5427 - val_loss: 1.0418 - val_accuracy: 0.5423\n",
      "Epoch 562/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0805 - accuracy: 0.5415 - val_loss: 1.0323 - val_accuracy: 0.5442\n",
      "Epoch 563/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0856 - accuracy: 0.5336 - val_loss: 1.0330 - val_accuracy: 0.5452\n",
      "Epoch 564/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0809 - accuracy: 0.5355 - val_loss: 1.0322 - val_accuracy: 0.5385\n",
      "Epoch 565/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0753 - accuracy: 0.5391 - val_loss: 1.0385 - val_accuracy: 0.5442\n",
      "Epoch 566/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0795 - accuracy: 0.5360 - val_loss: 1.0352 - val_accuracy: 0.5423\n",
      "Epoch 567/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0759 - accuracy: 0.5355 - val_loss: 1.0469 - val_accuracy: 0.5394\n",
      "Epoch 568/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0852 - accuracy: 0.5312 - val_loss: 1.0367 - val_accuracy: 0.5394\n",
      "Epoch 569/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0839 - accuracy: 0.5343 - val_loss: 1.0308 - val_accuracy: 0.5433\n",
      "Epoch 570/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0833 - accuracy: 0.5275 - val_loss: 1.0335 - val_accuracy: 0.5365\n",
      "Epoch 571/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0844 - accuracy: 0.5328 - val_loss: 1.0327 - val_accuracy: 0.5452\n",
      "Epoch 572/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0808 - accuracy: 0.5352 - val_loss: 1.0393 - val_accuracy: 0.5365\n",
      "Epoch 573/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0825 - accuracy: 0.5340 - val_loss: 1.0387 - val_accuracy: 0.5452\n",
      "Epoch 574/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0827 - accuracy: 0.5338 - val_loss: 1.0311 - val_accuracy: 0.5452\n",
      "Epoch 575/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0837 - accuracy: 0.5372 - val_loss: 1.0366 - val_accuracy: 0.5365\n",
      "Epoch 576/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0801 - accuracy: 0.5357 - val_loss: 1.0349 - val_accuracy: 0.5433\n",
      "Epoch 577/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0796 - accuracy: 0.5439 - val_loss: 1.0339 - val_accuracy: 0.5433\n",
      "Epoch 578/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0769 - accuracy: 0.5405 - val_loss: 1.0368 - val_accuracy: 0.5490\n",
      "Epoch 579/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0822 - accuracy: 0.5360 - val_loss: 1.0411 - val_accuracy: 0.5404\n",
      "Epoch 580/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0841 - accuracy: 0.5372 - val_loss: 1.0347 - val_accuracy: 0.5404\n",
      "Epoch 581/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0794 - accuracy: 0.5413 - val_loss: 1.0364 - val_accuracy: 0.5442\n",
      "Epoch 582/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0820 - accuracy: 0.5338 - val_loss: 1.0342 - val_accuracy: 0.5394\n",
      "Epoch 583/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0823 - accuracy: 0.5415 - val_loss: 1.0298 - val_accuracy: 0.5442\n",
      "Epoch 584/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0803 - accuracy: 0.5405 - val_loss: 1.0351 - val_accuracy: 0.5394\n",
      "Epoch 585/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0830 - accuracy: 0.5393 - val_loss: 1.0345 - val_accuracy: 0.5423\n",
      "Epoch 586/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0800 - accuracy: 0.5364 - val_loss: 1.0370 - val_accuracy: 0.5413\n",
      "Epoch 587/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0831 - accuracy: 0.5348 - val_loss: 1.0404 - val_accuracy: 0.5346\n",
      "Epoch 588/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0860 - accuracy: 0.5360 - val_loss: 1.0353 - val_accuracy: 0.5442\n",
      "Epoch 589/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0832 - accuracy: 0.5292 - val_loss: 1.0349 - val_accuracy: 0.5452\n",
      "Epoch 590/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0820 - accuracy: 0.5439 - val_loss: 1.0312 - val_accuracy: 0.5471\n",
      "Epoch 591/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0805 - accuracy: 0.5384 - val_loss: 1.0390 - val_accuracy: 0.5481\n",
      "Epoch 592/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0779 - accuracy: 0.5398 - val_loss: 1.0327 - val_accuracy: 0.5433\n",
      "Epoch 593/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0760 - accuracy: 0.5415 - val_loss: 1.0415 - val_accuracy: 0.5365\n",
      "Epoch 594/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0788 - accuracy: 0.5374 - val_loss: 1.0368 - val_accuracy: 0.5404\n",
      "Epoch 595/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0811 - accuracy: 0.5389 - val_loss: 1.0375 - val_accuracy: 0.5413\n",
      "Epoch 596/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0806 - accuracy: 0.5355 - val_loss: 1.0345 - val_accuracy: 0.5413\n",
      "Epoch 597/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0762 - accuracy: 0.5441 - val_loss: 1.0394 - val_accuracy: 0.5404\n",
      "Epoch 598/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0775 - accuracy: 0.5432 - val_loss: 1.0422 - val_accuracy: 0.5375\n",
      "Epoch 599/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0798 - accuracy: 0.5326 - val_loss: 1.0386 - val_accuracy: 0.5346\n",
      "Epoch 600/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0810 - accuracy: 0.5343 - val_loss: 1.0360 - val_accuracy: 0.5346\n",
      "Epoch 601/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0807 - accuracy: 0.5403 - val_loss: 1.0380 - val_accuracy: 0.5394\n",
      "Epoch 602/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0824 - accuracy: 0.5355 - val_loss: 1.0365 - val_accuracy: 0.5404\n",
      "Epoch 603/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0814 - accuracy: 0.5381 - val_loss: 1.0342 - val_accuracy: 0.5365\n",
      "Epoch 604/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0794 - accuracy: 0.5376 - val_loss: 1.0439 - val_accuracy: 0.5413\n",
      "Epoch 605/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0807 - accuracy: 0.5374 - val_loss: 1.0361 - val_accuracy: 0.5452\n",
      "Epoch 606/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0782 - accuracy: 0.5379 - val_loss: 1.0350 - val_accuracy: 0.5442\n",
      "Epoch 607/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0823 - accuracy: 0.5352 - val_loss: 1.0352 - val_accuracy: 0.5490\n",
      "Epoch 608/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0806 - accuracy: 0.5389 - val_loss: 1.0354 - val_accuracy: 0.5413\n",
      "Epoch 609/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0787 - accuracy: 0.5417 - val_loss: 1.0393 - val_accuracy: 0.5385\n",
      "Epoch 610/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0809 - accuracy: 0.5379 - val_loss: 1.0352 - val_accuracy: 0.5423\n",
      "Epoch 611/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0798 - accuracy: 0.5401 - val_loss: 1.0396 - val_accuracy: 0.5462\n",
      "Epoch 612/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0787 - accuracy: 0.5379 - val_loss: 1.0389 - val_accuracy: 0.5423\n",
      "Epoch 613/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0769 - accuracy: 0.5410 - val_loss: 1.0347 - val_accuracy: 0.5394\n",
      "Epoch 614/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0803 - accuracy: 0.5403 - val_loss: 1.0404 - val_accuracy: 0.5375\n",
      "Epoch 615/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0792 - accuracy: 0.5345 - val_loss: 1.0332 - val_accuracy: 0.5452\n",
      "Epoch 616/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0786 - accuracy: 0.5408 - val_loss: 1.0337 - val_accuracy: 0.5442\n",
      "Epoch 617/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0747 - accuracy: 0.5376 - val_loss: 1.0340 - val_accuracy: 0.5413\n",
      "Epoch 618/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0825 - accuracy: 0.5410 - val_loss: 1.0319 - val_accuracy: 0.5404\n",
      "Epoch 619/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0818 - accuracy: 0.5386 - val_loss: 1.0306 - val_accuracy: 0.5471\n",
      "Epoch 620/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0753 - accuracy: 0.5437 - val_loss: 1.0388 - val_accuracy: 0.5413\n",
      "Epoch 621/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0776 - accuracy: 0.5348 - val_loss: 1.0440 - val_accuracy: 0.5394\n",
      "Epoch 622/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0853 - accuracy: 0.5379 - val_loss: 1.0346 - val_accuracy: 0.5404\n",
      "Epoch 623/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0876 - accuracy: 0.5338 - val_loss: 1.0363 - val_accuracy: 0.5452\n",
      "Epoch 624/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0804 - accuracy: 0.5422 - val_loss: 1.0360 - val_accuracy: 0.5413\n",
      "Epoch 625/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0792 - accuracy: 0.5328 - val_loss: 1.0391 - val_accuracy: 0.5356\n",
      "Epoch 626/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0814 - accuracy: 0.5444 - val_loss: 1.0376 - val_accuracy: 0.5471\n",
      "Epoch 627/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0780 - accuracy: 0.5393 - val_loss: 1.0399 - val_accuracy: 0.5433\n",
      "Epoch 628/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0791 - accuracy: 0.5401 - val_loss: 1.0364 - val_accuracy: 0.5423\n",
      "Epoch 629/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0792 - accuracy: 0.5408 - val_loss: 1.0389 - val_accuracy: 0.5375\n",
      "Epoch 630/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0833 - accuracy: 0.5398 - val_loss: 1.0324 - val_accuracy: 0.5375\n",
      "Epoch 631/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0811 - accuracy: 0.5343 - val_loss: 1.0320 - val_accuracy: 0.5385\n",
      "Epoch 632/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0775 - accuracy: 0.5398 - val_loss: 1.0327 - val_accuracy: 0.5337\n",
      "Epoch 633/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0798 - accuracy: 0.5309 - val_loss: 1.0344 - val_accuracy: 0.5375\n",
      "Epoch 634/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0819 - accuracy: 0.5408 - val_loss: 1.0354 - val_accuracy: 0.5385\n",
      "Epoch 635/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0794 - accuracy: 0.5362 - val_loss: 1.0369 - val_accuracy: 0.5394\n",
      "Epoch 636/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0758 - accuracy: 0.5360 - val_loss: 1.0312 - val_accuracy: 0.5385\n",
      "Epoch 637/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0809 - accuracy: 0.5434 - val_loss: 1.0329 - val_accuracy: 0.5471\n",
      "Epoch 638/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0806 - accuracy: 0.5439 - val_loss: 1.0294 - val_accuracy: 0.5471\n",
      "Epoch 639/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0787 - accuracy: 0.5439 - val_loss: 1.0359 - val_accuracy: 0.5433\n",
      "Epoch 640/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0753 - accuracy: 0.5458 - val_loss: 1.0382 - val_accuracy: 0.5337\n",
      "Epoch 641/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0863 - accuracy: 0.5271 - val_loss: 1.0363 - val_accuracy: 0.5423\n",
      "Epoch 642/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0756 - accuracy: 0.5386 - val_loss: 1.0362 - val_accuracy: 0.5394\n",
      "Epoch 643/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0807 - accuracy: 0.5381 - val_loss: 1.0383 - val_accuracy: 0.5481\n",
      "Epoch 644/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0846 - accuracy: 0.5350 - val_loss: 1.0350 - val_accuracy: 0.5375\n",
      "Epoch 645/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0770 - accuracy: 0.5427 - val_loss: 1.0384 - val_accuracy: 0.5375\n",
      "Epoch 646/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0777 - accuracy: 0.5465 - val_loss: 1.0387 - val_accuracy: 0.5423\n",
      "Epoch 647/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0769 - accuracy: 0.5379 - val_loss: 1.0308 - val_accuracy: 0.5500\n",
      "Epoch 648/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0789 - accuracy: 0.5417 - val_loss: 1.0349 - val_accuracy: 0.5385\n",
      "Epoch 649/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0832 - accuracy: 0.5374 - val_loss: 1.0354 - val_accuracy: 0.5404\n",
      "Epoch 650/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0762 - accuracy: 0.5456 - val_loss: 1.0346 - val_accuracy: 0.5423\n",
      "Epoch 651/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0796 - accuracy: 0.5355 - val_loss: 1.0337 - val_accuracy: 0.5490\n",
      "Epoch 652/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0750 - accuracy: 0.5410 - val_loss: 1.0350 - val_accuracy: 0.5442\n",
      "Epoch 653/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0759 - accuracy: 0.5352 - val_loss: 1.0319 - val_accuracy: 0.5452\n",
      "Epoch 654/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0805 - accuracy: 0.5372 - val_loss: 1.0404 - val_accuracy: 0.5375\n",
      "Epoch 655/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0755 - accuracy: 0.5441 - val_loss: 1.0319 - val_accuracy: 0.5433\n",
      "Epoch 656/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0744 - accuracy: 0.5458 - val_loss: 1.0368 - val_accuracy: 0.5346\n",
      "Epoch 657/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0833 - accuracy: 0.5434 - val_loss: 1.0303 - val_accuracy: 0.5452\n",
      "Epoch 658/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0727 - accuracy: 0.5463 - val_loss: 1.0420 - val_accuracy: 0.5394\n",
      "Epoch 659/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0764 - accuracy: 0.5386 - val_loss: 1.0338 - val_accuracy: 0.5385\n",
      "Epoch 660/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0777 - accuracy: 0.5417 - val_loss: 1.0322 - val_accuracy: 0.5365\n",
      "Epoch 661/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0786 - accuracy: 0.5372 - val_loss: 1.0324 - val_accuracy: 0.5423\n",
      "Epoch 662/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0732 - accuracy: 0.5360 - val_loss: 1.0389 - val_accuracy: 0.5462\n",
      "Epoch 663/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0782 - accuracy: 0.5434 - val_loss: 1.0365 - val_accuracy: 0.5346\n",
      "Epoch 664/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0774 - accuracy: 0.5369 - val_loss: 1.0314 - val_accuracy: 0.5471\n",
      "Epoch 665/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0771 - accuracy: 0.5415 - val_loss: 1.0355 - val_accuracy: 0.5433\n",
      "Epoch 666/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0719 - accuracy: 0.5422 - val_loss: 1.0400 - val_accuracy: 0.5346\n",
      "Epoch 667/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0815 - accuracy: 0.5360 - val_loss: 1.0354 - val_accuracy: 0.5365\n",
      "Epoch 668/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0833 - accuracy: 0.5340 - val_loss: 1.0360 - val_accuracy: 0.5394\n",
      "Epoch 669/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0810 - accuracy: 0.5336 - val_loss: 1.0363 - val_accuracy: 0.5365\n",
      "Epoch 670/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0771 - accuracy: 0.5369 - val_loss: 1.0360 - val_accuracy: 0.5462\n",
      "Epoch 671/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0763 - accuracy: 0.5427 - val_loss: 1.0294 - val_accuracy: 0.5462\n",
      "Epoch 672/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0788 - accuracy: 0.5324 - val_loss: 1.0312 - val_accuracy: 0.5481\n",
      "Epoch 673/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0737 - accuracy: 0.5422 - val_loss: 1.0373 - val_accuracy: 0.5442\n",
      "Epoch 674/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0785 - accuracy: 0.5379 - val_loss: 1.0387 - val_accuracy: 0.5423\n",
      "Epoch 675/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0727 - accuracy: 0.5490 - val_loss: 1.0367 - val_accuracy: 0.5365\n",
      "Epoch 676/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0754 - accuracy: 0.5410 - val_loss: 1.0433 - val_accuracy: 0.5452\n",
      "Epoch 677/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0775 - accuracy: 0.5434 - val_loss: 1.0420 - val_accuracy: 0.5356\n",
      "Epoch 678/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0749 - accuracy: 0.5425 - val_loss: 1.0400 - val_accuracy: 0.5346\n",
      "Epoch 679/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0765 - accuracy: 0.5396 - val_loss: 1.0344 - val_accuracy: 0.5423\n",
      "Epoch 680/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0771 - accuracy: 0.5350 - val_loss: 1.0369 - val_accuracy: 0.5423\n",
      "Epoch 681/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0780 - accuracy: 0.5352 - val_loss: 1.0363 - val_accuracy: 0.5442\n",
      "Epoch 682/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0779 - accuracy: 0.5386 - val_loss: 1.0407 - val_accuracy: 0.5298\n",
      "Epoch 683/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0730 - accuracy: 0.5434 - val_loss: 1.0378 - val_accuracy: 0.5385\n",
      "Epoch 684/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0752 - accuracy: 0.5465 - val_loss: 1.0383 - val_accuracy: 0.5346\n",
      "Epoch 685/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0771 - accuracy: 0.5391 - val_loss: 1.0413 - val_accuracy: 0.5346\n",
      "Epoch 686/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0776 - accuracy: 0.5362 - val_loss: 1.0397 - val_accuracy: 0.5433\n",
      "Epoch 687/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0762 - accuracy: 0.5403 - val_loss: 1.0330 - val_accuracy: 0.5413\n",
      "Epoch 688/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0728 - accuracy: 0.5410 - val_loss: 1.0321 - val_accuracy: 0.5462\n",
      "Epoch 689/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0732 - accuracy: 0.5393 - val_loss: 1.0431 - val_accuracy: 0.5308\n",
      "Epoch 690/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0778 - accuracy: 0.5389 - val_loss: 1.0381 - val_accuracy: 0.5442\n",
      "Epoch 691/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0749 - accuracy: 0.5420 - val_loss: 1.0338 - val_accuracy: 0.5481\n",
      "Epoch 692/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0777 - accuracy: 0.5415 - val_loss: 1.0359 - val_accuracy: 0.5413\n",
      "Epoch 693/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0731 - accuracy: 0.5381 - val_loss: 1.0412 - val_accuracy: 0.5413\n",
      "Epoch 694/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0758 - accuracy: 0.5398 - val_loss: 1.0432 - val_accuracy: 0.5442\n",
      "Epoch 695/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0777 - accuracy: 0.5441 - val_loss: 1.0411 - val_accuracy: 0.5346\n",
      "Epoch 696/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0702 - accuracy: 0.5362 - val_loss: 1.0433 - val_accuracy: 0.5375\n",
      "Epoch 697/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0775 - accuracy: 0.5401 - val_loss: 1.0391 - val_accuracy: 0.5394\n",
      "Epoch 698/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0762 - accuracy: 0.5401 - val_loss: 1.0382 - val_accuracy: 0.5433\n",
      "Epoch 699/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0798 - accuracy: 0.5396 - val_loss: 1.0400 - val_accuracy: 0.5375\n",
      "Epoch 700/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0774 - accuracy: 0.5425 - val_loss: 1.0330 - val_accuracy: 0.5375\n",
      "Epoch 701/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0789 - accuracy: 0.5429 - val_loss: 1.0365 - val_accuracy: 0.5452\n",
      "Epoch 702/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0757 - accuracy: 0.5389 - val_loss: 1.0373 - val_accuracy: 0.5481\n",
      "Epoch 703/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0720 - accuracy: 0.5417 - val_loss: 1.0377 - val_accuracy: 0.5404\n",
      "Epoch 704/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0713 - accuracy: 0.5374 - val_loss: 1.0352 - val_accuracy: 0.5385\n",
      "Epoch 705/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0733 - accuracy: 0.5420 - val_loss: 1.0374 - val_accuracy: 0.5413\n",
      "Epoch 706/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0738 - accuracy: 0.5398 - val_loss: 1.0330 - val_accuracy: 0.5385\n",
      "Epoch 707/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0767 - accuracy: 0.5410 - val_loss: 1.0361 - val_accuracy: 0.5337\n",
      "Epoch 708/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0747 - accuracy: 0.5417 - val_loss: 1.0399 - val_accuracy: 0.5452\n",
      "Epoch 709/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0752 - accuracy: 0.5422 - val_loss: 1.0372 - val_accuracy: 0.5413\n",
      "Epoch 710/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0762 - accuracy: 0.5391 - val_loss: 1.0376 - val_accuracy: 0.5423\n",
      "Epoch 711/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0776 - accuracy: 0.5379 - val_loss: 1.0402 - val_accuracy: 0.5423\n",
      "Epoch 712/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0710 - accuracy: 0.5444 - val_loss: 1.0399 - val_accuracy: 0.5375\n",
      "Epoch 713/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0749 - accuracy: 0.5398 - val_loss: 1.0368 - val_accuracy: 0.5462\n",
      "Epoch 714/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0724 - accuracy: 0.5480 - val_loss: 1.0430 - val_accuracy: 0.5346\n",
      "Epoch 715/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0669 - accuracy: 0.5461 - val_loss: 1.0380 - val_accuracy: 0.5404\n",
      "Epoch 716/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0717 - accuracy: 0.5487 - val_loss: 1.0363 - val_accuracy: 0.5433\n",
      "Epoch 717/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0742 - accuracy: 0.5374 - val_loss: 1.0411 - val_accuracy: 0.5404\n",
      "Epoch 718/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0779 - accuracy: 0.5420 - val_loss: 1.0425 - val_accuracy: 0.5404\n",
      "Epoch 719/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0742 - accuracy: 0.5408 - val_loss: 1.0377 - val_accuracy: 0.5404\n",
      "Epoch 720/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0739 - accuracy: 0.5422 - val_loss: 1.0373 - val_accuracy: 0.5365\n",
      "Epoch 721/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0744 - accuracy: 0.5398 - val_loss: 1.0389 - val_accuracy: 0.5385\n",
      "Epoch 722/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0687 - accuracy: 0.5444 - val_loss: 1.0365 - val_accuracy: 0.5394\n",
      "Epoch 723/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0721 - accuracy: 0.5485 - val_loss: 1.0358 - val_accuracy: 0.5385\n",
      "Epoch 724/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0743 - accuracy: 0.5432 - val_loss: 1.0401 - val_accuracy: 0.5308\n",
      "Epoch 725/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0717 - accuracy: 0.5336 - val_loss: 1.0366 - val_accuracy: 0.5404\n",
      "Epoch 726/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0737 - accuracy: 0.5427 - val_loss: 1.0426 - val_accuracy: 0.5413\n",
      "Epoch 727/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0723 - accuracy: 0.5422 - val_loss: 1.0415 - val_accuracy: 0.5337\n",
      "Epoch 728/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0720 - accuracy: 0.5461 - val_loss: 1.0408 - val_accuracy: 0.5346\n",
      "Epoch 729/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0725 - accuracy: 0.5437 - val_loss: 1.0402 - val_accuracy: 0.5413\n",
      "Epoch 730/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0733 - accuracy: 0.5357 - val_loss: 1.0373 - val_accuracy: 0.5375\n",
      "Epoch 731/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0714 - accuracy: 0.5441 - val_loss: 1.0443 - val_accuracy: 0.5356\n",
      "Epoch 732/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0688 - accuracy: 0.5391 - val_loss: 1.0477 - val_accuracy: 0.5346\n",
      "Epoch 733/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0732 - accuracy: 0.5422 - val_loss: 1.0395 - val_accuracy: 0.5356\n",
      "Epoch 734/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0766 - accuracy: 0.5381 - val_loss: 1.0412 - val_accuracy: 0.5452\n",
      "Epoch 735/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0768 - accuracy: 0.5352 - val_loss: 1.0358 - val_accuracy: 0.5500\n",
      "Epoch 736/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0785 - accuracy: 0.5374 - val_loss: 1.0394 - val_accuracy: 0.5433\n",
      "Epoch 737/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0728 - accuracy: 0.5465 - val_loss: 1.0391 - val_accuracy: 0.5394\n",
      "Epoch 738/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0691 - accuracy: 0.5432 - val_loss: 1.0440 - val_accuracy: 0.5423\n",
      "Epoch 739/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0749 - accuracy: 0.5432 - val_loss: 1.0508 - val_accuracy: 0.5375\n",
      "Epoch 740/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0680 - accuracy: 0.5475 - val_loss: 1.0348 - val_accuracy: 0.5529\n",
      "Epoch 741/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0660 - accuracy: 0.5451 - val_loss: 1.0424 - val_accuracy: 0.5394\n",
      "Epoch 742/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0703 - accuracy: 0.5470 - val_loss: 1.0329 - val_accuracy: 0.5433\n",
      "Epoch 743/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0725 - accuracy: 0.5417 - val_loss: 1.0341 - val_accuracy: 0.5471\n",
      "Epoch 744/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0728 - accuracy: 0.5439 - val_loss: 1.0400 - val_accuracy: 0.5538\n",
      "Epoch 745/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0761 - accuracy: 0.5437 - val_loss: 1.0384 - val_accuracy: 0.5423\n",
      "Epoch 746/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0713 - accuracy: 0.5441 - val_loss: 1.0375 - val_accuracy: 0.5481\n",
      "Epoch 747/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0701 - accuracy: 0.5427 - val_loss: 1.0380 - val_accuracy: 0.5404\n",
      "Epoch 748/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0739 - accuracy: 0.5403 - val_loss: 1.0373 - val_accuracy: 0.5452\n",
      "Epoch 749/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0789 - accuracy: 0.5391 - val_loss: 1.0397 - val_accuracy: 0.5413\n",
      "Epoch 750/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0720 - accuracy: 0.5401 - val_loss: 1.0378 - val_accuracy: 0.5375\n",
      "Epoch 751/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0722 - accuracy: 0.5437 - val_loss: 1.0313 - val_accuracy: 0.5375\n",
      "Epoch 752/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0699 - accuracy: 0.5470 - val_loss: 1.0336 - val_accuracy: 0.5394\n",
      "Epoch 753/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0666 - accuracy: 0.5420 - val_loss: 1.0396 - val_accuracy: 0.5346\n",
      "Epoch 754/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0757 - accuracy: 0.5391 - val_loss: 1.0385 - val_accuracy: 0.5385\n",
      "Epoch 755/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0726 - accuracy: 0.5417 - val_loss: 1.0338 - val_accuracy: 0.5413\n",
      "Epoch 756/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0645 - accuracy: 0.5398 - val_loss: 1.0300 - val_accuracy: 0.5433\n",
      "Epoch 757/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0700 - accuracy: 0.5461 - val_loss: 1.0348 - val_accuracy: 0.5404\n",
      "Epoch 758/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0716 - accuracy: 0.5439 - val_loss: 1.0382 - val_accuracy: 0.5462\n",
      "Epoch 759/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0752 - accuracy: 0.5499 - val_loss: 1.0298 - val_accuracy: 0.5510\n",
      "Epoch 760/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0689 - accuracy: 0.5422 - val_loss: 1.0331 - val_accuracy: 0.5471\n",
      "Epoch 761/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0728 - accuracy: 0.5391 - val_loss: 1.0343 - val_accuracy: 0.5490\n",
      "Epoch 762/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0710 - accuracy: 0.5413 - val_loss: 1.0347 - val_accuracy: 0.5385\n",
      "Epoch 763/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0701 - accuracy: 0.5398 - val_loss: 1.0366 - val_accuracy: 0.5433\n",
      "Epoch 764/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0712 - accuracy: 0.5393 - val_loss: 1.0297 - val_accuracy: 0.5404\n",
      "Epoch 765/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0731 - accuracy: 0.5441 - val_loss: 1.0376 - val_accuracy: 0.5394\n",
      "Epoch 766/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0693 - accuracy: 0.5410 - val_loss: 1.0361 - val_accuracy: 0.5462\n",
      "Epoch 767/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0701 - accuracy: 0.5410 - val_loss: 1.0358 - val_accuracy: 0.5442\n",
      "Epoch 768/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0677 - accuracy: 0.5425 - val_loss: 1.0336 - val_accuracy: 0.5442\n",
      "Epoch 769/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0728 - accuracy: 0.5425 - val_loss: 1.0297 - val_accuracy: 0.5538\n",
      "Epoch 770/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0656 - accuracy: 0.5425 - val_loss: 1.0322 - val_accuracy: 0.5433\n",
      "Epoch 771/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0688 - accuracy: 0.5456 - val_loss: 1.0298 - val_accuracy: 0.5394\n",
      "Epoch 772/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0757 - accuracy: 0.5350 - val_loss: 1.0351 - val_accuracy: 0.5346\n",
      "Epoch 773/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0708 - accuracy: 0.5381 - val_loss: 1.0289 - val_accuracy: 0.5462\n",
      "Epoch 774/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0696 - accuracy: 0.5408 - val_loss: 1.0280 - val_accuracy: 0.5510\n",
      "Epoch 775/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0719 - accuracy: 0.5449 - val_loss: 1.0299 - val_accuracy: 0.5500\n",
      "Epoch 776/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0711 - accuracy: 0.5415 - val_loss: 1.0328 - val_accuracy: 0.5471\n",
      "Epoch 777/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0757 - accuracy: 0.5386 - val_loss: 1.0294 - val_accuracy: 0.5452\n",
      "Epoch 778/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0704 - accuracy: 0.5434 - val_loss: 1.0367 - val_accuracy: 0.5394\n",
      "Epoch 779/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0695 - accuracy: 0.5338 - val_loss: 1.0344 - val_accuracy: 0.5404\n",
      "Epoch 780/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0736 - accuracy: 0.5391 - val_loss: 1.0316 - val_accuracy: 0.5452\n",
      "Epoch 781/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0705 - accuracy: 0.5379 - val_loss: 1.0312 - val_accuracy: 0.5442\n",
      "Epoch 782/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0743 - accuracy: 0.5439 - val_loss: 1.0279 - val_accuracy: 0.5452\n",
      "Epoch 783/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0688 - accuracy: 0.5352 - val_loss: 1.0296 - val_accuracy: 0.5433\n",
      "Epoch 784/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0740 - accuracy: 0.5398 - val_loss: 1.0295 - val_accuracy: 0.5442\n",
      "Epoch 785/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0749 - accuracy: 0.5391 - val_loss: 1.0235 - val_accuracy: 0.5500\n",
      "Epoch 786/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0704 - accuracy: 0.5415 - val_loss: 1.0281 - val_accuracy: 0.5577\n",
      "Epoch 787/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0710 - accuracy: 0.5408 - val_loss: 1.0320 - val_accuracy: 0.5500\n",
      "Epoch 788/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0705 - accuracy: 0.5393 - val_loss: 1.0274 - val_accuracy: 0.5490\n",
      "Epoch 789/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0682 - accuracy: 0.5376 - val_loss: 1.0285 - val_accuracy: 0.5490\n",
      "Epoch 790/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0695 - accuracy: 0.5470 - val_loss: 1.0322 - val_accuracy: 0.5442\n",
      "Epoch 791/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0693 - accuracy: 0.5480 - val_loss: 1.0269 - val_accuracy: 0.5519\n",
      "Epoch 792/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0705 - accuracy: 0.5413 - val_loss: 1.0302 - val_accuracy: 0.5413\n",
      "Epoch 793/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0676 - accuracy: 0.5453 - val_loss: 1.0310 - val_accuracy: 0.5462\n",
      "Epoch 794/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0664 - accuracy: 0.5550 - val_loss: 1.0303 - val_accuracy: 0.5500\n",
      "Epoch 795/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0712 - accuracy: 0.5410 - val_loss: 1.0303 - val_accuracy: 0.5510\n",
      "Epoch 796/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0689 - accuracy: 0.5456 - val_loss: 1.0297 - val_accuracy: 0.5471\n",
      "Epoch 797/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0691 - accuracy: 0.5478 - val_loss: 1.0250 - val_accuracy: 0.5442\n",
      "Epoch 798/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0771 - accuracy: 0.5425 - val_loss: 1.0230 - val_accuracy: 0.5500\n",
      "Epoch 799/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0675 - accuracy: 0.5432 - val_loss: 1.0278 - val_accuracy: 0.5404\n",
      "Epoch 800/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0678 - accuracy: 0.5451 - val_loss: 1.0260 - val_accuracy: 0.5471\n",
      "Epoch 801/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0656 - accuracy: 0.5482 - val_loss: 1.0283 - val_accuracy: 0.5500\n",
      "Epoch 802/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0664 - accuracy: 0.5437 - val_loss: 1.0350 - val_accuracy: 0.5519\n",
      "Epoch 803/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0667 - accuracy: 0.5463 - val_loss: 1.0346 - val_accuracy: 0.5510\n",
      "Epoch 804/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0600 - accuracy: 0.5461 - val_loss: 1.0265 - val_accuracy: 0.5596\n",
      "Epoch 805/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0686 - accuracy: 0.5497 - val_loss: 1.0247 - val_accuracy: 0.5500\n",
      "Epoch 806/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0666 - accuracy: 0.5398 - val_loss: 1.0289 - val_accuracy: 0.5481\n",
      "Epoch 807/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0673 - accuracy: 0.5461 - val_loss: 1.0265 - val_accuracy: 0.5510\n",
      "Epoch 808/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0625 - accuracy: 0.5465 - val_loss: 1.0332 - val_accuracy: 0.5442\n",
      "Epoch 809/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0749 - accuracy: 0.5391 - val_loss: 1.0245 - val_accuracy: 0.5510\n",
      "Epoch 810/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0660 - accuracy: 0.5417 - val_loss: 1.0273 - val_accuracy: 0.5558\n",
      "Epoch 811/1500\n",
      "4157/4157 [==============================] - 0s 25us/step - loss: 1.0710 - accuracy: 0.5444 - val_loss: 1.0284 - val_accuracy: 0.5538\n",
      "Epoch 812/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0673 - accuracy: 0.5485 - val_loss: 1.0192 - val_accuracy: 0.5433\n",
      "Epoch 813/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0643 - accuracy: 0.5437 - val_loss: 1.0227 - val_accuracy: 0.5442\n",
      "Epoch 814/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0700 - accuracy: 0.5465 - val_loss: 1.0227 - val_accuracy: 0.5404\n",
      "Epoch 815/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0648 - accuracy: 0.5473 - val_loss: 1.0223 - val_accuracy: 0.5538\n",
      "Epoch 816/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0702 - accuracy: 0.5420 - val_loss: 1.0220 - val_accuracy: 0.5490\n",
      "Epoch 817/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0654 - accuracy: 0.5458 - val_loss: 1.0197 - val_accuracy: 0.5519\n",
      "Epoch 818/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0633 - accuracy: 0.5494 - val_loss: 1.0206 - val_accuracy: 0.5500\n",
      "Epoch 819/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0625 - accuracy: 0.5499 - val_loss: 1.0237 - val_accuracy: 0.5558\n",
      "Epoch 820/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0663 - accuracy: 0.5441 - val_loss: 1.0161 - val_accuracy: 0.5519\n",
      "Epoch 821/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0645 - accuracy: 0.5441 - val_loss: 1.0176 - val_accuracy: 0.5548\n",
      "Epoch 822/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0642 - accuracy: 0.5398 - val_loss: 1.0179 - val_accuracy: 0.5615\n",
      "Epoch 823/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0678 - accuracy: 0.5463 - val_loss: 1.0171 - val_accuracy: 0.5644\n",
      "Epoch 824/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0675 - accuracy: 0.5401 - val_loss: 1.0216 - val_accuracy: 0.5587\n",
      "Epoch 825/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0660 - accuracy: 0.5439 - val_loss: 1.0159 - val_accuracy: 0.5596\n",
      "Epoch 826/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0654 - accuracy: 0.5485 - val_loss: 1.0165 - val_accuracy: 0.5500\n",
      "Epoch 827/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0626 - accuracy: 0.5475 - val_loss: 1.0260 - val_accuracy: 0.5442\n",
      "Epoch 828/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0653 - accuracy: 0.5432 - val_loss: 1.0269 - val_accuracy: 0.5538\n",
      "Epoch 829/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0659 - accuracy: 0.5410 - val_loss: 1.0178 - val_accuracy: 0.5596\n",
      "Epoch 830/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0686 - accuracy: 0.5415 - val_loss: 1.0186 - val_accuracy: 0.5587\n",
      "Epoch 831/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0669 - accuracy: 0.5369 - val_loss: 1.0183 - val_accuracy: 0.5567\n",
      "Epoch 832/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0641 - accuracy: 0.5461 - val_loss: 1.0240 - val_accuracy: 0.5519\n",
      "Epoch 833/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0701 - accuracy: 0.5403 - val_loss: 1.0154 - val_accuracy: 0.5529\n",
      "Epoch 834/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0656 - accuracy: 0.5439 - val_loss: 1.0168 - val_accuracy: 0.5606\n",
      "Epoch 835/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0647 - accuracy: 0.5439 - val_loss: 1.0212 - val_accuracy: 0.5510\n",
      "Epoch 836/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0593 - accuracy: 0.5446 - val_loss: 1.0205 - val_accuracy: 0.5596\n",
      "Epoch 837/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0652 - accuracy: 0.5413 - val_loss: 1.0213 - val_accuracy: 0.5510\n",
      "Epoch 838/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0661 - accuracy: 0.5451 - val_loss: 1.0149 - val_accuracy: 0.5471\n",
      "Epoch 839/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0690 - accuracy: 0.5403 - val_loss: 1.0208 - val_accuracy: 0.5587\n",
      "Epoch 840/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0676 - accuracy: 0.5405 - val_loss: 1.0271 - val_accuracy: 0.5404\n",
      "Epoch 841/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0596 - accuracy: 0.5509 - val_loss: 1.0225 - val_accuracy: 0.5567\n",
      "Epoch 842/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0627 - accuracy: 0.5485 - val_loss: 1.0147 - val_accuracy: 0.5606\n",
      "Epoch 843/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0644 - accuracy: 0.5446 - val_loss: 1.0196 - val_accuracy: 0.5538\n",
      "Epoch 844/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0656 - accuracy: 0.5456 - val_loss: 1.0265 - val_accuracy: 0.5490\n",
      "Epoch 845/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0647 - accuracy: 0.5456 - val_loss: 1.0186 - val_accuracy: 0.5558\n",
      "Epoch 846/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0667 - accuracy: 0.5408 - val_loss: 1.0152 - val_accuracy: 0.5606\n",
      "Epoch 847/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0651 - accuracy: 0.5509 - val_loss: 1.0138 - val_accuracy: 0.5548\n",
      "Epoch 848/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0643 - accuracy: 0.5410 - val_loss: 1.0175 - val_accuracy: 0.5538\n",
      "Epoch 849/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0671 - accuracy: 0.5446 - val_loss: 1.0174 - val_accuracy: 0.5538\n",
      "Epoch 850/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0644 - accuracy: 0.5492 - val_loss: 1.0181 - val_accuracy: 0.5577\n",
      "Epoch 851/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0636 - accuracy: 0.5439 - val_loss: 1.0188 - val_accuracy: 0.5548\n",
      "Epoch 852/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0642 - accuracy: 0.5494 - val_loss: 1.0141 - val_accuracy: 0.5635\n",
      "Epoch 853/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0651 - accuracy: 0.5429 - val_loss: 1.0093 - val_accuracy: 0.5606\n",
      "Epoch 854/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0617 - accuracy: 0.5441 - val_loss: 1.0107 - val_accuracy: 0.5663\n",
      "Epoch 855/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0670 - accuracy: 0.5444 - val_loss: 1.0197 - val_accuracy: 0.5558\n",
      "Epoch 856/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0629 - accuracy: 0.5468 - val_loss: 1.0148 - val_accuracy: 0.5538\n",
      "Epoch 857/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0708 - accuracy: 0.5417 - val_loss: 1.0199 - val_accuracy: 0.5558\n",
      "Epoch 858/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0646 - accuracy: 0.5530 - val_loss: 1.0153 - val_accuracy: 0.5558\n",
      "Epoch 859/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0580 - accuracy: 0.5494 - val_loss: 1.0204 - val_accuracy: 0.5683\n",
      "Epoch 860/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0629 - accuracy: 0.5451 - val_loss: 1.0185 - val_accuracy: 0.5625\n",
      "Epoch 861/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0620 - accuracy: 0.5458 - val_loss: 1.0184 - val_accuracy: 0.5615\n",
      "Epoch 862/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0615 - accuracy: 0.5439 - val_loss: 1.0253 - val_accuracy: 0.5587\n",
      "Epoch 863/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0668 - accuracy: 0.5451 - val_loss: 1.0243 - val_accuracy: 0.5558\n",
      "Epoch 864/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0668 - accuracy: 0.5396 - val_loss: 1.0165 - val_accuracy: 0.5510\n",
      "Epoch 865/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0665 - accuracy: 0.5413 - val_loss: 1.0205 - val_accuracy: 0.5615\n",
      "Epoch 866/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0647 - accuracy: 0.5429 - val_loss: 1.0104 - val_accuracy: 0.5635\n",
      "Epoch 867/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0558 - accuracy: 0.5453 - val_loss: 1.0235 - val_accuracy: 0.5567\n",
      "Epoch 868/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0583 - accuracy: 0.5449 - val_loss: 1.0190 - val_accuracy: 0.5625\n",
      "Epoch 869/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0681 - accuracy: 0.5384 - val_loss: 1.0164 - val_accuracy: 0.5596\n",
      "Epoch 870/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0614 - accuracy: 0.5389 - val_loss: 1.0189 - val_accuracy: 0.5721\n",
      "Epoch 871/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0630 - accuracy: 0.5523 - val_loss: 1.0195 - val_accuracy: 0.5663\n",
      "Epoch 872/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0648 - accuracy: 0.5408 - val_loss: 1.0219 - val_accuracy: 0.5606\n",
      "Epoch 873/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0559 - accuracy: 0.5538 - val_loss: 1.0198 - val_accuracy: 0.5567\n",
      "Epoch 874/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0577 - accuracy: 0.5494 - val_loss: 1.0297 - val_accuracy: 0.5606\n",
      "Epoch 875/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0577 - accuracy: 0.5533 - val_loss: 1.0271 - val_accuracy: 0.5538\n",
      "Epoch 876/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0618 - accuracy: 0.5405 - val_loss: 1.0249 - val_accuracy: 0.5529\n",
      "Epoch 877/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0637 - accuracy: 0.5422 - val_loss: 1.0242 - val_accuracy: 0.5500\n",
      "Epoch 878/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0639 - accuracy: 0.5456 - val_loss: 1.0140 - val_accuracy: 0.5712\n",
      "Epoch 879/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0600 - accuracy: 0.5420 - val_loss: 1.0167 - val_accuracy: 0.5548\n",
      "Epoch 880/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0645 - accuracy: 0.5458 - val_loss: 1.0170 - val_accuracy: 0.5567\n",
      "Epoch 881/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0595 - accuracy: 0.5451 - val_loss: 1.0187 - val_accuracy: 0.5519\n",
      "Epoch 882/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0585 - accuracy: 0.5437 - val_loss: 1.0150 - val_accuracy: 0.5529\n",
      "Epoch 883/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0630 - accuracy: 0.5468 - val_loss: 1.0173 - val_accuracy: 0.5558\n",
      "Epoch 884/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0609 - accuracy: 0.5465 - val_loss: 1.0216 - val_accuracy: 0.5567\n",
      "Epoch 885/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0610 - accuracy: 0.5432 - val_loss: 1.0163 - val_accuracy: 0.5615\n",
      "Epoch 886/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0663 - accuracy: 0.5369 - val_loss: 1.0195 - val_accuracy: 0.5654\n",
      "Epoch 887/1500\n",
      "4157/4157 [==============================] - 0s 35us/step - loss: 1.0574 - accuracy: 0.5458 - val_loss: 1.0178 - val_accuracy: 0.5587\n",
      "Epoch 888/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0625 - accuracy: 0.5458 - val_loss: 1.0262 - val_accuracy: 0.5529\n",
      "Epoch 889/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0611 - accuracy: 0.5449 - val_loss: 1.0278 - val_accuracy: 0.5548\n",
      "Epoch 890/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0607 - accuracy: 0.5439 - val_loss: 1.0204 - val_accuracy: 0.5606\n",
      "Epoch 891/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0532 - accuracy: 0.5487 - val_loss: 1.0233 - val_accuracy: 0.5538\n",
      "Epoch 892/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0587 - accuracy: 0.5478 - val_loss: 1.0266 - val_accuracy: 0.5615\n",
      "Epoch 893/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0625 - accuracy: 0.5521 - val_loss: 1.0412 - val_accuracy: 0.5548\n",
      "Epoch 894/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0616 - accuracy: 0.5413 - val_loss: 1.0180 - val_accuracy: 0.5510\n",
      "Epoch 895/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0541 - accuracy: 0.5506 - val_loss: 1.0147 - val_accuracy: 0.5567\n",
      "Epoch 896/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0633 - accuracy: 0.5413 - val_loss: 1.0087 - val_accuracy: 0.5606\n",
      "Epoch 897/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0621 - accuracy: 0.5355 - val_loss: 1.0116 - val_accuracy: 0.5587\n",
      "Epoch 898/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0595 - accuracy: 0.5420 - val_loss: 1.0268 - val_accuracy: 0.5519\n",
      "Epoch 899/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0608 - accuracy: 0.5413 - val_loss: 1.0201 - val_accuracy: 0.5519\n",
      "Epoch 900/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0588 - accuracy: 0.5420 - val_loss: 1.0143 - val_accuracy: 0.5663\n",
      "Epoch 901/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0578 - accuracy: 0.5509 - val_loss: 1.0160 - val_accuracy: 0.5567\n",
      "Epoch 902/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0536 - accuracy: 0.5518 - val_loss: 1.0207 - val_accuracy: 0.5625\n",
      "Epoch 903/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0560 - accuracy: 0.5451 - val_loss: 1.0186 - val_accuracy: 0.5558\n",
      "Epoch 904/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0573 - accuracy: 0.5449 - val_loss: 1.0194 - val_accuracy: 0.5615\n",
      "Epoch 905/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0615 - accuracy: 0.5480 - val_loss: 1.0175 - val_accuracy: 0.5558\n",
      "Epoch 906/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0572 - accuracy: 0.5490 - val_loss: 1.0127 - val_accuracy: 0.5567\n",
      "Epoch 907/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0552 - accuracy: 0.5480 - val_loss: 1.0217 - val_accuracy: 0.5567\n",
      "Epoch 908/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0556 - accuracy: 0.5497 - val_loss: 1.0179 - val_accuracy: 0.5577\n",
      "Epoch 909/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0582 - accuracy: 0.5482 - val_loss: 1.0252 - val_accuracy: 0.5481\n",
      "Epoch 910/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0629 - accuracy: 0.5357 - val_loss: 1.0192 - val_accuracy: 0.5587\n",
      "Epoch 911/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0592 - accuracy: 0.5415 - val_loss: 1.0169 - val_accuracy: 0.5615\n",
      "Epoch 912/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0579 - accuracy: 0.5485 - val_loss: 1.0219 - val_accuracy: 0.5490\n",
      "Epoch 913/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0563 - accuracy: 0.5429 - val_loss: 1.0171 - val_accuracy: 0.5538\n",
      "Epoch 914/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0568 - accuracy: 0.5444 - val_loss: 1.0203 - val_accuracy: 0.5548\n",
      "Epoch 915/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0590 - accuracy: 0.5449 - val_loss: 1.0215 - val_accuracy: 0.5596\n",
      "Epoch 916/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0597 - accuracy: 0.5405 - val_loss: 1.0136 - val_accuracy: 0.5529\n",
      "Epoch 917/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0601 - accuracy: 0.5415 - val_loss: 1.0193 - val_accuracy: 0.5529\n",
      "Epoch 918/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0616 - accuracy: 0.5449 - val_loss: 1.0261 - val_accuracy: 0.5596\n",
      "Epoch 919/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0620 - accuracy: 0.5492 - val_loss: 1.0225 - val_accuracy: 0.5490\n",
      "Epoch 920/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0614 - accuracy: 0.5504 - val_loss: 1.0185 - val_accuracy: 0.5510\n",
      "Epoch 921/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0539 - accuracy: 0.5516 - val_loss: 1.0190 - val_accuracy: 0.5673\n",
      "Epoch 922/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0557 - accuracy: 0.5478 - val_loss: 1.0132 - val_accuracy: 0.5606\n",
      "Epoch 923/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0581 - accuracy: 0.5497 - val_loss: 1.0185 - val_accuracy: 0.5529\n",
      "Epoch 924/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0596 - accuracy: 0.5451 - val_loss: 1.0267 - val_accuracy: 0.5596\n",
      "Epoch 925/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0527 - accuracy: 0.5497 - val_loss: 1.0206 - val_accuracy: 0.5548\n",
      "Epoch 926/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0579 - accuracy: 0.5453 - val_loss: 1.0155 - val_accuracy: 0.5567\n",
      "Epoch 927/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0531 - accuracy: 0.5468 - val_loss: 1.0181 - val_accuracy: 0.5548\n",
      "Epoch 928/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0595 - accuracy: 0.5429 - val_loss: 1.0233 - val_accuracy: 0.5548\n",
      "Epoch 929/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0558 - accuracy: 0.5456 - val_loss: 1.0220 - val_accuracy: 0.5519\n",
      "Epoch 930/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0556 - accuracy: 0.5480 - val_loss: 1.0180 - val_accuracy: 0.5635\n",
      "Epoch 931/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0545 - accuracy: 0.5478 - val_loss: 1.0227 - val_accuracy: 0.5529\n",
      "Epoch 932/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0612 - accuracy: 0.5393 - val_loss: 1.0199 - val_accuracy: 0.5577\n",
      "Epoch 933/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0546 - accuracy: 0.5485 - val_loss: 1.0212 - val_accuracy: 0.5567\n",
      "Epoch 934/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0541 - accuracy: 0.5458 - val_loss: 1.0231 - val_accuracy: 0.5500\n",
      "Epoch 935/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0578 - accuracy: 0.5463 - val_loss: 1.0271 - val_accuracy: 0.5529\n",
      "Epoch 936/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0573 - accuracy: 0.5511 - val_loss: 1.0223 - val_accuracy: 0.5519\n",
      "Epoch 937/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0584 - accuracy: 0.5425 - val_loss: 1.0227 - val_accuracy: 0.5538\n",
      "Epoch 938/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0568 - accuracy: 0.5482 - val_loss: 1.0214 - val_accuracy: 0.5596\n",
      "Epoch 939/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0541 - accuracy: 0.5437 - val_loss: 1.0187 - val_accuracy: 0.5519\n",
      "Epoch 940/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0505 - accuracy: 0.5511 - val_loss: 1.0211 - val_accuracy: 0.5529\n",
      "Epoch 941/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0577 - accuracy: 0.5408 - val_loss: 1.0127 - val_accuracy: 0.5635\n",
      "Epoch 942/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0596 - accuracy: 0.5439 - val_loss: 1.0216 - val_accuracy: 0.5625\n",
      "Epoch 943/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0565 - accuracy: 0.5417 - val_loss: 1.0115 - val_accuracy: 0.5635\n",
      "Epoch 944/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0544 - accuracy: 0.5497 - val_loss: 1.0224 - val_accuracy: 0.5606\n",
      "Epoch 945/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0546 - accuracy: 0.5461 - val_loss: 1.0201 - val_accuracy: 0.5596\n",
      "Epoch 946/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0522 - accuracy: 0.5506 - val_loss: 1.0191 - val_accuracy: 0.5577\n",
      "Epoch 947/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0580 - accuracy: 0.5473 - val_loss: 1.0197 - val_accuracy: 0.5606\n",
      "Epoch 948/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0607 - accuracy: 0.5379 - val_loss: 1.0171 - val_accuracy: 0.5596\n",
      "Epoch 949/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0531 - accuracy: 0.5405 - val_loss: 1.0225 - val_accuracy: 0.5635\n",
      "Epoch 950/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0549 - accuracy: 0.5413 - val_loss: 1.0274 - val_accuracy: 0.5567\n",
      "Epoch 951/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0570 - accuracy: 0.5528 - val_loss: 1.0273 - val_accuracy: 0.5471\n",
      "Epoch 952/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0493 - accuracy: 0.5509 - val_loss: 1.0233 - val_accuracy: 0.5644\n",
      "Epoch 953/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0524 - accuracy: 0.5499 - val_loss: 1.0268 - val_accuracy: 0.5548\n",
      "Epoch 954/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0565 - accuracy: 0.5497 - val_loss: 1.0146 - val_accuracy: 0.5644\n",
      "Epoch 955/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0563 - accuracy: 0.5470 - val_loss: 1.0194 - val_accuracy: 0.5567\n",
      "Epoch 956/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0510 - accuracy: 0.5439 - val_loss: 1.0254 - val_accuracy: 0.5510\n",
      "Epoch 957/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0543 - accuracy: 0.5434 - val_loss: 1.0268 - val_accuracy: 0.5654\n",
      "Epoch 958/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0540 - accuracy: 0.5506 - val_loss: 1.0278 - val_accuracy: 0.5510\n",
      "Epoch 959/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0566 - accuracy: 0.5463 - val_loss: 1.0243 - val_accuracy: 0.5510\n",
      "Epoch 960/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0527 - accuracy: 0.5478 - val_loss: 1.0213 - val_accuracy: 0.5558\n",
      "Epoch 961/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0540 - accuracy: 0.5482 - val_loss: 1.0300 - val_accuracy: 0.5596\n",
      "Epoch 962/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0529 - accuracy: 0.5461 - val_loss: 1.0297 - val_accuracy: 0.5587\n",
      "Epoch 963/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0581 - accuracy: 0.5413 - val_loss: 1.0208 - val_accuracy: 0.5558\n",
      "Epoch 964/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0534 - accuracy: 0.5516 - val_loss: 1.0228 - val_accuracy: 0.5644\n",
      "Epoch 965/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0562 - accuracy: 0.5432 - val_loss: 1.0202 - val_accuracy: 0.5740\n",
      "Epoch 966/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0514 - accuracy: 0.5492 - val_loss: 1.0279 - val_accuracy: 0.5596\n",
      "Epoch 967/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0530 - accuracy: 0.5446 - val_loss: 1.0236 - val_accuracy: 0.5567\n",
      "Epoch 968/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0575 - accuracy: 0.5425 - val_loss: 1.0239 - val_accuracy: 0.5596\n",
      "Epoch 969/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0518 - accuracy: 0.5502 - val_loss: 1.0243 - val_accuracy: 0.5548\n",
      "Epoch 970/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0565 - accuracy: 0.5408 - val_loss: 1.0299 - val_accuracy: 0.5519\n",
      "Epoch 971/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0538 - accuracy: 0.5504 - val_loss: 1.0302 - val_accuracy: 0.5538\n",
      "Epoch 972/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0585 - accuracy: 0.5490 - val_loss: 1.0290 - val_accuracy: 0.5587\n",
      "Epoch 973/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0542 - accuracy: 0.5482 - val_loss: 1.0295 - val_accuracy: 0.5490\n",
      "Epoch 974/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0471 - accuracy: 0.5473 - val_loss: 1.0322 - val_accuracy: 0.5529\n",
      "Epoch 975/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0535 - accuracy: 0.5490 - val_loss: 1.0230 - val_accuracy: 0.5577\n",
      "Epoch 976/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0503 - accuracy: 0.5494 - val_loss: 1.0228 - val_accuracy: 0.5615\n",
      "Epoch 977/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0527 - accuracy: 0.5530 - val_loss: 1.0217 - val_accuracy: 0.5538\n",
      "Epoch 978/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0558 - accuracy: 0.5439 - val_loss: 1.0313 - val_accuracy: 0.5510\n",
      "Epoch 979/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0501 - accuracy: 0.5542 - val_loss: 1.0345 - val_accuracy: 0.5519\n",
      "Epoch 980/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0614 - accuracy: 0.5389 - val_loss: 1.0261 - val_accuracy: 0.5615\n",
      "Epoch 981/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0522 - accuracy: 0.5429 - val_loss: 1.0252 - val_accuracy: 0.5558\n",
      "Epoch 982/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0510 - accuracy: 0.5523 - val_loss: 1.0260 - val_accuracy: 0.5663\n",
      "Epoch 983/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0610 - accuracy: 0.5533 - val_loss: 1.0119 - val_accuracy: 0.5625\n",
      "Epoch 984/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0559 - accuracy: 0.5420 - val_loss: 1.0156 - val_accuracy: 0.5606\n",
      "Epoch 985/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0494 - accuracy: 0.5509 - val_loss: 1.0250 - val_accuracy: 0.5596\n",
      "Epoch 986/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0501 - accuracy: 0.5453 - val_loss: 1.0207 - val_accuracy: 0.5683\n",
      "Epoch 987/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0454 - accuracy: 0.5494 - val_loss: 1.0188 - val_accuracy: 0.5548\n",
      "Epoch 988/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0567 - accuracy: 0.5413 - val_loss: 1.0238 - val_accuracy: 0.5500\n",
      "Epoch 989/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0539 - accuracy: 0.5410 - val_loss: 1.0224 - val_accuracy: 0.5712\n",
      "Epoch 990/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0503 - accuracy: 0.5427 - val_loss: 1.0234 - val_accuracy: 0.5663\n",
      "Epoch 991/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0531 - accuracy: 0.5557 - val_loss: 1.0183 - val_accuracy: 0.5702\n",
      "Epoch 992/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0515 - accuracy: 0.5499 - val_loss: 1.0204 - val_accuracy: 0.5625\n",
      "Epoch 993/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0560 - accuracy: 0.5415 - val_loss: 1.0163 - val_accuracy: 0.5538\n",
      "Epoch 994/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0535 - accuracy: 0.5463 - val_loss: 1.0202 - val_accuracy: 0.5548\n",
      "Epoch 995/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0519 - accuracy: 0.5458 - val_loss: 1.0229 - val_accuracy: 0.5644\n",
      "Epoch 996/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0527 - accuracy: 0.5521 - val_loss: 1.0246 - val_accuracy: 0.5567\n",
      "Epoch 997/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0510 - accuracy: 0.5482 - val_loss: 1.0270 - val_accuracy: 0.5510\n",
      "Epoch 998/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0469 - accuracy: 0.5521 - val_loss: 1.0308 - val_accuracy: 0.5529\n",
      "Epoch 999/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0509 - accuracy: 0.5487 - val_loss: 1.0210 - val_accuracy: 0.5625\n",
      "Epoch 1000/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0515 - accuracy: 0.5516 - val_loss: 1.0227 - val_accuracy: 0.5625\n",
      "Epoch 1001/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0532 - accuracy: 0.5480 - val_loss: 1.0232 - val_accuracy: 0.5625\n",
      "Epoch 1002/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0507 - accuracy: 0.5482 - val_loss: 1.0144 - val_accuracy: 0.5615\n",
      "Epoch 1003/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0468 - accuracy: 0.5518 - val_loss: 1.0122 - val_accuracy: 0.5692\n",
      "Epoch 1004/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0509 - accuracy: 0.5502 - val_loss: 1.0105 - val_accuracy: 0.5606\n",
      "Epoch 1005/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0470 - accuracy: 0.5465 - val_loss: 1.0116 - val_accuracy: 0.5788\n",
      "Epoch 1006/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0449 - accuracy: 0.5468 - val_loss: 1.0182 - val_accuracy: 0.5510\n",
      "Epoch 1007/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0465 - accuracy: 0.5463 - val_loss: 1.0188 - val_accuracy: 0.5663\n",
      "Epoch 1008/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0559 - accuracy: 0.5429 - val_loss: 1.0252 - val_accuracy: 0.5587\n",
      "Epoch 1009/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0527 - accuracy: 0.5514 - val_loss: 1.0212 - val_accuracy: 0.5510\n",
      "Epoch 1010/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0513 - accuracy: 0.5420 - val_loss: 1.0118 - val_accuracy: 0.5673\n",
      "Epoch 1011/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0501 - accuracy: 0.5458 - val_loss: 1.0185 - val_accuracy: 0.5625\n",
      "Epoch 1012/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0549 - accuracy: 0.5468 - val_loss: 1.0292 - val_accuracy: 0.5548\n",
      "Epoch 1013/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0514 - accuracy: 0.5509 - val_loss: 1.0198 - val_accuracy: 0.5587\n",
      "Epoch 1014/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0448 - accuracy: 0.5571 - val_loss: 1.0206 - val_accuracy: 0.5760\n",
      "Epoch 1015/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0494 - accuracy: 0.5461 - val_loss: 1.0236 - val_accuracy: 0.5596\n",
      "Epoch 1016/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0578 - accuracy: 0.5427 - val_loss: 1.0158 - val_accuracy: 0.5596\n",
      "Epoch 1017/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0545 - accuracy: 0.5441 - val_loss: 1.0144 - val_accuracy: 0.5644\n",
      "Epoch 1018/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0496 - accuracy: 0.5499 - val_loss: 1.0198 - val_accuracy: 0.5519\n",
      "Epoch 1019/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0477 - accuracy: 0.5516 - val_loss: 1.0202 - val_accuracy: 0.5606\n",
      "Epoch 1020/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0471 - accuracy: 0.5429 - val_loss: 1.0236 - val_accuracy: 0.5683\n",
      "Epoch 1021/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0498 - accuracy: 0.5521 - val_loss: 1.0203 - val_accuracy: 0.5625\n",
      "Epoch 1022/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0544 - accuracy: 0.5499 - val_loss: 1.0281 - val_accuracy: 0.5462\n",
      "Epoch 1023/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0499 - accuracy: 0.5403 - val_loss: 1.0194 - val_accuracy: 0.5635\n",
      "Epoch 1024/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0447 - accuracy: 0.5504 - val_loss: 1.0169 - val_accuracy: 0.5654\n",
      "Epoch 1025/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0417 - accuracy: 0.5509 - val_loss: 1.0224 - val_accuracy: 0.5635\n",
      "Epoch 1026/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0442 - accuracy: 0.5502 - val_loss: 1.0189 - val_accuracy: 0.5577\n",
      "Epoch 1027/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0513 - accuracy: 0.5502 - val_loss: 1.0201 - val_accuracy: 0.5683\n",
      "Epoch 1028/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0511 - accuracy: 0.5545 - val_loss: 1.0244 - val_accuracy: 0.5538\n",
      "Epoch 1029/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0496 - accuracy: 0.5449 - val_loss: 1.0204 - val_accuracy: 0.5587\n",
      "Epoch 1030/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0506 - accuracy: 0.5463 - val_loss: 1.0221 - val_accuracy: 0.5500\n",
      "Epoch 1031/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0492 - accuracy: 0.5554 - val_loss: 1.0267 - val_accuracy: 0.5558\n",
      "Epoch 1032/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0529 - accuracy: 0.5451 - val_loss: 1.0263 - val_accuracy: 0.5625\n",
      "Epoch 1033/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0447 - accuracy: 0.5446 - val_loss: 1.0252 - val_accuracy: 0.5625\n",
      "Epoch 1034/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0502 - accuracy: 0.5497 - val_loss: 1.0167 - val_accuracy: 0.5615\n",
      "Epoch 1035/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0478 - accuracy: 0.5504 - val_loss: 1.0165 - val_accuracy: 0.5731\n",
      "Epoch 1036/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0471 - accuracy: 0.5511 - val_loss: 1.0217 - val_accuracy: 0.5721\n",
      "Epoch 1037/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0481 - accuracy: 0.5461 - val_loss: 1.0193 - val_accuracy: 0.5673\n",
      "Epoch 1038/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0484 - accuracy: 0.5465 - val_loss: 1.0188 - val_accuracy: 0.5721\n",
      "Epoch 1039/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0509 - accuracy: 0.5437 - val_loss: 1.0232 - val_accuracy: 0.5606\n",
      "Epoch 1040/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0454 - accuracy: 0.5509 - val_loss: 1.0160 - val_accuracy: 0.5692\n",
      "Epoch 1041/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0475 - accuracy: 0.5461 - val_loss: 1.0180 - val_accuracy: 0.5558\n",
      "Epoch 1042/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0482 - accuracy: 0.5528 - val_loss: 1.0241 - val_accuracy: 0.5635\n",
      "Epoch 1043/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0451 - accuracy: 0.5463 - val_loss: 1.0205 - val_accuracy: 0.5712\n",
      "Epoch 1044/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0440 - accuracy: 0.5458 - val_loss: 1.0132 - val_accuracy: 0.5663\n",
      "Epoch 1045/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0450 - accuracy: 0.5449 - val_loss: 1.0204 - val_accuracy: 0.5635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1046/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0411 - accuracy: 0.5487 - val_loss: 1.0178 - val_accuracy: 0.5615\n",
      "Epoch 1047/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0464 - accuracy: 0.5492 - val_loss: 1.0309 - val_accuracy: 0.5490\n",
      "Epoch 1048/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0425 - accuracy: 0.5499 - val_loss: 1.0200 - val_accuracy: 0.5615\n",
      "Epoch 1049/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0502 - accuracy: 0.5432 - val_loss: 1.0206 - val_accuracy: 0.5683\n",
      "Epoch 1050/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0425 - accuracy: 0.5535 - val_loss: 1.0317 - val_accuracy: 0.5615\n",
      "Epoch 1051/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0466 - accuracy: 0.5504 - val_loss: 1.0179 - val_accuracy: 0.5692\n",
      "Epoch 1052/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0430 - accuracy: 0.5494 - val_loss: 1.0233 - val_accuracy: 0.5721\n",
      "Epoch 1053/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0505 - accuracy: 0.5451 - val_loss: 1.0233 - val_accuracy: 0.5587\n",
      "Epoch 1054/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0494 - accuracy: 0.5504 - val_loss: 1.0316 - val_accuracy: 0.5577\n",
      "Epoch 1055/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0506 - accuracy: 0.5511 - val_loss: 1.0203 - val_accuracy: 0.5635\n",
      "Epoch 1056/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0471 - accuracy: 0.5475 - val_loss: 1.0293 - val_accuracy: 0.5596\n",
      "Epoch 1057/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0499 - accuracy: 0.5463 - val_loss: 1.0328 - val_accuracy: 0.5740\n",
      "Epoch 1058/1500\n",
      "4157/4157 [==============================] - 0s 38us/step - loss: 1.0525 - accuracy: 0.5465 - val_loss: 1.0314 - val_accuracy: 0.5673\n",
      "Epoch 1059/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0440 - accuracy: 0.5550 - val_loss: 1.0272 - val_accuracy: 0.5606\n",
      "Epoch 1060/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0480 - accuracy: 0.5494 - val_loss: 1.0353 - val_accuracy: 0.5606\n",
      "Epoch 1061/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0494 - accuracy: 0.5499 - val_loss: 1.0250 - val_accuracy: 0.5692\n",
      "Epoch 1062/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0421 - accuracy: 0.5591 - val_loss: 1.0380 - val_accuracy: 0.5587\n",
      "Epoch 1063/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0466 - accuracy: 0.5465 - val_loss: 1.0288 - val_accuracy: 0.5654\n",
      "Epoch 1064/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0505 - accuracy: 0.5494 - val_loss: 1.0254 - val_accuracy: 0.5654\n",
      "Epoch 1065/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0441 - accuracy: 0.5545 - val_loss: 1.0230 - val_accuracy: 0.5673\n",
      "Epoch 1066/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0490 - accuracy: 0.5499 - val_loss: 1.0258 - val_accuracy: 0.5635\n",
      "Epoch 1067/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0433 - accuracy: 0.5547 - val_loss: 1.0200 - val_accuracy: 0.5615\n",
      "Epoch 1068/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0421 - accuracy: 0.5499 - val_loss: 1.0263 - val_accuracy: 0.5625\n",
      "Epoch 1069/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0460 - accuracy: 0.5463 - val_loss: 1.0285 - val_accuracy: 0.5731\n",
      "Epoch 1070/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0515 - accuracy: 0.5444 - val_loss: 1.0278 - val_accuracy: 0.5644\n",
      "Epoch 1071/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0486 - accuracy: 0.5468 - val_loss: 1.0352 - val_accuracy: 0.5519\n",
      "Epoch 1072/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0433 - accuracy: 0.5478 - val_loss: 1.0300 - val_accuracy: 0.5692\n",
      "Epoch 1073/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0440 - accuracy: 0.5504 - val_loss: 1.0326 - val_accuracy: 0.5606\n",
      "Epoch 1074/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0440 - accuracy: 0.5559 - val_loss: 1.0254 - val_accuracy: 0.5644\n",
      "Epoch 1075/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0454 - accuracy: 0.5511 - val_loss: 1.0385 - val_accuracy: 0.5635\n",
      "Epoch 1076/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0494 - accuracy: 0.5490 - val_loss: 1.0248 - val_accuracy: 0.5615\n",
      "Epoch 1077/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0445 - accuracy: 0.5468 - val_loss: 1.0310 - val_accuracy: 0.5673\n",
      "Epoch 1078/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0458 - accuracy: 0.5482 - val_loss: 1.0285 - val_accuracy: 0.5606\n",
      "Epoch 1079/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0426 - accuracy: 0.5475 - val_loss: 1.0292 - val_accuracy: 0.5567\n",
      "Epoch 1080/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0407 - accuracy: 0.5530 - val_loss: 1.0242 - val_accuracy: 0.5635\n",
      "Epoch 1081/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0381 - accuracy: 0.5506 - val_loss: 1.0232 - val_accuracy: 0.5635\n",
      "Epoch 1082/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0426 - accuracy: 0.5506 - val_loss: 1.0360 - val_accuracy: 0.5606\n",
      "Epoch 1083/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0426 - accuracy: 0.5487 - val_loss: 1.0233 - val_accuracy: 0.5654\n",
      "Epoch 1084/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0415 - accuracy: 0.5494 - val_loss: 1.0240 - val_accuracy: 0.5692\n",
      "Epoch 1085/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0483 - accuracy: 0.5506 - val_loss: 1.0209 - val_accuracy: 0.5673\n",
      "Epoch 1086/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0391 - accuracy: 0.5538 - val_loss: 1.0163 - val_accuracy: 0.5606\n",
      "Epoch 1087/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0452 - accuracy: 0.5545 - val_loss: 1.0192 - val_accuracy: 0.5663\n",
      "Epoch 1088/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0462 - accuracy: 0.5485 - val_loss: 1.0262 - val_accuracy: 0.5663\n",
      "Epoch 1089/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0432 - accuracy: 0.5502 - val_loss: 1.0265 - val_accuracy: 0.5721\n",
      "Epoch 1090/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0423 - accuracy: 0.5487 - val_loss: 1.0298 - val_accuracy: 0.5692\n",
      "Epoch 1091/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0440 - accuracy: 0.5521 - val_loss: 1.0200 - val_accuracy: 0.5663\n",
      "Epoch 1092/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0454 - accuracy: 0.5441 - val_loss: 1.0203 - val_accuracy: 0.5673\n",
      "Epoch 1093/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0480 - accuracy: 0.5482 - val_loss: 1.0238 - val_accuracy: 0.5635\n",
      "Epoch 1094/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0454 - accuracy: 0.5506 - val_loss: 1.0232 - val_accuracy: 0.5712\n",
      "Epoch 1095/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0431 - accuracy: 0.5574 - val_loss: 1.0217 - val_accuracy: 0.5721\n",
      "Epoch 1096/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0411 - accuracy: 0.5511 - val_loss: 1.0123 - val_accuracy: 0.5740\n",
      "Epoch 1097/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0441 - accuracy: 0.5518 - val_loss: 1.0201 - val_accuracy: 0.5673\n",
      "Epoch 1098/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0463 - accuracy: 0.5420 - val_loss: 1.0170 - val_accuracy: 0.5673\n",
      "Epoch 1099/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0478 - accuracy: 0.5499 - val_loss: 1.0228 - val_accuracy: 0.5673\n",
      "Epoch 1100/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0392 - accuracy: 0.5547 - val_loss: 1.0162 - val_accuracy: 0.5587\n",
      "Epoch 1101/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0466 - accuracy: 0.5478 - val_loss: 1.0112 - val_accuracy: 0.5712\n",
      "Epoch 1102/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0424 - accuracy: 0.5461 - val_loss: 1.0146 - val_accuracy: 0.5663\n",
      "Epoch 1103/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0421 - accuracy: 0.5429 - val_loss: 1.0159 - val_accuracy: 0.5644\n",
      "Epoch 1104/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0448 - accuracy: 0.5425 - val_loss: 1.0243 - val_accuracy: 0.5615\n",
      "Epoch 1105/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0411 - accuracy: 0.5470 - val_loss: 1.0220 - val_accuracy: 0.5654\n",
      "Epoch 1106/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0445 - accuracy: 0.5429 - val_loss: 1.0164 - val_accuracy: 0.5692\n",
      "Epoch 1107/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0408 - accuracy: 0.5540 - val_loss: 1.0248 - val_accuracy: 0.5625\n",
      "Epoch 1108/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0408 - accuracy: 0.5490 - val_loss: 1.0208 - val_accuracy: 0.5635\n",
      "Epoch 1109/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0404 - accuracy: 0.5557 - val_loss: 1.0296 - val_accuracy: 0.5702\n",
      "Epoch 1110/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0465 - accuracy: 0.5480 - val_loss: 1.0178 - val_accuracy: 0.5760\n",
      "Epoch 1111/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0410 - accuracy: 0.5490 - val_loss: 1.0361 - val_accuracy: 0.5635\n",
      "Epoch 1112/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0428 - accuracy: 0.5434 - val_loss: 1.0261 - val_accuracy: 0.5702\n",
      "Epoch 1113/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0445 - accuracy: 0.5482 - val_loss: 1.0341 - val_accuracy: 0.5712\n",
      "Epoch 1114/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0356 - accuracy: 0.5574 - val_loss: 1.0331 - val_accuracy: 0.5654\n",
      "Epoch 1115/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0372 - accuracy: 0.5542 - val_loss: 1.0310 - val_accuracy: 0.5644\n",
      "Epoch 1116/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0473 - accuracy: 0.5588 - val_loss: 1.0183 - val_accuracy: 0.5654\n",
      "Epoch 1117/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0471 - accuracy: 0.5514 - val_loss: 1.0181 - val_accuracy: 0.5683\n",
      "Epoch 1118/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0399 - accuracy: 0.5550 - val_loss: 1.0249 - val_accuracy: 0.5712\n",
      "Epoch 1119/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0428 - accuracy: 0.5504 - val_loss: 1.0290 - val_accuracy: 0.5606\n",
      "Epoch 1120/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0469 - accuracy: 0.5427 - val_loss: 1.0427 - val_accuracy: 0.5577\n",
      "Epoch 1121/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0481 - accuracy: 0.5502 - val_loss: 1.0263 - val_accuracy: 0.5606\n",
      "Epoch 1122/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0417 - accuracy: 0.5564 - val_loss: 1.0212 - val_accuracy: 0.5587\n",
      "Epoch 1123/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0423 - accuracy: 0.5514 - val_loss: 1.0216 - val_accuracy: 0.5673\n",
      "Epoch 1124/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0432 - accuracy: 0.5480 - val_loss: 1.0269 - val_accuracy: 0.5663\n",
      "Epoch 1125/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0497 - accuracy: 0.5502 - val_loss: 1.0360 - val_accuracy: 0.5702\n",
      "Epoch 1126/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0384 - accuracy: 0.5509 - val_loss: 1.0343 - val_accuracy: 0.5596\n",
      "Epoch 1127/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0457 - accuracy: 0.5413 - val_loss: 1.0181 - val_accuracy: 0.5673\n",
      "Epoch 1128/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0451 - accuracy: 0.5482 - val_loss: 1.0205 - val_accuracy: 0.5683\n",
      "Epoch 1129/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0441 - accuracy: 0.5518 - val_loss: 1.0179 - val_accuracy: 0.5673\n",
      "Epoch 1130/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0461 - accuracy: 0.5458 - val_loss: 1.0134 - val_accuracy: 0.5663\n",
      "Epoch 1131/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0418 - accuracy: 0.5511 - val_loss: 1.0237 - val_accuracy: 0.5644\n",
      "Epoch 1132/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0429 - accuracy: 0.5504 - val_loss: 1.0263 - val_accuracy: 0.5654\n",
      "Epoch 1133/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0352 - accuracy: 0.5475 - val_loss: 1.0256 - val_accuracy: 0.5663\n",
      "Epoch 1134/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0328 - accuracy: 0.5571 - val_loss: 1.0328 - val_accuracy: 0.5625\n",
      "Epoch 1135/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0425 - accuracy: 0.5511 - val_loss: 1.0199 - val_accuracy: 0.5673\n",
      "Epoch 1136/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0433 - accuracy: 0.5559 - val_loss: 1.0224 - val_accuracy: 0.5692\n",
      "Epoch 1137/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0390 - accuracy: 0.5473 - val_loss: 1.0129 - val_accuracy: 0.5721\n",
      "Epoch 1138/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0442 - accuracy: 0.5545 - val_loss: 1.0173 - val_accuracy: 0.5750\n",
      "Epoch 1139/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0425 - accuracy: 0.5540 - val_loss: 1.0215 - val_accuracy: 0.5702\n",
      "Epoch 1140/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0433 - accuracy: 0.5523 - val_loss: 1.0205 - val_accuracy: 0.5683\n",
      "Epoch 1141/1500\n",
      "4157/4157 [==============================] - 0s 41us/step - loss: 1.0392 - accuracy: 0.5559 - val_loss: 1.0186 - val_accuracy: 0.5673\n",
      "Epoch 1142/1500\n",
      "4157/4157 [==============================] - 0s 49us/step - loss: 1.0393 - accuracy: 0.5518 - val_loss: 1.0320 - val_accuracy: 0.5615\n",
      "Epoch 1143/1500\n",
      "4157/4157 [==============================] - 0s 43us/step - loss: 1.0414 - accuracy: 0.5506 - val_loss: 1.0284 - val_accuracy: 0.5712\n",
      "Epoch 1144/1500\n",
      "4157/4157 [==============================] - 0s 46us/step - loss: 1.0456 - accuracy: 0.5473 - val_loss: 1.0230 - val_accuracy: 0.5712\n",
      "Epoch 1145/1500\n",
      "4157/4157 [==============================] - 0s 53us/step - loss: 1.0436 - accuracy: 0.5547 - val_loss: 1.0327 - val_accuracy: 0.5663\n",
      "Epoch 1146/1500\n",
      "4157/4157 [==============================] - 0s 38us/step - loss: 1.0416 - accuracy: 0.5533 - val_loss: 1.0244 - val_accuracy: 0.5663\n",
      "Epoch 1147/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0385 - accuracy: 0.5439 - val_loss: 1.0367 - val_accuracy: 0.5587\n",
      "Epoch 1148/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0401 - accuracy: 0.5562 - val_loss: 1.0190 - val_accuracy: 0.5673\n",
      "Epoch 1149/1500\n",
      "4157/4157 [==============================] - 0s 47us/step - loss: 1.0348 - accuracy: 0.5559 - val_loss: 1.0260 - val_accuracy: 0.5683\n",
      "Epoch 1150/1500\n",
      "4157/4157 [==============================] - 0s 54us/step - loss: 1.0428 - accuracy: 0.5579 - val_loss: 1.0251 - val_accuracy: 0.5635\n",
      "Epoch 1151/1500\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 1.0429 - accuracy: 0.54 - 0s 44us/step - loss: 1.0429 - accuracy: 0.5518 - val_loss: 1.0298 - val_accuracy: 0.5712\n",
      "Epoch 1152/1500\n",
      "4157/4157 [==============================] - 0s 48us/step - loss: 1.0426 - accuracy: 0.5550 - val_loss: 1.0194 - val_accuracy: 0.5625\n",
      "Epoch 1153/1500\n",
      "4157/4157 [==============================] - 0s 53us/step - loss: 1.0434 - accuracy: 0.5509 - val_loss: 1.0170 - val_accuracy: 0.5740\n",
      "Epoch 1154/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 37us/step - loss: 1.0415 - accuracy: 0.5502 - val_loss: 1.0221 - val_accuracy: 0.5760\n",
      "Epoch 1155/1500\n",
      "4157/4157 [==============================] - 0s 37us/step - loss: 1.0379 - accuracy: 0.5651 - val_loss: 1.0251 - val_accuracy: 0.5615\n",
      "Epoch 1156/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0367 - accuracy: 0.5579 - val_loss: 1.0308 - val_accuracy: 0.5654\n",
      "Epoch 1157/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0422 - accuracy: 0.5485 - val_loss: 1.0285 - val_accuracy: 0.5673\n",
      "Epoch 1158/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0373 - accuracy: 0.5540 - val_loss: 1.0291 - val_accuracy: 0.5673\n",
      "Epoch 1159/1500\n",
      "4157/4157 [==============================] - 0s 40us/step - loss: 1.0386 - accuracy: 0.5603 - val_loss: 1.0282 - val_accuracy: 0.5712\n",
      "Epoch 1160/1500\n",
      "4157/4157 [==============================] - 0s 37us/step - loss: 1.0389 - accuracy: 0.5535 - val_loss: 1.0270 - val_accuracy: 0.5702\n",
      "Epoch 1161/1500\n",
      "4157/4157 [==============================] - 0s 43us/step - loss: 1.0413 - accuracy: 0.5487 - val_loss: 1.0299 - val_accuracy: 0.5673\n",
      "Epoch 1162/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0505 - accuracy: 0.5422 - val_loss: 1.0326 - val_accuracy: 0.5615\n",
      "Epoch 1163/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0417 - accuracy: 0.5516 - val_loss: 1.0311 - val_accuracy: 0.5654\n",
      "Epoch 1164/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0394 - accuracy: 0.5571 - val_loss: 1.0313 - val_accuracy: 0.5654\n",
      "Epoch 1165/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0434 - accuracy: 0.5535 - val_loss: 1.0320 - val_accuracy: 0.5731\n",
      "Epoch 1166/1500\n",
      "4157/4157 [==============================] - 0s 37us/step - loss: 1.0391 - accuracy: 0.5504 - val_loss: 1.0265 - val_accuracy: 0.5644\n",
      "Epoch 1167/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0414 - accuracy: 0.5475 - val_loss: 1.0309 - val_accuracy: 0.5644\n",
      "Epoch 1168/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0395 - accuracy: 0.5521 - val_loss: 1.0306 - val_accuracy: 0.5644\n",
      "Epoch 1169/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0413 - accuracy: 0.5526 - val_loss: 1.0245 - val_accuracy: 0.5635\n",
      "Epoch 1170/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5509 - val_loss: 1.0228 - val_accuracy: 0.5692\n",
      "Epoch 1171/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0402 - accuracy: 0.5528 - val_loss: 1.0301 - val_accuracy: 0.5644\n",
      "Epoch 1172/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0368 - accuracy: 0.5530 - val_loss: 1.0251 - val_accuracy: 0.5683\n",
      "Epoch 1173/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0371 - accuracy: 0.5557 - val_loss: 1.0290 - val_accuracy: 0.5663\n",
      "Epoch 1174/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0421 - accuracy: 0.5518 - val_loss: 1.0259 - val_accuracy: 0.5644\n",
      "Epoch 1175/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0353 - accuracy: 0.5480 - val_loss: 1.0321 - val_accuracy: 0.5663\n",
      "Epoch 1176/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0384 - accuracy: 0.5509 - val_loss: 1.0251 - val_accuracy: 0.5644\n",
      "Epoch 1177/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0336 - accuracy: 0.5545 - val_loss: 1.0279 - val_accuracy: 0.5692\n",
      "Epoch 1178/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0382 - accuracy: 0.5468 - val_loss: 1.0320 - val_accuracy: 0.5654\n",
      "Epoch 1179/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0411 - accuracy: 0.5509 - val_loss: 1.0331 - val_accuracy: 0.5721\n",
      "Epoch 1180/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0381 - accuracy: 0.5552 - val_loss: 1.0340 - val_accuracy: 0.5721\n",
      "Epoch 1181/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0382 - accuracy: 0.5451 - val_loss: 1.0321 - val_accuracy: 0.5625\n",
      "Epoch 1182/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0382 - accuracy: 0.5579 - val_loss: 1.0392 - val_accuracy: 0.5558\n",
      "Epoch 1183/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0422 - accuracy: 0.5465 - val_loss: 1.0300 - val_accuracy: 0.5654\n",
      "Epoch 1184/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0375 - accuracy: 0.5514 - val_loss: 1.0340 - val_accuracy: 0.5635\n",
      "Epoch 1185/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0391 - accuracy: 0.5468 - val_loss: 1.0334 - val_accuracy: 0.5596\n",
      "Epoch 1186/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0354 - accuracy: 0.5530 - val_loss: 1.0360 - val_accuracy: 0.5702\n",
      "Epoch 1187/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0371 - accuracy: 0.5557 - val_loss: 1.0318 - val_accuracy: 0.5644\n",
      "Epoch 1188/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0398 - accuracy: 0.5480 - val_loss: 1.0336 - val_accuracy: 0.5712\n",
      "Epoch 1189/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0386 - accuracy: 0.5463 - val_loss: 1.0368 - val_accuracy: 0.5625\n",
      "Epoch 1190/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0345 - accuracy: 0.5545 - val_loss: 1.0297 - val_accuracy: 0.5577\n",
      "Epoch 1191/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0349 - accuracy: 0.5494 - val_loss: 1.0352 - val_accuracy: 0.5625\n",
      "Epoch 1192/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0368 - accuracy: 0.5521 - val_loss: 1.0414 - val_accuracy: 0.5548\n",
      "Epoch 1193/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0427 - accuracy: 0.5550 - val_loss: 1.0227 - val_accuracy: 0.5663\n",
      "Epoch 1194/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0372 - accuracy: 0.5499 - val_loss: 1.0280 - val_accuracy: 0.5663\n",
      "Epoch 1195/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0402 - accuracy: 0.5514 - val_loss: 1.0396 - val_accuracy: 0.5683\n",
      "Epoch 1196/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0346 - accuracy: 0.5535 - val_loss: 1.0396 - val_accuracy: 0.5558\n",
      "Epoch 1197/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0355 - accuracy: 0.5564 - val_loss: 1.0335 - val_accuracy: 0.5654\n",
      "Epoch 1198/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0403 - accuracy: 0.5576 - val_loss: 1.0224 - val_accuracy: 0.5644\n",
      "Epoch 1199/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0323 - accuracy: 0.5540 - val_loss: 1.0284 - val_accuracy: 0.5683\n",
      "Epoch 1200/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0334 - accuracy: 0.5571 - val_loss: 1.0308 - val_accuracy: 0.5654\n",
      "Epoch 1201/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0361 - accuracy: 0.5557 - val_loss: 1.0245 - val_accuracy: 0.5596\n",
      "Epoch 1202/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0363 - accuracy: 0.5509 - val_loss: 1.0235 - val_accuracy: 0.5673\n",
      "Epoch 1203/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0411 - accuracy: 0.5554 - val_loss: 1.0298 - val_accuracy: 0.5644\n",
      "Epoch 1204/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0346 - accuracy: 0.5499 - val_loss: 1.0325 - val_accuracy: 0.5692\n",
      "Epoch 1205/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0370 - accuracy: 0.5499 - val_loss: 1.0242 - val_accuracy: 0.5625\n",
      "Epoch 1206/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0380 - accuracy: 0.5550 - val_loss: 1.0292 - val_accuracy: 0.5702\n",
      "Epoch 1207/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0426 - accuracy: 0.5449 - val_loss: 1.0210 - val_accuracy: 0.5712\n",
      "Epoch 1208/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0360 - accuracy: 0.5463 - val_loss: 1.0246 - val_accuracy: 0.5731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1209/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0319 - accuracy: 0.5499 - val_loss: 1.0309 - val_accuracy: 0.5567\n",
      "Epoch 1210/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0394 - accuracy: 0.5490 - val_loss: 1.0180 - val_accuracy: 0.5769\n",
      "Epoch 1211/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0317 - accuracy: 0.5516 - val_loss: 1.0309 - val_accuracy: 0.5673\n",
      "Epoch 1212/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0471 - accuracy: 0.5499 - val_loss: 1.0260 - val_accuracy: 0.5740\n",
      "Epoch 1213/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0358 - accuracy: 0.5528 - val_loss: 1.0252 - val_accuracy: 0.5692\n",
      "Epoch 1214/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0398 - accuracy: 0.5453 - val_loss: 1.0307 - val_accuracy: 0.5760\n",
      "Epoch 1215/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0390 - accuracy: 0.5569 - val_loss: 1.0247 - val_accuracy: 0.5673\n",
      "Epoch 1216/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0324 - accuracy: 0.5521 - val_loss: 1.0244 - val_accuracy: 0.5750\n",
      "Epoch 1217/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0397 - accuracy: 0.5499 - val_loss: 1.0233 - val_accuracy: 0.5712\n",
      "Epoch 1218/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0368 - accuracy: 0.5533 - val_loss: 1.0306 - val_accuracy: 0.5663\n",
      "Epoch 1219/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0350 - accuracy: 0.5504 - val_loss: 1.0282 - val_accuracy: 0.5712\n",
      "Epoch 1220/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0307 - accuracy: 0.5509 - val_loss: 1.0190 - val_accuracy: 0.5702\n",
      "Epoch 1221/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0341 - accuracy: 0.5622 - val_loss: 1.0212 - val_accuracy: 0.5625\n",
      "Epoch 1222/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0378 - accuracy: 0.5542 - val_loss: 1.0294 - val_accuracy: 0.5712\n",
      "Epoch 1223/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0376 - accuracy: 0.5461 - val_loss: 1.0286 - val_accuracy: 0.5654\n",
      "Epoch 1224/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0314 - accuracy: 0.5511 - val_loss: 1.0277 - val_accuracy: 0.5769\n",
      "Epoch 1225/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0380 - accuracy: 0.5516 - val_loss: 1.0260 - val_accuracy: 0.5798\n",
      "Epoch 1226/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0391 - accuracy: 0.5509 - val_loss: 1.0244 - val_accuracy: 0.5750\n",
      "Epoch 1227/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0406 - accuracy: 0.5463 - val_loss: 1.0298 - val_accuracy: 0.5808\n",
      "Epoch 1228/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0426 - accuracy: 0.5518 - val_loss: 1.0337 - val_accuracy: 0.5644\n",
      "Epoch 1229/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0344 - accuracy: 0.5502 - val_loss: 1.0298 - val_accuracy: 0.5788\n",
      "Epoch 1230/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0351 - accuracy: 0.5571 - val_loss: 1.0294 - val_accuracy: 0.5635\n",
      "Epoch 1231/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0352 - accuracy: 0.5547 - val_loss: 1.0273 - val_accuracy: 0.5644\n",
      "Epoch 1232/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5567 - val_loss: 1.0321 - val_accuracy: 0.5567\n",
      "Epoch 1233/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0372 - accuracy: 0.5516 - val_loss: 1.0322 - val_accuracy: 0.5654\n",
      "Epoch 1234/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0357 - accuracy: 0.5557 - val_loss: 1.0368 - val_accuracy: 0.5644\n",
      "Epoch 1235/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0322 - accuracy: 0.5607 - val_loss: 1.0382 - val_accuracy: 0.5577\n",
      "Epoch 1236/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0410 - accuracy: 0.5478 - val_loss: 1.0481 - val_accuracy: 0.5615\n",
      "Epoch 1237/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0331 - accuracy: 0.5591 - val_loss: 1.0312 - val_accuracy: 0.5635\n",
      "Epoch 1238/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0399 - accuracy: 0.5538 - val_loss: 1.0280 - val_accuracy: 0.5683\n",
      "Epoch 1239/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0313 - accuracy: 0.5511 - val_loss: 1.0288 - val_accuracy: 0.5721\n",
      "Epoch 1240/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0329 - accuracy: 0.5571 - val_loss: 1.0246 - val_accuracy: 0.5798\n",
      "Epoch 1241/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0317 - accuracy: 0.5547 - val_loss: 1.0295 - val_accuracy: 0.5750\n",
      "Epoch 1242/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0335 - accuracy: 0.5528 - val_loss: 1.0241 - val_accuracy: 0.5740\n",
      "Epoch 1243/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0344 - accuracy: 0.5610 - val_loss: 1.0294 - val_accuracy: 0.5750\n",
      "Epoch 1244/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0348 - accuracy: 0.5591 - val_loss: 1.0302 - val_accuracy: 0.5740\n",
      "Epoch 1245/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0310 - accuracy: 0.5473 - val_loss: 1.0264 - val_accuracy: 0.5692\n",
      "Epoch 1246/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0391 - accuracy: 0.5533 - val_loss: 1.0154 - val_accuracy: 0.5692\n",
      "Epoch 1247/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0327 - accuracy: 0.5490 - val_loss: 1.0261 - val_accuracy: 0.5673\n",
      "Epoch 1248/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0379 - accuracy: 0.5509 - val_loss: 1.0258 - val_accuracy: 0.5712\n",
      "Epoch 1249/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0336 - accuracy: 0.5622 - val_loss: 1.0317 - val_accuracy: 0.5673\n",
      "Epoch 1250/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0403 - accuracy: 0.5526 - val_loss: 1.0229 - val_accuracy: 0.5731\n",
      "Epoch 1251/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0338 - accuracy: 0.5478 - val_loss: 1.0201 - val_accuracy: 0.5779\n",
      "Epoch 1252/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0395 - accuracy: 0.5468 - val_loss: 1.0264 - val_accuracy: 0.5769\n",
      "Epoch 1253/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0371 - accuracy: 0.5514 - val_loss: 1.0230 - val_accuracy: 0.5721\n",
      "Epoch 1254/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0348 - accuracy: 0.5542 - val_loss: 1.0281 - val_accuracy: 0.5750\n",
      "Epoch 1255/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0348 - accuracy: 0.5554 - val_loss: 1.0230 - val_accuracy: 0.5663\n",
      "Epoch 1256/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0316 - accuracy: 0.5562 - val_loss: 1.0289 - val_accuracy: 0.5740\n",
      "Epoch 1257/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0277 - accuracy: 0.5579 - val_loss: 1.0272 - val_accuracy: 0.5644\n",
      "Epoch 1258/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0315 - accuracy: 0.5487 - val_loss: 1.0306 - val_accuracy: 0.5750\n",
      "Epoch 1259/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0352 - accuracy: 0.5540 - val_loss: 1.0202 - val_accuracy: 0.5740\n",
      "Epoch 1260/1500\n",
      "4157/4157 [==============================] - 0s 43us/step - loss: 1.0398 - accuracy: 0.5465 - val_loss: 1.0272 - val_accuracy: 0.5702\n",
      "Epoch 1261/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0317 - accuracy: 0.5624 - val_loss: 1.0277 - val_accuracy: 0.5798\n",
      "Epoch 1262/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0284 - accuracy: 0.5449 - val_loss: 1.0208 - val_accuracy: 0.5731\n",
      "Epoch 1263/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0307 - accuracy: 0.5530 - val_loss: 1.0227 - val_accuracy: 0.5683\n",
      "Epoch 1264/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0400 - accuracy: 0.5545 - val_loss: 1.0215 - val_accuracy: 0.5731\n",
      "Epoch 1265/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0336 - accuracy: 0.5504 - val_loss: 1.0236 - val_accuracy: 0.5683\n",
      "Epoch 1266/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5516 - val_loss: 1.0180 - val_accuracy: 0.5663\n",
      "Epoch 1267/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0374 - accuracy: 0.5463 - val_loss: 1.0217 - val_accuracy: 0.5808\n",
      "Epoch 1268/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0362 - accuracy: 0.5504 - val_loss: 1.0200 - val_accuracy: 0.5654\n",
      "Epoch 1269/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0364 - accuracy: 0.5552 - val_loss: 1.0313 - val_accuracy: 0.5740\n",
      "Epoch 1270/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0292 - accuracy: 0.5603 - val_loss: 1.0330 - val_accuracy: 0.5750\n",
      "Epoch 1271/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0335 - accuracy: 0.5586 - val_loss: 1.0280 - val_accuracy: 0.5683\n",
      "Epoch 1272/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5557 - val_loss: 1.0250 - val_accuracy: 0.5740\n",
      "Epoch 1273/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0277 - accuracy: 0.5612 - val_loss: 1.0287 - val_accuracy: 0.5788\n",
      "Epoch 1274/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0289 - accuracy: 0.5603 - val_loss: 1.0344 - val_accuracy: 0.5740\n",
      "Epoch 1275/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0344 - accuracy: 0.5627 - val_loss: 1.0259 - val_accuracy: 0.5683\n",
      "Epoch 1276/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0363 - accuracy: 0.5535 - val_loss: 1.0343 - val_accuracy: 0.5740\n",
      "Epoch 1277/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0371 - accuracy: 0.5497 - val_loss: 1.0293 - val_accuracy: 0.5721\n",
      "Epoch 1278/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0347 - accuracy: 0.5511 - val_loss: 1.0297 - val_accuracy: 0.5692\n",
      "Epoch 1279/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0357 - accuracy: 0.5538 - val_loss: 1.0353 - val_accuracy: 0.5702\n",
      "Epoch 1280/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0372 - accuracy: 0.5518 - val_loss: 1.0234 - val_accuracy: 0.5788\n",
      "Epoch 1281/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0397 - accuracy: 0.5540 - val_loss: 1.0211 - val_accuracy: 0.5702\n",
      "Epoch 1282/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0442 - accuracy: 0.5482 - val_loss: 1.0277 - val_accuracy: 0.5750\n",
      "Epoch 1283/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0338 - accuracy: 0.5571 - val_loss: 1.0279 - val_accuracy: 0.5769\n",
      "Epoch 1284/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0372 - accuracy: 0.5456 - val_loss: 1.0326 - val_accuracy: 0.5702\n",
      "Epoch 1285/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0336 - accuracy: 0.5562 - val_loss: 1.0237 - val_accuracy: 0.5731\n",
      "Epoch 1286/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0434 - accuracy: 0.5547 - val_loss: 1.0253 - val_accuracy: 0.5702\n",
      "Epoch 1287/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0312 - accuracy: 0.5528 - val_loss: 1.0312 - val_accuracy: 0.5731\n",
      "Epoch 1288/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0376 - accuracy: 0.5533 - val_loss: 1.0321 - val_accuracy: 0.5788\n",
      "Epoch 1289/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0330 - accuracy: 0.5593 - val_loss: 1.0289 - val_accuracy: 0.5683\n",
      "Epoch 1290/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0310 - accuracy: 0.5538 - val_loss: 1.0351 - val_accuracy: 0.5692\n",
      "Epoch 1291/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0360 - accuracy: 0.5598 - val_loss: 1.0367 - val_accuracy: 0.5798\n",
      "Epoch 1292/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0415 - accuracy: 0.5494 - val_loss: 1.0338 - val_accuracy: 0.5721\n",
      "Epoch 1293/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0298 - accuracy: 0.5576 - val_loss: 1.0304 - val_accuracy: 0.5740\n",
      "Epoch 1294/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0304 - accuracy: 0.5564 - val_loss: 1.0416 - val_accuracy: 0.5750\n",
      "Epoch 1295/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0322 - accuracy: 0.5574 - val_loss: 1.0296 - val_accuracy: 0.5596\n",
      "Epoch 1296/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0339 - accuracy: 0.5579 - val_loss: 1.0167 - val_accuracy: 0.5692\n",
      "Epoch 1297/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0338 - accuracy: 0.5583 - val_loss: 1.0237 - val_accuracy: 0.5712\n",
      "Epoch 1298/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0343 - accuracy: 0.5538 - val_loss: 1.0240 - val_accuracy: 0.5683\n",
      "Epoch 1299/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0296 - accuracy: 0.5600 - val_loss: 1.0288 - val_accuracy: 0.5740\n",
      "Epoch 1300/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0294 - accuracy: 0.5603 - val_loss: 1.0283 - val_accuracy: 0.5779\n",
      "Epoch 1301/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0300 - accuracy: 0.5542 - val_loss: 1.0135 - val_accuracy: 0.5702\n",
      "Epoch 1302/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0271 - accuracy: 0.5559 - val_loss: 1.0330 - val_accuracy: 0.5760\n",
      "Epoch 1303/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0269 - accuracy: 0.5475 - val_loss: 1.0370 - val_accuracy: 0.5654\n",
      "Epoch 1304/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0278 - accuracy: 0.5545 - val_loss: 1.0343 - val_accuracy: 0.5663\n",
      "Epoch 1305/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0429 - accuracy: 0.5595 - val_loss: 1.0224 - val_accuracy: 0.5740\n",
      "Epoch 1306/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5612 - val_loss: 1.0325 - val_accuracy: 0.5769\n",
      "Epoch 1307/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0370 - accuracy: 0.5588 - val_loss: 1.0313 - val_accuracy: 0.5788\n",
      "Epoch 1308/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0339 - accuracy: 0.5576 - val_loss: 1.0249 - val_accuracy: 0.5721\n",
      "Epoch 1309/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0301 - accuracy: 0.5564 - val_loss: 1.0275 - val_accuracy: 0.5673\n",
      "Epoch 1310/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0347 - accuracy: 0.5588 - val_loss: 1.0230 - val_accuracy: 0.5712\n",
      "Epoch 1311/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0337 - accuracy: 0.5615 - val_loss: 1.0299 - val_accuracy: 0.5798\n",
      "Epoch 1312/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0352 - accuracy: 0.5506 - val_loss: 1.0386 - val_accuracy: 0.5702\n",
      "Epoch 1313/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0326 - accuracy: 0.5523 - val_loss: 1.0345 - val_accuracy: 0.5760\n",
      "Epoch 1314/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0364 - accuracy: 0.5550 - val_loss: 1.0315 - val_accuracy: 0.5740\n",
      "Epoch 1315/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0358 - accuracy: 0.5482 - val_loss: 1.0429 - val_accuracy: 0.5654\n",
      "Epoch 1316/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0292 - accuracy: 0.5540 - val_loss: 1.0307 - val_accuracy: 0.5750\n",
      "Epoch 1317/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0300 - accuracy: 0.5554 - val_loss: 1.0276 - val_accuracy: 0.5740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1318/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0339 - accuracy: 0.5612 - val_loss: 1.0269 - val_accuracy: 0.5731\n",
      "Epoch 1319/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0362 - accuracy: 0.5492 - val_loss: 1.0231 - val_accuracy: 0.5750\n",
      "Epoch 1320/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0274 - accuracy: 0.5567 - val_loss: 1.0412 - val_accuracy: 0.5654\n",
      "Epoch 1321/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0329 - accuracy: 0.5499 - val_loss: 1.0317 - val_accuracy: 0.5760\n",
      "Epoch 1322/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0327 - accuracy: 0.5571 - val_loss: 1.0324 - val_accuracy: 0.5673\n",
      "Epoch 1323/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0310 - accuracy: 0.5615 - val_loss: 1.0333 - val_accuracy: 0.5663\n",
      "Epoch 1324/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0273 - accuracy: 0.5552 - val_loss: 1.0213 - val_accuracy: 0.5731\n",
      "Epoch 1325/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5492 - val_loss: 1.0305 - val_accuracy: 0.5673\n",
      "Epoch 1326/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0308 - accuracy: 0.5591 - val_loss: 1.0277 - val_accuracy: 0.5606\n",
      "Epoch 1327/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0271 - accuracy: 0.5554 - val_loss: 1.0305 - val_accuracy: 0.5731\n",
      "Epoch 1328/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0368 - accuracy: 0.5526 - val_loss: 1.0403 - val_accuracy: 0.5606\n",
      "Epoch 1329/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0323 - accuracy: 0.5552 - val_loss: 1.0342 - val_accuracy: 0.5731\n",
      "Epoch 1330/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0375 - accuracy: 0.5514 - val_loss: 1.0299 - val_accuracy: 0.5760\n",
      "Epoch 1331/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0288 - accuracy: 0.5591 - val_loss: 1.0339 - val_accuracy: 0.5692\n",
      "Epoch 1332/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0350 - accuracy: 0.5526 - val_loss: 1.0378 - val_accuracy: 0.5683\n",
      "Epoch 1333/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0314 - accuracy: 0.5552 - val_loss: 1.0356 - val_accuracy: 0.5731\n",
      "Epoch 1334/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0311 - accuracy: 0.5588 - val_loss: 1.0287 - val_accuracy: 0.5663\n",
      "Epoch 1335/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0314 - accuracy: 0.5586 - val_loss: 1.0429 - val_accuracy: 0.5740\n",
      "Epoch 1336/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0286 - accuracy: 0.5574 - val_loss: 1.0229 - val_accuracy: 0.5740\n",
      "Epoch 1337/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0290 - accuracy: 0.5581 - val_loss: 1.0400 - val_accuracy: 0.5673\n",
      "Epoch 1338/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0304 - accuracy: 0.5528 - val_loss: 1.0281 - val_accuracy: 0.5663\n",
      "Epoch 1339/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0343 - accuracy: 0.5518 - val_loss: 1.0328 - val_accuracy: 0.5673\n",
      "Epoch 1340/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0291 - accuracy: 0.5521 - val_loss: 1.0332 - val_accuracy: 0.5702\n",
      "Epoch 1341/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0335 - accuracy: 0.5494 - val_loss: 1.0283 - val_accuracy: 0.5731\n",
      "Epoch 1342/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0365 - accuracy: 0.5557 - val_loss: 1.0316 - val_accuracy: 0.5721\n",
      "Epoch 1343/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0308 - accuracy: 0.5550 - val_loss: 1.0280 - val_accuracy: 0.5702\n",
      "Epoch 1344/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0271 - accuracy: 0.5631 - val_loss: 1.0343 - val_accuracy: 0.5731\n",
      "Epoch 1345/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0306 - accuracy: 0.5567 - val_loss: 1.0339 - val_accuracy: 0.5712\n",
      "Epoch 1346/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0319 - accuracy: 0.5593 - val_loss: 1.0358 - val_accuracy: 0.5712\n",
      "Epoch 1347/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0289 - accuracy: 0.5557 - val_loss: 1.0262 - val_accuracy: 0.5721\n",
      "Epoch 1348/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0330 - accuracy: 0.5581 - val_loss: 1.0259 - val_accuracy: 0.5740\n",
      "Epoch 1349/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0298 - accuracy: 0.5562 - val_loss: 1.0293 - val_accuracy: 0.5712\n",
      "Epoch 1350/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0323 - accuracy: 0.5499 - val_loss: 1.0280 - val_accuracy: 0.5721\n",
      "Epoch 1351/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0279 - accuracy: 0.5550 - val_loss: 1.0204 - val_accuracy: 0.5740\n",
      "Epoch 1352/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0295 - accuracy: 0.5542 - val_loss: 1.0161 - val_accuracy: 0.5750\n",
      "Epoch 1353/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0289 - accuracy: 0.5605 - val_loss: 1.0229 - val_accuracy: 0.5731\n",
      "Epoch 1354/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0321 - accuracy: 0.5557 - val_loss: 1.0318 - val_accuracy: 0.5702\n",
      "Epoch 1355/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0325 - accuracy: 0.5535 - val_loss: 1.0376 - val_accuracy: 0.5731\n",
      "Epoch 1356/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0307 - accuracy: 0.5545 - val_loss: 1.0404 - val_accuracy: 0.5712\n",
      "Epoch 1357/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0292 - accuracy: 0.5547 - val_loss: 1.0310 - val_accuracy: 0.5692\n",
      "Epoch 1358/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0317 - accuracy: 0.5535 - val_loss: 1.0348 - val_accuracy: 0.5673\n",
      "Epoch 1359/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0322 - accuracy: 0.5569 - val_loss: 1.0332 - val_accuracy: 0.5673\n",
      "Epoch 1360/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0322 - accuracy: 0.5595 - val_loss: 1.0346 - val_accuracy: 0.5673\n",
      "Epoch 1361/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0251 - accuracy: 0.5547 - val_loss: 1.0359 - val_accuracy: 0.5731\n",
      "Epoch 1362/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0317 - accuracy: 0.5559 - val_loss: 1.0289 - val_accuracy: 0.5692\n",
      "Epoch 1363/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0344 - accuracy: 0.5583 - val_loss: 1.0274 - val_accuracy: 0.5673\n",
      "Epoch 1364/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0269 - accuracy: 0.5552 - val_loss: 1.0359 - val_accuracy: 0.5740\n",
      "Epoch 1365/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0295 - accuracy: 0.5574 - val_loss: 1.0276 - val_accuracy: 0.5673\n",
      "Epoch 1366/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0336 - accuracy: 0.5574 - val_loss: 1.0245 - val_accuracy: 0.5663\n",
      "Epoch 1367/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0325 - accuracy: 0.5526 - val_loss: 1.0233 - val_accuracy: 0.5769\n",
      "Epoch 1368/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0288 - accuracy: 0.5557 - val_loss: 1.0307 - val_accuracy: 0.5731\n",
      "Epoch 1369/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0343 - accuracy: 0.5538 - val_loss: 1.0334 - val_accuracy: 0.5712\n",
      "Epoch 1370/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0303 - accuracy: 0.5615 - val_loss: 1.0264 - val_accuracy: 0.5731\n",
      "Epoch 1371/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0280 - accuracy: 0.5641 - val_loss: 1.0218 - val_accuracy: 0.5683\n",
      "Epoch 1372/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0263 - accuracy: 0.5559 - val_loss: 1.0241 - val_accuracy: 0.5750\n",
      "Epoch 1373/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0255 - accuracy: 0.5545 - val_loss: 1.0367 - val_accuracy: 0.5663\n",
      "Epoch 1374/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0268 - accuracy: 0.5559 - val_loss: 1.0321 - val_accuracy: 0.5683\n",
      "Epoch 1375/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0229 - accuracy: 0.5576 - val_loss: 1.0495 - val_accuracy: 0.5683\n",
      "Epoch 1376/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0288 - accuracy: 0.5550 - val_loss: 1.0474 - val_accuracy: 0.5644\n",
      "Epoch 1377/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0221 - accuracy: 0.5574 - val_loss: 1.0412 - val_accuracy: 0.5625\n",
      "Epoch 1378/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0280 - accuracy: 0.5530 - val_loss: 1.0361 - val_accuracy: 0.5673\n",
      "Epoch 1379/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0253 - accuracy: 0.5564 - val_loss: 1.0300 - val_accuracy: 0.5702\n",
      "Epoch 1380/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0349 - accuracy: 0.5499 - val_loss: 1.0368 - val_accuracy: 0.5673\n",
      "Epoch 1381/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0307 - accuracy: 0.5586 - val_loss: 1.0281 - val_accuracy: 0.5683\n",
      "Epoch 1382/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0260 - accuracy: 0.5530 - val_loss: 1.0344 - val_accuracy: 0.5702\n",
      "Epoch 1383/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0302 - accuracy: 0.5605 - val_loss: 1.0336 - val_accuracy: 0.5673\n",
      "Epoch 1384/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0332 - accuracy: 0.5542 - val_loss: 1.0270 - val_accuracy: 0.5721\n",
      "Epoch 1385/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0314 - accuracy: 0.5612 - val_loss: 1.0343 - val_accuracy: 0.5567\n",
      "Epoch 1386/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0288 - accuracy: 0.5478 - val_loss: 1.0353 - val_accuracy: 0.5654\n",
      "Epoch 1387/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0353 - accuracy: 0.5480 - val_loss: 1.0400 - val_accuracy: 0.5615\n",
      "Epoch 1388/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0261 - accuracy: 0.5617 - val_loss: 1.0391 - val_accuracy: 0.5721\n",
      "Epoch 1389/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0256 - accuracy: 0.5530 - val_loss: 1.0228 - val_accuracy: 0.5654\n",
      "Epoch 1390/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0321 - accuracy: 0.5526 - val_loss: 1.0220 - val_accuracy: 0.5683\n",
      "Epoch 1391/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0301 - accuracy: 0.5643 - val_loss: 1.0323 - val_accuracy: 0.5760\n",
      "Epoch 1392/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0315 - accuracy: 0.5598 - val_loss: 1.0298 - val_accuracy: 0.5673\n",
      "Epoch 1393/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0312 - accuracy: 0.5581 - val_loss: 1.0308 - val_accuracy: 0.5663\n",
      "Epoch 1394/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0224 - accuracy: 0.5576 - val_loss: 1.0294 - val_accuracy: 0.5712\n",
      "Epoch 1395/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0284 - accuracy: 0.5586 - val_loss: 1.0382 - val_accuracy: 0.5625\n",
      "Epoch 1396/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0283 - accuracy: 0.5586 - val_loss: 1.0349 - val_accuracy: 0.5663\n",
      "Epoch 1397/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0369 - accuracy: 0.5581 - val_loss: 1.0267 - val_accuracy: 0.5615\n",
      "Epoch 1398/1500\n",
      "4157/4157 [==============================] - 0s 31us/step - loss: 1.0295 - accuracy: 0.5600 - val_loss: 1.0199 - val_accuracy: 0.5683\n",
      "Epoch 1399/1500\n",
      "4157/4157 [==============================] - 0s 30us/step - loss: 1.0339 - accuracy: 0.5528 - val_loss: 1.0297 - val_accuracy: 0.5654\n",
      "Epoch 1400/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0259 - accuracy: 0.5550 - val_loss: 1.0332 - val_accuracy: 0.5625\n",
      "Epoch 1401/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0262 - accuracy: 0.5554 - val_loss: 1.0429 - val_accuracy: 0.5654\n",
      "Epoch 1402/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0309 - accuracy: 0.5612 - val_loss: 1.0439 - val_accuracy: 0.5663\n",
      "Epoch 1403/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0293 - accuracy: 0.5600 - val_loss: 1.0370 - val_accuracy: 0.5663\n",
      "Epoch 1404/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0320 - accuracy: 0.5579 - val_loss: 1.0239 - val_accuracy: 0.5644\n",
      "Epoch 1405/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0230 - accuracy: 0.5603 - val_loss: 1.0280 - val_accuracy: 0.5644\n",
      "Epoch 1406/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0289 - accuracy: 0.5617 - val_loss: 1.0292 - val_accuracy: 0.5702\n",
      "Epoch 1407/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0300 - accuracy: 0.5492 - val_loss: 1.0265 - val_accuracy: 0.5702\n",
      "Epoch 1408/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0253 - accuracy: 0.5581 - val_loss: 1.0274 - val_accuracy: 0.5712\n",
      "Epoch 1409/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0238 - accuracy: 0.5562 - val_loss: 1.0263 - val_accuracy: 0.5692\n",
      "Epoch 1410/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0335 - accuracy: 0.5554 - val_loss: 1.0397 - val_accuracy: 0.5712\n",
      "Epoch 1411/1500\n",
      "4157/4157 [==============================] - 0s 35us/step - loss: 1.0259 - accuracy: 0.5598 - val_loss: 1.0548 - val_accuracy: 0.5683\n",
      "Epoch 1412/1500\n",
      "4157/4157 [==============================] - 0s 51us/step - loss: 1.0305 - accuracy: 0.5485 - val_loss: 1.0555 - val_accuracy: 0.5683\n",
      "Epoch 1413/1500\n",
      "4157/4157 [==============================] - 0s 49us/step - loss: 1.0307 - accuracy: 0.5523 - val_loss: 1.0473 - val_accuracy: 0.5692\n",
      "Epoch 1414/1500\n",
      "4157/4157 [==============================] - 0s 41us/step - loss: 1.0293 - accuracy: 0.5569 - val_loss: 1.0488 - val_accuracy: 0.5625\n",
      "Epoch 1415/1500\n",
      "4157/4157 [==============================] - 0s 36us/step - loss: 1.0249 - accuracy: 0.5612 - val_loss: 1.0351 - val_accuracy: 0.5663\n",
      "Epoch 1416/1500\n",
      "4157/4157 [==============================] - 0s 33us/step - loss: 1.0295 - accuracy: 0.5617 - val_loss: 1.0348 - val_accuracy: 0.5683\n",
      "Epoch 1417/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0248 - accuracy: 0.5603 - val_loss: 1.0320 - val_accuracy: 0.5692\n",
      "Epoch 1418/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0275 - accuracy: 0.5605 - val_loss: 1.0317 - val_accuracy: 0.5683\n",
      "Epoch 1419/1500\n",
      "4157/4157 [==============================] - 0s 39us/step - loss: 1.0322 - accuracy: 0.5516 - val_loss: 1.0374 - val_accuracy: 0.5596\n",
      "Epoch 1420/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0262 - accuracy: 0.5607 - val_loss: 1.0381 - val_accuracy: 0.5625\n",
      "Epoch 1421/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0275 - accuracy: 0.5583 - val_loss: 1.0524 - val_accuracy: 0.5606\n",
      "Epoch 1422/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0293 - accuracy: 0.5581 - val_loss: 1.0423 - val_accuracy: 0.5692\n",
      "Epoch 1423/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0268 - accuracy: 0.5530 - val_loss: 1.0309 - val_accuracy: 0.5712\n",
      "Epoch 1424/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0235 - accuracy: 0.5567 - val_loss: 1.0334 - val_accuracy: 0.5635\n",
      "Epoch 1425/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0255 - accuracy: 0.5567 - val_loss: 1.0453 - val_accuracy: 0.5683\n",
      "Epoch 1426/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0235 - accuracy: 0.5569 - val_loss: 1.0352 - val_accuracy: 0.5731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1427/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0241 - accuracy: 0.5583 - val_loss: 1.0296 - val_accuracy: 0.5692\n",
      "Epoch 1428/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0254 - accuracy: 0.5576 - val_loss: 1.0356 - val_accuracy: 0.5702\n",
      "Epoch 1429/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0254 - accuracy: 0.5550 - val_loss: 1.0451 - val_accuracy: 0.5673\n",
      "Epoch 1430/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0249 - accuracy: 0.5547 - val_loss: 1.0368 - val_accuracy: 0.5721\n",
      "Epoch 1431/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0251 - accuracy: 0.5540 - val_loss: 1.0303 - val_accuracy: 0.5692\n",
      "Epoch 1432/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0275 - accuracy: 0.5526 - val_loss: 1.0258 - val_accuracy: 0.5692\n",
      "Epoch 1433/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0253 - accuracy: 0.5588 - val_loss: 1.0342 - val_accuracy: 0.5692\n",
      "Epoch 1434/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0338 - accuracy: 0.5523 - val_loss: 1.0255 - val_accuracy: 0.5721\n",
      "Epoch 1435/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0239 - accuracy: 0.5586 - val_loss: 1.0382 - val_accuracy: 0.5635\n",
      "Epoch 1436/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0239 - accuracy: 0.5550 - val_loss: 1.0500 - val_accuracy: 0.5702\n",
      "Epoch 1437/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0244 - accuracy: 0.5542 - val_loss: 1.0249 - val_accuracy: 0.5702\n",
      "Epoch 1438/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0252 - accuracy: 0.5689 - val_loss: 1.0247 - val_accuracy: 0.5635\n",
      "Epoch 1439/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0271 - accuracy: 0.5554 - val_loss: 1.0255 - val_accuracy: 0.5683\n",
      "Epoch 1440/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0239 - accuracy: 0.5579 - val_loss: 1.0169 - val_accuracy: 0.5644\n",
      "Epoch 1441/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0194 - accuracy: 0.5634 - val_loss: 1.0302 - val_accuracy: 0.5760\n",
      "Epoch 1442/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0260 - accuracy: 0.5533 - val_loss: 1.0305 - val_accuracy: 0.5587\n",
      "Epoch 1443/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0282 - accuracy: 0.5610 - val_loss: 1.0338 - val_accuracy: 0.5615\n",
      "Epoch 1444/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0249 - accuracy: 0.5607 - val_loss: 1.0360 - val_accuracy: 0.5596\n",
      "Epoch 1445/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0247 - accuracy: 0.5593 - val_loss: 1.0340 - val_accuracy: 0.5606\n",
      "Epoch 1446/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0334 - accuracy: 0.5581 - val_loss: 1.0306 - val_accuracy: 0.5625\n",
      "Epoch 1447/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0271 - accuracy: 0.5514 - val_loss: 1.0376 - val_accuracy: 0.5654\n",
      "Epoch 1448/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0223 - accuracy: 0.5598 - val_loss: 1.0324 - val_accuracy: 0.5635\n",
      "Epoch 1449/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0187 - accuracy: 0.5622 - val_loss: 1.0216 - val_accuracy: 0.5712\n",
      "Epoch 1450/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0231 - accuracy: 0.5547 - val_loss: 1.0285 - val_accuracy: 0.5663\n",
      "Epoch 1451/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0272 - accuracy: 0.5567 - val_loss: 1.0207 - val_accuracy: 0.5663\n",
      "Epoch 1452/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0257 - accuracy: 0.5530 - val_loss: 1.0344 - val_accuracy: 0.5644\n",
      "Epoch 1453/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0245 - accuracy: 0.5581 - val_loss: 1.0295 - val_accuracy: 0.5692\n",
      "Epoch 1454/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0313 - accuracy: 0.5631 - val_loss: 1.0359 - val_accuracy: 0.5596\n",
      "Epoch 1455/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0252 - accuracy: 0.5603 - val_loss: 1.0328 - val_accuracy: 0.5731\n",
      "Epoch 1456/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0278 - accuracy: 0.5571 - val_loss: 1.0201 - val_accuracy: 0.5654\n",
      "Epoch 1457/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0202 - accuracy: 0.5603 - val_loss: 1.0408 - val_accuracy: 0.5644\n",
      "Epoch 1458/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0238 - accuracy: 0.5612 - val_loss: 1.0319 - val_accuracy: 0.5702\n",
      "Epoch 1459/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0343 - accuracy: 0.5579 - val_loss: 1.0195 - val_accuracy: 0.5683\n",
      "Epoch 1460/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0262 - accuracy: 0.5518 - val_loss: 1.0294 - val_accuracy: 0.5663\n",
      "Epoch 1461/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0243 - accuracy: 0.5641 - val_loss: 1.0271 - val_accuracy: 0.5692\n",
      "Epoch 1462/1500\n",
      "4157/4157 [==============================] - 0s 32us/step - loss: 1.0240 - accuracy: 0.5591 - val_loss: 1.0327 - val_accuracy: 0.5654\n",
      "Epoch 1463/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0297 - accuracy: 0.5518 - val_loss: 1.0385 - val_accuracy: 0.5625\n",
      "Epoch 1464/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0263 - accuracy: 0.5526 - val_loss: 1.0334 - val_accuracy: 0.5731\n",
      "Epoch 1465/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0241 - accuracy: 0.5595 - val_loss: 1.0412 - val_accuracy: 0.5721\n",
      "Epoch 1466/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0290 - accuracy: 0.5485 - val_loss: 1.0491 - val_accuracy: 0.5721\n",
      "Epoch 1467/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0303 - accuracy: 0.5550 - val_loss: 1.0568 - val_accuracy: 0.5510\n",
      "Epoch 1468/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0216 - accuracy: 0.5547 - val_loss: 1.0335 - val_accuracy: 0.5625\n",
      "Epoch 1469/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0203 - accuracy: 0.5581 - val_loss: 1.0548 - val_accuracy: 0.5644\n",
      "Epoch 1470/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0250 - accuracy: 0.5567 - val_loss: 1.0594 - val_accuracy: 0.5606\n",
      "Epoch 1471/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0234 - accuracy: 0.5588 - val_loss: 1.0520 - val_accuracy: 0.5673\n",
      "Epoch 1472/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0205 - accuracy: 0.5612 - val_loss: 1.0373 - val_accuracy: 0.5673\n",
      "Epoch 1473/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0279 - accuracy: 0.5571 - val_loss: 1.0353 - val_accuracy: 0.5635\n",
      "Epoch 1474/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0286 - accuracy: 0.5607 - val_loss: 1.0431 - val_accuracy: 0.5712\n",
      "Epoch 1475/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0220 - accuracy: 0.5574 - val_loss: 1.0545 - val_accuracy: 0.5654\n",
      "Epoch 1476/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0297 - accuracy: 0.5586 - val_loss: 1.0374 - val_accuracy: 0.5721\n",
      "Epoch 1477/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0308 - accuracy: 0.5521 - val_loss: 1.0430 - val_accuracy: 0.5663\n",
      "Epoch 1478/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0252 - accuracy: 0.5562 - val_loss: 1.0477 - val_accuracy: 0.5731\n",
      "Epoch 1479/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0284 - accuracy: 0.5603 - val_loss: 1.0497 - val_accuracy: 0.5673\n",
      "Epoch 1480/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0311 - accuracy: 0.5583 - val_loss: 1.0379 - val_accuracy: 0.5644\n",
      "Epoch 1481/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0249 - accuracy: 0.5588 - val_loss: 1.0331 - val_accuracy: 0.5740\n",
      "Epoch 1482/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0259 - accuracy: 0.5627 - val_loss: 1.0457 - val_accuracy: 0.5635\n",
      "Epoch 1483/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0309 - accuracy: 0.5588 - val_loss: 1.0500 - val_accuracy: 0.5702\n",
      "Epoch 1484/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0200 - accuracy: 0.5533 - val_loss: 1.0441 - val_accuracy: 0.5635\n",
      "Epoch 1485/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0277 - accuracy: 0.5598 - val_loss: 1.0348 - val_accuracy: 0.5644\n",
      "Epoch 1486/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0244 - accuracy: 0.5571 - val_loss: 1.0354 - val_accuracy: 0.5702\n",
      "Epoch 1487/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0252 - accuracy: 0.5574 - val_loss: 1.0396 - val_accuracy: 0.5635\n",
      "Epoch 1488/1500\n",
      "4157/4157 [==============================] - 0s 28us/step - loss: 1.0236 - accuracy: 0.5656 - val_loss: 1.0446 - val_accuracy: 0.5596\n",
      "Epoch 1489/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0247 - accuracy: 0.5576 - val_loss: 1.0404 - val_accuracy: 0.5625\n",
      "Epoch 1490/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0320 - accuracy: 0.5516 - val_loss: 1.0430 - val_accuracy: 0.5654\n",
      "Epoch 1491/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0198 - accuracy: 0.5670 - val_loss: 1.0449 - val_accuracy: 0.5654\n",
      "Epoch 1492/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0254 - accuracy: 0.5552 - val_loss: 1.0491 - val_accuracy: 0.5644\n",
      "Epoch 1493/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0302 - accuracy: 0.5562 - val_loss: 1.0371 - val_accuracy: 0.5721\n",
      "Epoch 1494/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0204 - accuracy: 0.5487 - val_loss: 1.0501 - val_accuracy: 0.5663\n",
      "Epoch 1495/1500\n",
      "4157/4157 [==============================] - 0s 26us/step - loss: 1.0250 - accuracy: 0.5593 - val_loss: 1.0426 - val_accuracy: 0.5702\n",
      "Epoch 1496/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0269 - accuracy: 0.5607 - val_loss: 1.0456 - val_accuracy: 0.5644\n",
      "Epoch 1497/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0267 - accuracy: 0.5624 - val_loss: 1.0435 - val_accuracy: 0.5673\n",
      "Epoch 1498/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0317 - accuracy: 0.5627 - val_loss: 1.0282 - val_accuracy: 0.5654\n",
      "Epoch 1499/1500\n",
      "4157/4157 [==============================] - 0s 29us/step - loss: 1.0168 - accuracy: 0.5675 - val_loss: 1.0487 - val_accuracy: 0.5625\n",
      "Epoch 1500/1500\n",
      "4157/4157 [==============================] - 0s 27us/step - loss: 1.0234 - accuracy: 0.5622 - val_loss: 1.0389 - val_accuracy: 0.5721\n",
      "1300/1300 [==============================] - 0s 8us/step\n",
      "\n",
      "Test Loss: [1.06979055588062, 0.5569230914115906]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################################################\n",
    "x_train_red, y_train_red, x_test_red, y_test_red = generate_data(red_wine, 0.8)\n",
    "y_train_red = one_hot_enc(y_train_red)\n",
    "y_test_red = one_hot_enc(y_test_red)\n",
    "\n",
    "x_train = np.append(x_train, x_train_red, axis=0)\n",
    "y_train = np.append(y_train, y_train_red, axis=0)\n",
    "x_test = np.append(x_test, x_test_red, axis=0)\n",
    "y_test = np.append(y_test, y_test_red, axis=0)\n",
    "\n",
    "model = DNN(n_in, n_h, n_h2, n_h3, n_h4, n_h5, n_h6, n_h7, n_h8, n_h9, n_out)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=1500,\n",
    "                    batch_size=BATCH_SIZE, validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "performance_test = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(f'\\nTest Loss: {performance_test}')\n",
    "\n",
    "plot_loss(history)\n",
    "plt.show()\n",
    "plot_acc(history)\n",
    "plt.show()\n",
    "###########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WindClassifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "f7eb9da2086e92ec6b3f9d89598363e45a1a635b7cda3a5d64804cd6cbde1def"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
